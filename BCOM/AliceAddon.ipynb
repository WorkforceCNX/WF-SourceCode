{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5d2346d1-0842-4245-9bb9-1e6136aab7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library listü§ñ\n",
    "import glob, warnings, polars as pl, datetime, sqlite3, time, os, zipfile, xml.dom.minidom\n",
    "from datetime import datetime as dt, time as t, timedelta, date\n",
    "import pandas as pd, numpy as np, sqlalchemy as sa, xlsxwriter\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from sqlalchemy import create_engine, text\n",
    "import math\n",
    "# -----------------------------------------------------------------------------------------------#\n",
    "# Source collection\n",
    "# user_credential = os.path.join(os.environ['USERPROFILE'],r'Concentrix Corporation//CNXVN - WFM Team - Documents//')\n",
    "user_credential = os.path.join(os.environ['USERPROFILE'],r'Concentrix Corporation//CNXVN - WFM Team - Documents//')\n",
    "\n",
    "# INPUT-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ\n",
    "# [BKN]LOGOUT_COUNT 0Ô∏è‚É£1Ô∏è‚É£\n",
    "Link_LOGOUT_COUNT = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN//LOGOUT_COUNT//*.CSV')\n",
    "# [BKN]AGENTS 0Ô∏è‚É£2Ô∏è‚É£\n",
    "Link_AGENTS = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//AGENTS//*.xlsx')\n",
    "# [GLB]EmployeeMaster 0Ô∏è‚É£3Ô∏è‚É£\n",
    "Link_EmployeeMaster = os.path.join(user_credential,\n",
    "                                    r'DataBase//DataRaw//GLOBAL//WDD//*.xlsx')\n",
    "# [GLB]Ramco 0Ô∏è‚É£4Ô∏è‚É£\n",
    "Link_Ramco = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//GLOBAL//RAMCO//*.CSV')\n",
    "# [BKN]Schedule 0Ô∏è‚É£5Ô∏è‚É£\n",
    "Link_Schedule = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//ROSTER//*.xlsx')\n",
    "# [BKN]EPS 0Ô∏è‚É£6Ô∏è‚É£\n",
    "Link_EPS = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//EPS//*.CSV')\n",
    "# [BKN]AHT 0Ô∏è‚É£7Ô∏è‚É£\n",
    "Link_AHT = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//AHT//*.CSV')\n",
    "# [BKN]Holiday 0Ô∏è‚É£8Ô∏è‚É£\n",
    "Link_Holiday = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//HOLIDAY_MAPPING//*.CSV')\n",
    "# [BKN]IntervalReq 0Ô∏è‚É£9Ô∏è‚É£\n",
    "Link_IntervalReq = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN//INTERVAL_REQUIREMENT//*.xlsx')\n",
    "# [BKN]CapacityHC 1Ô∏è‚É£0Ô∏è‚É£\n",
    "Link_CapacityHC = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN//CAPACITY_HC//*.xlsx')\n",
    "# [BKN]RampHC 1Ô∏è‚É£1Ô∏è‚É£\n",
    "Link_RampHC = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//RAMPUP_HC//*.xlsx')\n",
    "# [BKN]CSAT_Tp 1Ô∏è‚É£2Ô∏è‚É£\n",
    "Link_CSAT_Tp = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//CSAT//*.CSV')\n",
    "# [BKN]CSAT_Rs 1Ô∏è‚É£3Ô∏è‚É£\n",
    "Link_CSAT_Rs = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//CSAT_RESO//*.CSV')\n",
    "# [BKN]CUIC 1Ô∏è‚É£4Ô∏è‚É£\n",
    "Link_CUIC = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//CUIC//*.xlsx')\n",
    "# [BKN]ExcepReq 1Ô∏è‚É£5Ô∏è‚É£\n",
    "Link_ExcepReq = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//EXCEPTION_REQ//*.xlsx')\n",
    "# [BKN]KPI_Tar 1Ô∏è‚É£6Ô∏è‚É£\n",
    "Link_KPI_Tar = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//KPI_TARGET//*.xlsx')\n",
    "# [BKN]OverTime 1Ô∏è‚É£7Ô∏è‚É£\n",
    "Link_OverTime = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//OVERTIME//*.xlsx')\n",
    "# [BKN]PSAT 1Ô∏è‚É£8Ô∏è‚É£\n",
    "Link_PSAT = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//PSAT//*.CSV')\n",
    "# [BKN]Quality 1Ô∏è‚É£9Ô∏è‚É£\n",
    "Link_Quality = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//QUALITY//*.xlsx')\n",
    "# [GLB]OTRamco 2Ô∏è‚É£0Ô∏è‚É£\n",
    "Link_OTRamco = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//GLOBAL//OT_RAMCO//*.xlsx')\n",
    "# [BKN]DailyReq 2Ô∏è‚É£1Ô∏è‚É£\n",
    "Link_DailyReq = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//REQUIREMENT_HOURS//*.xlsx')\n",
    "# [BKN]IEX 2Ô∏è‚É£2Ô∏è‚É£\n",
    "Link_IEX = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//IEX//*.xlsx')\n",
    "# [BKN]Workplan 2Ô∏è‚É£3Ô∏è‚É£\n",
    "Link_Workplan = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//WORKPLAN//WORKPLAN QUERY//*.xlsx')\n",
    "# [BKN]Ticket 2Ô∏è‚É£4Ô∏è‚É£\n",
    "Link_Ticket = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//TICKET//*.CSV')\n",
    "# [BKN]RONA 2Ô∏è‚É£5Ô∏è‚É£\n",
    "Link_RONA = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//RONA//*.xlsx')\n",
    "# [BKN]SC_Labels 2Ô∏è‚É£6Ô∏è‚É£\n",
    "Link_SC_Labels = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//SC_LABELS//*.CSV')\n",
    "# [BKN]ShrinkTar 2Ô∏è‚É£7Ô∏è‚É£\n",
    "Link_ShrinkTar = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//SHRINKAGE_TARGET//*.xlsx')\n",
    "# [GLB]WorkdayDump 2Ô∏è‚É£8Ô∏è‚É£\n",
    "Link_Attri_Ter = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//GLOBAL//WDD//*.xlsx')\n",
    "# [BKN]HC_Transfer 2Ô∏è‚É£9Ô∏è‚É£\n",
    "Link_HC_Transfer = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN//HC_TRANSFER//*.xlsx')\n",
    "# [BKN]Workplan_summary 3Ô∏è‚É£0Ô∏è‚É£\n",
    "Link_Workplan_summary = os.path.join(user_credential,\n",
    "                                    r'DataBase//DataRaw//BKN//WORKPLAN_SUMMARY//WORKPLAN_SUMMARY_QUERY//*.xlsx')\n",
    "# [BKN]CSAT_PEGA 3Ô∏è‚É£1Ô∏è‚É£\n",
    "Link_CSAT_PEGA = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//CSAT_PEGA//*.CSV')\n",
    "# [BKN]IPH_PEGA 3Ô∏è‚É£2Ô∏è‚É£\n",
    "Link_IPH_PEGA = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//IPH_PEGA//*.CSV')\n",
    "#[BKN]ContactTracker 3Ô∏è‚É£3Ô∏è‚É£\n",
    "Link_ContactTracker = os.path.join(os.environ['USERPROFILE'],\n",
    "                                   r'OneDrive - Concentrix Corporation//DataBase//DataRaw//BKN//ContactTracker//*.xlsx')\n",
    "# [BKN]OT_REQ 3Ô∏è‚É£4Ô∏è‚É£\n",
    "Link_OT_REQ = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//OT_REQ//*.xlsx')\n",
    "# [BKN]PROJECTED_HC 3Ô∏è‚É£5Ô∏è‚É£\n",
    "Link_PROJECTED_HC = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//PROJECTED_HEADCOUNT//*.xlsm')\n",
    "# [BKN]IEXHRS 3Ô∏è‚É£6Ô∏è‚É£\n",
    "Link_IEXHRS = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//IEXHOURS//Overview Interval Query//*.xlsx')\n",
    "# [BKN]REALTIME_CUIC 3Ô∏è‚É£7Ô∏è‚É£\n",
    "Link_REALTIME_CUIC = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//REALTIME_VIEW//*.xlsx')\n",
    "\n",
    "# OUTPUT-----üì•-----üì•-----üì•-----üì•-----üì•-----üì•-----üì•-----üì•-----üì•-----üì•\n",
    "# [BKN]EEAAO üìë\n",
    "DF_EEAAO = os.path.join(user_credential, \n",
    "                        r'DataBase//DataFrame//BKN//EEAAO_DF')\n",
    "# [BKN]REVENUE üìë\n",
    "DF_REVENUE = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//REVENUE')\n",
    "# [BKN]CSAT_CMB üìë\n",
    "DF_CSAT_CMB = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//CSAT_COMBINE')\n",
    "# [BKN]JEOPADY üìë\n",
    "DF_JEOPADY = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//JEOPADY')\n",
    "\n",
    "# [GLB]NM_REPORT üìë\n",
    "DF_NM_REPORT = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//GLOBAL//NM_REPORT')\n",
    "# [GLB]OT_REPORT üìë\n",
    "DF_OT_REPORT = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//GLOBAL//OT_REPORT')\n",
    "# [BKN]AgentWorkPlan üìë\n",
    "DF_AGENT_WORKPLAN = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//AGENT_WORKPLAN')\n",
    "# [BKN]INTERVAL_REQ üìë\n",
    "DF_INTERVAL_REQ = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//INTERVAL_REQ')\n",
    "# [BKN]CONTACT_TRACKER üìë\n",
    "DF_CONTACT_TRACKER = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//CONTACT_TRACKER')\n",
    "# [BKN]DATA_TRACKER üìë\n",
    "DF_DATA_TRACKER = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//DATA_TRACKER')\n",
    "# [BKN]IEXHRS üìë\n",
    "DF_IEXHRS = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//IEXHOURS')\n",
    "# [BKN]AHT_DETAIL üìë\n",
    "DF_AHT_DETAIL = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//AHT_DETAIL')\n",
    "# [BKN]ATTRITION üìë\n",
    "DF_ATTRITION = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//ATTRITION_DF')\n",
    "# [BKN]CHECKDUP üìë\n",
    "DF_CHECKDUP = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//CHECKDUP')\n",
    "# [BKN]ATD_DF üìë\n",
    "DF_ATD_DF = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//ATD_DF')\n",
    "# [BKN]ATD_DF üìë\n",
    "DF_LOGIN_DF = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//LOGIN_DETAIL_DF//Booking - Agent Wise Login Detail.xlsx')\n",
    "Login_Logout_Folder= os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//Late_Soon_Insight')\n",
    "Stafftime_Folder= os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//Shortage of Stafftime')\n",
    "Logout_Count_Folder= os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//LOGOUT_COUNT_Insight')\n",
    "Low_CPH_Folder= os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//Low_CPH_Insight')\n",
    "OOH_Folder=os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//Out_of_Hoop_insight')\n",
    "BKN_Folder= os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN')\n",
    "CPH_QUALITY_AHT_DF = os.path.join(user_credential, \n",
    "                            r'RTA_PersonalFile//Alice Nguyen')\n",
    "Seatmap = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//SEAT_MAP')\n",
    "schedule=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//SCHEDULE')\n",
    "attrition=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//ATTRITION')\n",
    "delivery=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//DELIVERY')\n",
    "csat=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//CSAT')\n",
    "cph=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//CPH')\n",
    "eeaao=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//EEAAO')\n",
    "data_tracker=os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//DATA_TRACKER')\n",
    "atd=os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//ATD_DF')\n",
    "ot_report=os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//OT')\n",
    "# -----------------------------------------------------------------------------------------------#\n",
    "# Tracker_Folder\n",
    "folder_paths = [\n",
    "    os.path.dirname(Link) for Link in [\n",
    "        Link_LOGOUT_COUNT, Link_AGENTS, Link_EmployeeMaster, Link_Ramco, Link_Schedule, Link_EPS, Link_AHT, Link_Holiday, \n",
    "        Link_IntervalReq, Link_CapacityHC, Link_RampHC, Link_CSAT_Tp, Link_CSAT_Rs, Link_CUIC, Link_ExcepReq, Link_KPI_Tar, \n",
    "        Link_OverTime, Link_PSAT, Link_Quality, Link_OTRamco, Link_DailyReq, Link_IEX, Link_Workplan, Link_Ticket, Link_RONA, \n",
    "        Link_SC_Labels, Link_ShrinkTar, Link_Attri_Ter, Link_HC_Transfer, Link_Workplan_summary, Link_CSAT_PEGA, Link_IPH_PEGA, \n",
    "        Link_OT_REQ, Link_IEXHRS]] \n",
    "\n",
    "# -----------------------------------------------------------------------------------------------#\n",
    "# MyMiscellaneous\n",
    "\n",
    "# [DB]TonyMiscellaneous\n",
    "Link_DB = os.path.join(os.environ['USERPROFILE'], r'Desktop//Bcom_DB.db')\n",
    "link_PENDINGDETAIL = os.path.join(user_credential, r'DataBase//DataFrame//GLOBAL//PendingDetail//DetailPending.xlsx')\n",
    "conn = create_engine(f\"sqlite:///{Link_DB}\")\n",
    "server_name = \"PHMANVMDEV01V\"\n",
    "server_ip = \"10.5.11.60\"\n",
    "database = \"wfm_vn_dev\"\n",
    "user = \"usr_wfmvn_dev\"\n",
    "password = \"12guWU2OdEj5kEspl9Rlfoglf\"\n",
    "# SQL Server Authentication üîó\n",
    "connection_string = f\"mssql+pyodbc://{user}:{password}@{server_ip}/{database}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "# Windows Authentication üîó\n",
    "# connection_string = f\"mssql+pyodbc://{server_name}/{database}?driver=ODBC+Driver+17+for+SQL+Server&Trusted_Connection=yes\"\n",
    "engine = create_engine(connection_string, fast_executemany=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "92f900bb-43ec-495a-95ed-e2a869fd8f40",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Powwer BI notive\n",
    "\n",
    "\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "/* DATA TRACKER  */\n",
    " \n",
    "--EPS\n",
    "select 'Working Hours' as [DISPLAY_NAME],cast(max([Session Login]) as date) as [LastestData] from BCOM.EPS\n",
    "union all\n",
    "--CPI\n",
    "select 'CPI' as [DISPLAY_NAME],cast(max([Date]) as date) as [LastestData] from BCOM.CPI\n",
    "union all\n",
    "--CPI_PEGA\n",
    "select 'PEGA Swivel' as [DISPLAY_NAME],cast(max([Day of Date]) as date) as [LastestData] from BCOM.CPI_PEGA\n",
    "union all\n",
    "--CSAT_RS\n",
    "select 'CSAT' as [DISPLAY_NAME],cast(max([Sort by Dimension]) as date) as [LastestData] from BCOM.CSAT_RS\n",
    "union all\n",
    "--PSAT\n",
    "select 'PSAT' as [DISPLAY_NAME],cast(max([Sorted by Dimension]) as date) as [LastestData] from BCOM.PSAT\n",
    "union all\n",
    "--Quality\n",
    "select 'QUALITY' as [DISPLAY_NAME],cast(max([eval_date]) as date) as [LastestData] from BCOM.Quality\n",
    "union all\n",
    "--AHT2\n",
    "select 'AHT' as [DISPLAY_NAME],cast(max([Date]) as date) as [LastestData] from BCOM.AHT2\n",
    "union all\n",
    "--ROSTER\n",
    "select 'ROSTER' as [DISPLAY_NAME],cast(max([Attribute]) as date) as [LastestData] from BCOM.ROSTER\n",
    "\n",
    "\"\"\"\n",
    " \n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "datatracker_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "datatracker_df = datatracker_df.with_columns(pl.col(\"LastestData\").dt.strftime(\"%Y-%m-%d\"))\n",
    " \n",
    "# Export to CSV\n",
    "os.chdir(data_tracker)\n",
    "datatracker_CSV = datatracker_df.write_excel(workbook=\"BKN_DATA_TRACKER.xlsx\",worksheet=\"Sheet1\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfab1536-ab51-4bc8-bc90-febbfc84afbd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ATD TEAMS Detail LINK\n",
    "\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[Shift],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [Present],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]=DATEADD(DAY, -1,CAST(GETDATE() As Date)) and [Shift]not in ('OFF','Training','New Hire Training')\n",
    "Order by [TL_Name], [Shift] DESC\n",
    "\"\"\"\n",
    " \n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "atd_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_CSV = atd_df.write_csv(\"BKN_ATD_DF.csv\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9924c83b-a788-4c1d-af9c-626214b5b086",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ATD TEAMS PIVOT 1 (Overall)\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "with atd as (\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[week_shift],[Shift],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [ATD],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END AS [NormalShift],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk],\n",
    "CASE WHEN [Shift]='OFF' then 0 else 1 end as [Headcount]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]=DATEADD(DAY, -1,CAST(GETDATE() As Date)) and [Shift] not in ('OFF','Training','New Hire Training'))\n",
    "select [Date],\n",
    "sum([Headcount]) as [Headcount],sum([ATD]) as [Present],sum([UPL-Not present at desk]) as [UPL-Not present at desk],\n",
    "sum([UnplanLeave]) as [UPL-Request within 7 days],sum([PlanLeave]) as [PlanLeave],\n",
    "case when sum([Headcount])=0 then 0 else sum([ATD])/sum([Headcount]) end as [Present%]\n",
    "from atd\n",
    "group by [Date]\n",
    "\"\"\"\n",
    " \n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "atd_pivot_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "atd_pivot_df=atd_pivot_df.with_columns(pl.col(\"Date\").dt.to_string(\"%Y-%m-%d\"))\n",
    "atd_pivot_df=atd_pivot_df.to_pandas()\n",
    "atd_pivot_df['Present%'] = atd_pivot_df['Present%'].map('{:.2%}'.format)\n",
    "atd_pivot_df=pl.from_pandas(atd_pivot_df)\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_pivot_CSV = atd_pivot_df.write_excel(workbook=\"BKN_pivot_ATD_DF_total.xlsx\",worksheet=\"Sheet1\",\n",
    "                                           table_name='Frame0', table_style='Table Style Medium 2',autofit=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf15281a-ab8d-40c9-810c-4c2ad3d5ee03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ATD TEAMS PIVOT 2 (Per TL)\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "with atd as (\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[week_shift],[Shift],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [ATD],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END AS [NormalShift],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk],\n",
    "CASE WHEN [Shift]='OFF' then 0 else 1 end as [Headcount]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]=DATEADD(DAY, -1,CAST(GETDATE() As Date)) and [Shift] not in ('OFF','Training','New Hire Training'))\n",
    "select [Date],[TL_Name],\n",
    "sum([Headcount]) as [Headcount],sum([ATD]) as [Present],sum([UPL-Not present at desk]) as [UPL-Not present at desk],\n",
    "sum([UnplanLeave]) as [UPL-Request within 7 days],sum([PlanLeave]) as [PlanLeave],\n",
    "case when sum([Headcount])=0 then 0 else sum([ATD])/sum([Headcount]) end as [Present%]\n",
    "from atd\n",
    "group by [Date],[TL_Name]\n",
    "order by case when sum([Headcount])=0 then 0 else sum([ATD])/sum([Headcount]) end asc\n",
    "\"\"\"\n",
    " \n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "atd_pivot_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "atd_pivot_df=atd_pivot_df.with_columns(pl.col(\"Date\").dt.to_string(\"%Y-%m-%d\"))\n",
    "atd_pivot_df=atd_pivot_df.to_pandas()\n",
    "atd_pivot_df['Present%'] = atd_pivot_df['Present%'].map('{:.2%}'.format)\n",
    "atd_pivot_df=pl.from_pandas(atd_pivot_df)\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_pivot_CSV = atd_pivot_df.write_excel(workbook=\"BKN_pivot_ATD_DF.xlsx\",worksheet=\"Sheet1\",\n",
    "                                           table_name='Frame0', table_style='Table Style Medium 2',autofit=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1012b368-4b36-4783-8dd6-7e05974bc484",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ATD MAIL Detail LINK ( Diliip xa ma)\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[week_shift],[Original_Shift] as [Shift],\n",
    "cast([CUICLoggedTime(s)] as float)/3600 as [CUIC Hrs],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [ATD],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END AS [NormalShift],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk],\n",
    "CASE WHEN [Shift]='OFF' then 0 else 1 end as [Headcount],cast([OT_Registered(s)] as float)/3600 as [OT],[Ramco_Code] as [RAMCO],\n",
    "CASE WHEN [ScheduleHours(H)]>0 THEN 1 ELSE 0 END AS [Schedule Agents],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9 WHEN [ScheduleHours(H)]>0 THEN 4 ELSE 0 END AS [Schedule Hours],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9+cast([OT_Registered(s)] as float)/3600 \n",
    "WHEN [ScheduleHours(H)]>0 THEN 4+cast([OT_Registered(s)] as float)/3600 ELSE 0 END AS [Schedule+OT],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 9 WHEN [SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Unplanned Lost Hrs],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 9 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Planned Lost Hrs]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]>DATEADD(DAY, -60,CAST(GETDATE() As Date))\n",
    "order by [Date] desc\n",
    "\"\"\"\n",
    " \n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "atd_mail_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_mail_CSV = atd_mail_df.write_excel(workbook=\"BKN_ATD_Mail.xlsx\",worksheet=\"Sheet1\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1b786af-bf9f-42f0-a127-e730512f7c3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ATD Mail PIVOT 1 Overall (Dillip team)\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "with ATD as (\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[week_shift],[Original_Shift] as [Shift],\n",
    "cast([CUICLoggedTime(s)] as float)/3600 as [CUIC Hrs],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [ATD],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END AS [NormalShift],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk],\n",
    "CASE WHEN [Shift]='OFF' then 0 else 1 end as [Headcount],cast([OT_Registered(s)] as float)/3600 as [OT],[Ramco_Code] as [RAMCO],\n",
    "CASE WHEN [ScheduleHours(H)]>0 THEN 1 ELSE 0 END AS [Schedule Agents],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9 WHEN [ScheduleHours(H)]>0 THEN 4 ELSE 0 END AS [Schedule Hours],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9+cast([OT_Registered(s)] as float)/3600 \n",
    "WHEN [ScheduleHours(H)]>0 THEN 4+cast([OT_Registered(s)] as float)/3600 ELSE 0 END AS [Schedule+OT],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 9 WHEN [SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Unplanned Lost Hrs],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 9 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Planned Lost Hrs]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]>=DATEADD(DAY, -2,CAST(GETDATE() As Date)) and [Date]<=DATEADD(DAY, 0,CAST(GETDATE() As Date)))\n",
    "select [Date],sum([Schedule Agents]) as [Schedule Agents],sum([Schedule Hours]) as [Schedule Hours],\n",
    "sum([OT]) as [OT],sum([Schedule+OT]) as [Schedule+OT],sum([Unplanned Lost Hrs]) as [Unplanned Lost Hrs],\n",
    "sum([Planned Lost Hrs]) as [Planned Lost Hrs],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs])/sum([Schedule+OT]) end as [Unplanned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Planned Lost Hrs])/sum([Schedule+OT]) end as [Planned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Overall AR %],\n",
    "1-case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Attendance %]\n",
    "from ATD\n",
    "group by [Date]\n",
    "\"\"\"\n",
    " \n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "atd_pivot1_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "atd_pivot1_df=atd_pivot1_df.with_columns(pl.col(\"Date\").dt.to_string(\"%Y-%m-%d\"))\n",
    "atd_pivot1_df=atd_pivot1_df.to_pandas()\n",
    "atd_pivot1_df['Unplanned AR%'] = atd_pivot1_df['Unplanned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot1_df['Planned AR%'] = atd_pivot1_df['Planned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot1_df['Overall AR %'] = atd_pivot1_df['Overall AR %'].map('{:.2%}'.format)\n",
    "atd_pivot1_df['Attendance %'] = atd_pivot1_df['Attendance %'].map('{:.2%}'.format)\n",
    "atd_pivot1_df['OT'] = atd_pivot1_df['OT'].fillna(0)\n",
    "atd_pivot1_df['OT'] = atd_pivot1_df['OT'].astype(\"int64\")\n",
    "atd_pivot1_df['Schedule+OT'] = atd_pivot1_df['Schedule+OT'].fillna(0)\n",
    "atd_pivot1_df['Schedule+OT'] = atd_pivot1_df['Schedule+OT'].astype(\"int64\")\n",
    "\n",
    "atd_pivot1_df=pl.from_pandas(atd_pivot1_df)\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_pivot1_CSV = atd_pivot1_df.write_excel(workbook=\"BKN_ATD_pivot_1.xlsx\",worksheet=\"Sheet1\",\n",
    "                                           table_name='Table1', table_style='Table Style Medium 2',autofit=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "646dd65a-e60e-4152-baa3-bf9501c0c303",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ATD Mail PIVOT 2 By LOB (Dillip team)\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "with ATD as (\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[week_shift],[Original_Shift] as [Shift],\n",
    "cast([CUICLoggedTime(s)] as float)/3600 as [CUIC Hrs],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [ATD],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END AS [NormalShift],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk],\n",
    "CASE WHEN [Shift]='OFF' then 0 else 1 end as [Headcount],cast([OT_Registered(s)] as float)/3600 as [OT],[Ramco_Code] as [RAMCO],\n",
    "CASE WHEN [ScheduleHours(H)]>0 THEN 1 ELSE 0 END AS [Schedule Agents],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9 WHEN [ScheduleHours(H)]>0 THEN 4 ELSE 0 END AS [Schedule Hours],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9+cast([OT_Registered(s)] as float)/3600 \n",
    "WHEN [ScheduleHours(H)]>0 THEN 4+cast([OT_Registered(s)] as float)/3600 ELSE 0 END AS [Schedule+OT],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 9 WHEN [SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Unplanned Lost Hrs],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 9 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Planned Lost Hrs]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]=DATEADD(DAY, 0,CAST(GETDATE() As Date)))\n",
    "select [Date],[LOB],sum([Schedule Agents]) as [Schedule Agents],sum([Schedule Hours]) as [Schedule Hours],\n",
    "sum([OT]) as [OT],sum([Schedule+OT]) as [Schedule+OT],sum([Unplanned Lost Hrs]) as [Unplanned Lost Hrs],\n",
    "sum([Planned Lost Hrs]) as [Planned Lost Hrs],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs])/sum([Schedule+OT]) end as [Unplanned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Planned Lost Hrs])/sum([Schedule+OT]) end as [Planned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Overall AR %],\n",
    "1-case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Attendance %]\n",
    "from ATD\n",
    "group by [Date],[LOB]\n",
    "\"\"\"\n",
    " \n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "atd_pivot2_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "atd_pivot2_df=atd_pivot2_df.with_columns(pl.col(\"Date\").dt.to_string(\"%Y-%m-%d\"))\n",
    "atd_pivot2_df=atd_pivot2_df.to_pandas()\n",
    "atd_pivot2_df['Unplanned AR%'] = atd_pivot2_df['Unplanned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot2_df['Planned AR%'] = atd_pivot2_df['Planned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot2_df['Overall AR %'] = atd_pivot2_df['Overall AR %'].map('{:.2%}'.format)\n",
    "atd_pivot2_df['Attendance %'] = atd_pivot2_df['Attendance %'].map('{:.2%}'.format)\n",
    "atd_pivot2_df['OT'] = atd_pivot2_df['OT'].fillna(0)\n",
    "atd_pivot2_df['OT'] = atd_pivot2_df['OT'].astype(\"int64\")\n",
    "atd_pivot2_df['Schedule+OT'] = atd_pivot2_df['Schedule+OT'].fillna(0)\n",
    "atd_pivot2_df['Schedule+OT'] = atd_pivot2_df['Schedule+OT'].astype(\"int64\")\n",
    "\n",
    "atd_pivot2_df=pl.from_pandas(atd_pivot2_df)\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_pivot2_CSV = atd_pivot2_df.write_excel(workbook=\"BKN_ATD_pivot_2.xlsx\",worksheet=\"Sheet1\",\n",
    "                                           table_name='Table1', table_style='Table Style Medium 2',autofit=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aad78067-afb7-46fc-a7e6-27f10aa56989",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ATD Mail PIVOT 3 BY TL (Dillip team)\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "with ATD as (\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[week_shift],[Original_Shift] as [Shift],\n",
    "cast([CUICLoggedTime(s)] as float)/3600 as [CUIC Hrs],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [ATD],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END AS [NormalShift],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk],\n",
    "CASE WHEN [Shift]='OFF' then 0 else 1 end as [Headcount],cast([OT_Registered(s)] as float)/3600 as [OT],[Ramco_Code] as [RAMCO],\n",
    "CASE WHEN [ScheduleHours(H)]>0 THEN 1 ELSE 0 END AS [Schedule Agents],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9 WHEN [ScheduleHours(H)]>0 THEN 4 ELSE 0 END AS [Schedule Hours],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9+cast([OT_Registered(s)] as float)/3600 \n",
    "WHEN [ScheduleHours(H)]>0 THEN 4+cast([OT_Registered(s)] as float)/3600 ELSE 0 END AS [Schedule+OT],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 9 WHEN [SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Unplanned Lost Hrs],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 9 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Planned Lost Hrs]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]=DATEADD(DAY, 0,CAST(GETDATE() As Date)))\n",
    "select [Date],[TL_Name],sum([Schedule Agents]) as [Schedule Agents],sum([Schedule Hours]) as [Schedule Hours],\n",
    "sum([OT]) as [OT],sum([Schedule+OT]) as [Schedule+OT],sum([Unplanned Lost Hrs]) as [Unplanned Lost Hrs],\n",
    "sum([Planned Lost Hrs]) as [Planned Lost Hrs],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs])/sum([Schedule+OT]) end as [Unplanned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Planned Lost Hrs])/sum([Schedule+OT]) end as [Planned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Overall AR %],\n",
    "1-case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Attendance %]\n",
    "from ATD\n",
    "group by [Date],[TL_Name]\n",
    "\"\"\"\n",
    " \n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "atd_pivot3_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "atd_pivot3_df=atd_pivot3_df.with_columns(pl.col(\"Date\").dt.to_string(\"%Y-%m-%d\"))\n",
    "atd_pivot3_df=atd_pivot3_df.to_pandas()\n",
    "atd_pivot3_df['Unplanned AR%'] = atd_pivot3_df['Unplanned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot3_df['Planned AR%'] = atd_pivot3_df['Planned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot3_df['Overall AR %'] = atd_pivot3_df['Overall AR %'].map('{:.2%}'.format)\n",
    "atd_pivot3_df['Attendance %'] = atd_pivot3_df['Attendance %'].map('{:.2%}'.format)\n",
    "atd_pivot3_df['OT'] = atd_pivot3_df['OT'].fillna(0)\n",
    "atd_pivot3_df['OT'] = atd_pivot3_df['OT'].astype(\"int64\")\n",
    "atd_pivot3_df['Schedule+OT'] = atd_pivot3_df['Schedule+OT'].fillna(0)\n",
    "atd_pivot3_df['Schedule+OT'] = atd_pivot3_df['Schedule+OT'].astype(\"int64\")\n",
    "\n",
    "atd_pivot3_df=pl.from_pandas(atd_pivot3_df)\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_pivot3_CSV = atd_pivot3_df.write_excel(workbook=\"BKN_ATD_pivot_3.xlsx\",worksheet=\"Sheet1\",\n",
    "                                           table_name='Table1', table_style='Table Style Medium 2',autofit=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6b2c9e4-35ce-401d-b433-2940fa2c8b74",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #Import table##EEAAO\n",
    "# # C√¢u l·ªánh SQL\n",
    "# sql_query_raw = \"\"\"\n",
    "\n",
    "# SELECT  [YEAR] as [year],[MONTH] as [month],[Date] as [date],[Week_num] as [weeknum],[Week_day] as [weekday],[Emp ID] as [eid],\n",
    "# [TED Name] as [agent],[Wave] as [wave],[Tenure] as [tenure],[TL_Name] as [teamlead],[OM_Name] as [om],[DPE_Name] as [dpe],\n",
    "# [Shift] as [shift],[Shift_definition] as [shift_definition],[Shift_type] as [shift_type],[LOB] as [lob],[week_off] as [weekoff],\n",
    "# [Csat Score] as [csat_score],[Csat Survey] as [csat_survey],[Psat_survey] as [psat_score],[Psat_Score] as [psat_survey],\n",
    "# [Total_Cases] as [total_cases],cast([Productive(s)] as float) /3600 as [productive_hours],\n",
    "# cast([Downtime(s)] as float)/3600 as [downtime_hours],[Overall_AHT_Time] as [handling_time],[Overall_AHT_Count] as [handling_cases],\n",
    "# cast ([OT_Registered(s)] as float)/3600 as [ot_registered],[Late-Soon] as [late_soon],[customer_score]+[business_score]+[compliance_score] as [quality_score],\n",
    "# [customer_weight]+[business_weight]+[compliance_weight] as [quality_weight],\n",
    "# case when [Termination/Transfer] is null then 0 else 1 end as [resign],\n",
    "# cast ([StaffTime(s)] as float)/3600 as [stafftime],cast ([ScheduleSeconds(s)] as float)/3600 as [schedule_hours]\n",
    "# FROM BCOM.EEAAO\n",
    "# where [Date] >='2025-01-01'\n",
    "# Order by [Emp ID],[Date] DESC;\n",
    "\n",
    "# \"\"\"\n",
    "# sql_query=text(sql_query_raw)\n",
    "# # ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "# eeaao_df = pl.read_database(query=sql_query, connection=engine)\n",
    "# engine.dispose()\n",
    "# # Export to CSV\n",
    "# os.chdir(eeaao)\n",
    "# eeaao_CSV = eeaao_df.write_excel(workbook=\"EEAAO_MODEL.xlsx\",worksheet=\"Query1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16050cfd-3c4e-45bf-8753-ccb82dd3b4ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ATTRITION\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "SET DATEFIRST 1;\n",
    "WITH\n",
    "ROSTER_RAW AS ( --IMPORT BCOM.ROSTER\n",
    "\n",
    "SELECT [Emp ID], [Attribute], [Value], [LOB], [team_leader], [week_shift], [week_off], [OM], [DPE] FROM BCOM.ROSTER \n",
    "\n",
    "),\n",
    "\n",
    "Staff_RAW AS ( --IMPORT BCOM.Staff\n",
    "\n",
    "SELECT [Employee_ID], [Wave #], [Role], [Booking Login ID], [Language Start Date], [TED Name], [CUIC Name], [EnterpriseName], [Hire_Date], [PST_Start_Date], [Production_Start_Date], [Designation], [cnx_email], [Booking Email], [Full name], [IEX], [serial_number], [BKN_ID], [Extension Number] FROM BCOM.Staff \n",
    "\n",
    "),\n",
    "\n",
    "RAMCO_RAW AS ( --IMPORT GLB.RAMCO\n",
    "\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code], \n",
    "\n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define] \n",
    "\n",
    "FROM GLB.RAMCO \n",
    "\n",
    "),\n",
    "\n",
    "ROSTER_RAW2 AS ( --IMPORT BCOM.ROSTER 2\n",
    "\n",
    "SELECT\n",
    "\n",
    "\tROSTER_RAW.[Emp ID], ROSTER_RAW.[Attribute] AS [Date], \n",
    "\n",
    "\tROSTER_RAW.[Value] AS [Original_Shift], ROSTER_RAW.[LOB], ROSTER_RAW.[team_leader], ROSTER_RAW.[week_shift], \n",
    "\n",
    "\tROSTER_RAW.[week_off], ROSTER_RAW.[OM], ROSTER_RAW.[DPE],\n",
    "\n",
    "\tCASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END AS [Shift],\n",
    "\n",
    "\tCASE \n",
    "\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('OFF', 'AL', 'CO', 'HO', 'UPL', 'VGH') THEN 'OFF'\n",
    "\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('Training', 'PEGA') THEN 'Training'\n",
    "\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\n",
    "\t\t\tELSE Null END AS [Shift_type]\n",
    "\n",
    "FROM ROSTER_RAW\n",
    "\n",
    "LEFT JOIN RAMCO_RAW ON ROSTER_RAW.[Emp ID] = RAMCO_RAW.[EID] AND ROSTER_RAW.[Attribute] = RAMCO_RAW.[Date] \n",
    "\n",
    "),\n",
    "\n",
    "TRANSFER_RAW AS ( --IMPORT BCOM.LTTransfers\n",
    "\n",
    "SELECT [EID], [LWD], [Remarks] \n",
    "\n",
    "FROM BCOM.LTTransfers\n",
    "\n",
    "),\n",
    "\n",
    "TERMINATION_RAW AS ( --IMPORT GLB.Termination\n",
    "\n",
    "SELECT [EMPLOYEE_ID], [LWD], [Termination Reason] \n",
    "\n",
    "FROM GLB.Termination \n",
    "\n",
    "WHERE [Client Name ( Process )] = 'Bookingcom' And [JOB_ROLE] = 'Agent' And [COUNTRY] = 'Vietnam'\n",
    "\n",
    "),\n",
    "\n",
    "RESIGNATION_RAW AS ( --IMPORT GLB.Resignation 1 (RAW)\n",
    "\n",
    "SELECT [Employee ID], [Proposed Termination Date], [Resignation Primary Reason] \n",
    "\n",
    "FROM GLB.Resignation \n",
    "\n",
    "WHERE [MSA Client] = 'Bookingcom' And [Job Family] = 'Contact Center' And [Country] = 'Vietnam'\n",
    "\n",
    "),\n",
    "\n",
    "--IMPORT TL,OM,DPE\n",
    "\n",
    "TL_RAW AS (SELECT [Employee_ID],[TED Name] AS [TL_Name] FROM BCOM.Staff),\n",
    "\n",
    "OM_RAW AS (SELECT [Employee_ID],[TED Name] AS [OM_Name] FROM BCOM.Staff),\n",
    "\n",
    "DPE_RAW AS (SELECT [Employee_ID],[TED Name] AS [DPE_Name] FROM BCOM.Staff),\n",
    "\n",
    "ROSTER_RAW3 AS ( --IMPORT BCOM.ROSTER 3\n",
    "\n",
    "SELECT\n",
    "\n",
    "ROSTER_RAW2.[Shift], ROSTER_RAW2.[Shift_type], ROSTER_RAW2.[Original_Shift], ROSTER_RAW2.[LOB], ROSTER_RAW2.[week_shift], ROSTER_RAW2.[week_off], \n",
    "\n",
    "ROSTER_RAW2.[team_leader] AS [TL_ID], TL_RAW.[TL_Name], ROSTER_RAW2.[OM] AS [OM_ID], OM_RAW.[OM_Name], ROSTER_RAW2.[DPE] AS [DPE_ID], DPE_RAW.[DPE_Name],\n",
    "\n",
    "COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) AS [Emp ID], Staff_RAW.[Full name] AS [Emp_Name], \n",
    "\n",
    "Staff_RAW.[Wave #] AS [Wave], Staff_RAW.[Booking Login ID], Staff_RAW.[TED Name], Staff_RAW.[cnx_email], Staff_RAW.[Booking Email], Staff_RAW.[CUIC Name], Staff_RAW.[PST_Start_Date],\n",
    "\n",
    "COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]) AS [Date],\n",
    "\n",
    "CASE \n",
    "\n",
    "    WHEN DATEDIFF(day, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) >= 90 THEN 'TN'\n",
    "\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined' \n",
    "\n",
    "    ELSE 'NH' END AS [Tenure],\n",
    "\n",
    "CASE \n",
    "\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 30 THEN '00-30'\n",
    "\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 60 THEN '31-60'\n",
    "\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 90 THEN '61-90'\n",
    "\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 120 THEN '91-120'\n",
    "\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 120 THEN '120+'\n",
    "\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined'\n",
    "\n",
    "    ELSE 'Undefined' END AS [Tenure days],\n",
    "\n",
    "CASE \n",
    "\n",
    "\tWHEN FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00') < 3 AND MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 10\n",
    "\n",
    "\tTHEN CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]))+1, FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\n",
    "\tELSE CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])), FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\n",
    "\tEND AS [Week_num],\n",
    "\n",
    "CASE\n",
    "\n",
    "WHEN ROSTER_RAW2.[Shift] IN (\n",
    "\n",
    "'0000-0900','0100-1000','0200-1100','0300-1200','0400-1300','0500-1400','0600-1500','0700-1600','0800-1700','0900-1800','1000-1900','1100-2000',\n",
    "\n",
    "'1200-2100','1300-2200','1400-2300','1500-0000','1600-0100','1700-0200','1800-0300','1900-0400','2000-0500','2100-0600','2200-0700','2300-0800'\n",
    "\n",
    ",'HAL','Training','DOWNTIME','PEGA','New Hire Training'\n",
    "\n",
    ") THEN 'WORK'\n",
    "\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('AL', 'CO', 'VGH','HO') THEN 'Planned leave'\n",
    "\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('UPL') THEN 'Unplanned leave' ELSE NULL END AS [Shift_definition],\n",
    "\n",
    "YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [YEAR],\n",
    "\n",
    "MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [MONTH],\n",
    "\n",
    "DATENAME(weekday, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [Week_day],\n",
    "\n",
    "COALESCE(TRANSFER_RAW.[Remarks], TERMINATION_RAW.[Termination Reason], RESIGNATION_RAW.[Resignation Primary Reason]) AS [Termination/Transfer],\n",
    "\n",
    "CASE \n",
    "\n",
    "    WHEN ROSTER_RAW2.[LOB] IN ('NL', 'ID4', 'HE4', 'XT4', 'EL', 'TR', 'KO', 'IT', 'CS', 'HU', 'FR', 'ZH', 'RU', 'PL', 'PT', 'NO', 'DA', 'DE', 'RO') THEN 'Unbabel'\n",
    "\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'EN' THEN 'English'\n",
    "\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSP' THEN 'Vietnamese CSP'\n",
    "\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSG' THEN 'Vietnamese CSG'\n",
    "\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'Senior VICSP' THEN 'Senior VICSP'\n",
    "\n",
    "    ELSE 'Undefined' END AS [LOB Group],\n",
    "\n",
    "-- Set up ScheduleSeconds(s)\n",
    "\n",
    "CASE\n",
    "\n",
    "    WHEN CHARINDEX('-', ROSTER_RAW2.[Original_Shift]) = 5 OR ROSTER_RAW2.[Original_Shift] IN ('UPL', 'PEGA') THEN 9 * 3600\n",
    "\n",
    "    WHEN ROSTER_RAW2.[Original_Shift] IN ('HAL', 'HSL') THEN 4 * 3600\n",
    "\n",
    "    ELSE 0\n",
    "\n",
    "END AS [ScheduleSeconds(s)]\n",
    "\n",
    "FROM ROSTER_RAW2\n",
    "\n",
    "FULL JOIN TRANSFER_RAW ON ROSTER_RAW2.[Emp ID] = TRANSFER_RAW.[EID] And ROSTER_RAW2.[Date] = TRANSFER_RAW.[LWD]\n",
    "\n",
    "FULL JOIN TERMINATION_RAW ON ROSTER_RAW2.[Emp ID] = TERMINATION_RAW.[EMPLOYEE_ID] And ROSTER_RAW2.[Date] = TERMINATION_RAW.[LWD]\n",
    "\n",
    "FULL JOIN RESIGNATION_RAW ON ROSTER_RAW2.[Emp ID] = RESIGNATION_RAW.[Employee ID] And ROSTER_RAW2.[Date] = RESIGNATION_RAW.[Proposed Termination Date]\n",
    "\n",
    "LEFT JOIN TL_RAW ON ROSTER_RAW2.[team_leader] = TL_RAW.[Employee_ID]\n",
    "\n",
    "LEFT JOIN OM_RAW ON ROSTER_RAW2.[OM] = OM_RAW.[Employee_ID]\n",
    "\n",
    "LEFT JOIN DPE_RAW ON ROSTER_RAW2.[DPE] = DPE_RAW.[Employee_ID]\n",
    "\n",
    "LEFT JOIN Staff_RAW ON COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) = Staff_RAW.[Employee_ID])\n",
    ",\n",
    "EEAAO as (\n",
    "select [Date],[Emp ID],[Termination/Transfer],[TL_ID],[OM_ID],[DPE_ID]\n",
    "from ROSTER_RAW3),\n",
    "\n",
    "RankedData as (\n",
    "\tSELECT \n",
    "        [Attribute] AS [Date],[Emp ID],[team_leader],[OM],[DPE],ROW_NUMBER() OVER (PARTITION BY [Emp ID] ORDER BY [Attribute] DESC) AS rn\n",
    "    FROM \n",
    "        BCOM.ROSTER),\n",
    "SCHE as (\n",
    "\tSELECT [Date],[Emp ID],[team_leader],[OM],[DPE]\n",
    "\tFROM RankedData\n",
    "\tWHERE \n",
    "\t\trn = 1),\n",
    "\n",
    "MiniTer as (\n",
    "select [EMPLOYEE_ID],[SUPERVISOR_ID]\n",
    "from GLB.Termination\n",
    "where [COUNTRY]='Vietnam' and [Client Name ( Process )]='Bookingcom' ),\n",
    "\n",
    "EmpMaster as (\n",
    "select [EMPLOYEE_NUMBER],[SUPERVISOR_ID],[MANAGER_02_ID],[SUPERVISOR_FULL_NAME],[MANAGER_02_FULL_NAME]\n",
    "from GLB.EmpMaster\n",
    "where [MSA Client]='Bookingcom' and [Country]='Vietnam'),\n",
    "\n",
    "TER as (\n",
    "select MiniTer.[EMPLOYEE_ID], max(COALESCE(MiniTer.[SUPERVISOR_ID], SCHE.[team_leader], EmpMaster.[SUPERVISOR_ID])) As [TeamLead],\n",
    "max(COALESCE(EmpMaster.[SUPERVISOR_ID],SCHE.[OM])) As [OM], max(SCHE.[DPE]) as [DPE] from MiniTer\n",
    "left join SCHE on MiniTer.[SUPERVISOR_ID]=SCHE.[team_leader]\n",
    "left join EmpMaster on MiniTer.[SUPERVISOR_ID]=EmpMaster.[EMPLOYEE_NUMBER]\n",
    "group by MiniTer.[EMPLOYEE_ID]),\n",
    "\n",
    "MiniRESIGN as (\n",
    "select [Employee ID],[Sup ID]\n",
    "from GLB.Resignation\n",
    "where [MSA Client]='Bookingcom' and Country='Vietnam'),\n",
    "RESIGN as (\n",
    "select MiniRESIGN.[Employee ID], max(COALESCE(MiniRESIGN.[Sup ID], SCHE.[team_leader], EmpMaster.[SUPERVISOR_ID])) As [TeamLead],\n",
    "max(COALESCE(EmpMaster.[SUPERVISOR_ID],SCHE.[OM])) As [OM],max(SCHE.[DPE]) as [DPE]\n",
    "from MiniRESIGN\n",
    "left join SCHE on MiniRESIGN.[Sup ID]=SCHE.[team_leader]\n",
    "left join EmpMaster on MiniRESIGN.[Sup ID]=EmpMaster.[EMPLOYEE_NUMBER]\n",
    "group by MiniRESIGN.[Employee ID]),\n",
    "TERMINATE as (\n",
    "select EEAAO.[Emp ID],EEAAO.[Date],EEAAO.[Termination/Transfer],\n",
    "COALESCE( TER.[TeamLead],RESIGN.[TeamLead],EEAAO.[TL_ID],SCHE.[team_leader]) as [TEAMLEADER],\n",
    "COALESCE( TER.[OM],RESIGN.[OM],EEAAO.[OM_ID],SCHE.[OM]) as [OM],\n",
    "COALESCE( TER.[DPE],RESIGN.[DPE],EEAAO.[DPE_ID],SCHE.[DPE]) as [DPE]\n",
    " from EEAAO\n",
    "left join SCHE on EEAAO.[Emp ID]=SCHE.[Emp ID]\n",
    "left join TER on EEAAO.[Emp ID]=TER.[EMPLOYEE_ID]\n",
    "left join RESIGN on EEAAO.[Emp ID]=RESIGN.[Employee ID]),\n",
    "MR_Emp as (\n",
    "select [Employee_ID],[TED Name] as [Agents Name] from BCOM.Staff\n",
    "),\n",
    "MR_TL as (\n",
    "select [Employee_ID],[TED Name] as [TL Name] from BCOM.Staff\n",
    "),\n",
    "MR_OM as (\n",
    "select [Employee_ID],[TED Name] as [OM Name] from BCOM.Staff\n",
    "),\n",
    "MR_DPE as (\n",
    "select [Employee_ID],[TED Name] as [DPE Name] from BCOM.Staff\n",
    ")\n",
    ",\n",
    "Attrition as (\n",
    "select TERMINATE.[Emp ID],TERMINATE.[Date],TERMINATE.[Termination/Transfer],MR_Emp.[Agents Name],TERMINATE.[TEAMLEADER],MR_TL.[TL Name],\n",
    "TERMINATE.[OM],MR_OM.[OM Name],TERMINATE.[DPE],MR_DPE.[DPE Name],\n",
    "DATEADD(day, 1 - DATEPART(weekday, TERMINATE.[Date]), TERMINATE.[Date]) AS [Week 2]\n",
    "from TERMINATE\n",
    "left join MR_Emp on TERMINATE.[Emp ID]=MR_Emp.[Employee_ID]\n",
    "left join MR_TL on TERMINATE.[TEAMLEADER]=MR_TL.[Employee_ID]\n",
    "left join MR_OM on TERMINATE.[OM]=MR_OM.[Employee_ID]\n",
    "left join MR_DPE on TERMINATE.[DPE]=MR_DPE.[Employee_ID]\n",
    "where TERMINATE.[Date]>=DATEADD(DAY, -730,CAST(GETDATE() As Date)) and (left(TERMINATE.[Termination/Transfer],7) <> 'Lateral' or TERMINATE.[Termination/Transfer] is null) )\n",
    "select * from Attrition\n",
    "\"\"\"\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "\n",
    "attrition_df = pl.read_database(query=sql_query, connection=engine)\n",
    "\n",
    "engine.dispose()\n",
    "\n",
    "# Export to CSV\n",
    "\n",
    "os.chdir(DF_ATTRITION)\n",
    "\n",
    "attrition_df_CSV = attrition_df.write_csv(\"BKN_ATTRITION.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e471024-c556-4bbe-a56a-4c8d8c8420dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]ATD MM Detail linküé°\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "WITH\n",
    "-- Create GLB.OT_RAMCO 1 (RAW)\n",
    "OTRAMCO_RAW AS (  --Setup OTRamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [OT_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] in ('OT1.0X','OT1.5X','OT2.0X','OT2.1X','OT2.5X','OT2.7X') And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "PHRAMCO_RAW AS (  --Setup PHRamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [PH_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] in ('OT3.0X','OT3.9X','OT4.0X') And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "NSARAMCO_RAW AS (  --Setup NSARamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [NSA_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] = 'NSA' And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "-- Create GLB.RAMCO 1 (RAW)\n",
    "RAMCO_RAW AS ( \n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define] \n",
    "FROM GLB.RAMCO \n",
    "),\n",
    "-- Create RAMCO Pre1 (RAW)\n",
    "RAMCO_RAW_Pre1 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre1], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre1] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create BCOM.RegisteredOT (RAW)\n",
    "RegisteredOT_RAW AS (\n",
    "SELECT [Date], [Emp ID], [OT]*3600 AS [OT_Registered(s)], [Type] AS [OT_Registered_Type] FROM BCOM.RegisteredOT\n",
    "),\n",
    "-- Create RAMCO Pre2 (RAW)\n",
    "RAMCO_RAW_Pre2 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre2], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre2] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre3 (RAW)\n",
    "RAMCO_RAW_Pre3 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre3], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre3] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre4 (RAW)\n",
    "RAMCO_RAW_Pre4 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre4], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre4] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre5 (RAW)\n",
    "RAMCO_RAW_Pre5 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre5], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre5] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre6 (RAW)\n",
    "RAMCO_RAW_Pre6 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre6], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre6] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create GLB.PremHdays 1 (RAW)\n",
    "PremHday_RAW AS ( SELECT [Date],[Holiday] FROM GLB.PremHdays \n",
    "),\n",
    "-- Create BCOM.ROSTER 1 (RAW)\n",
    "ROSTER_RAW AS ( SELECT [Emp ID], [Attribute], [Value], [LOB], [team_leader], [week_shift], [week_off], [OM], [DPE] FROM BCOM.ROSTER \n",
    "),\n",
    "-- Create ROSTER(n-1) 1 (RAW)\n",
    "ROSTER_Pre1_RAW AS ( SELECT [Emp ID], [Attribute] AS [Date-1], [Value], [LOB], [team_leader], [week_shift], [week_off], [OM], [DPE] FROM BCOM.ROSTER \n",
    "),\n",
    "-- Create BCOM.LTTransfers 1 (RAW)\n",
    "TRANSFER_RAW AS (      \n",
    "SELECT [EID], [LWD], [Remarks] \n",
    "FROM BCOM.LTTransfers\n",
    "),\n",
    "-- Create BCOM.ExceptionReq 1 (RAW)\n",
    "ExceptionReq_RAW AS (\n",
    "SELECT [Date (MM/DD/YYYY)] AS [Date], [Emp ID], SUM([Exception request (Minute)]*60) AS [Req_Second] FROM BCOM.ExceptionReq\n",
    "WHERE [OM] = 'Approve' \n",
    "GROUP BY [Date (MM/DD/YYYY)],[Emp ID] \n",
    "),\n",
    "-- Create GLB.Termination 1 (RAW)\n",
    "TERMINATION_RAW AS (   \n",
    "SELECT [EMPLOYEE_ID], [LWD], [Termination Reason] \n",
    "FROM GLB.Termination \n",
    "WHERE [Client Name ( Process )] = 'Bookingcom' And [JOB_ROLE] = 'Agent' And [COUNTRY] = 'Vietnam'\n",
    "),\n",
    "-- Create GLB.Resignation 1 (RAW)\n",
    "RESIGNATION_RAW AS (   \n",
    "SELECT [Employee ID], [Proposed Termination Date], [Resignation Primary Reason] \n",
    "FROM GLB.Resignation \n",
    "WHERE [MSA Client] = 'Bookingcom' And [Job Family] = 'Contact Center' And [Country] = 'Vietnam'\n",
    "),\n",
    "-- Create BCOM.EPS 1 (RAW)\n",
    "EPS_RAW AS ( \n",
    "SELECT [Username], [Session Login], [Session Logout], [Session Time], [BPE Code], [Total Time], [SessionLogin_VN], CAST([SessionLogin_VN] AS DATE) AS [Date_Login_VN], DATEADD(DAY, -1, CAST([SessionLogin_VN] AS DATE)) AS [PreviousDate_Login_VN], CAST([SessionLogin_VN] AS TIME) AS [Time_Login_VN], [SessionLogout_VN], CAST([SessionLogout_VN] AS DATE) AS [Date_Logout_VN], CAST([SessionLogout_VN] AS TIME) AS [Time_Logout_VN], [NightTime], [DayTime], [Night_BPE], [Day_BPE] FROM BCOM.EPS \n",
    "),\n",
    "-- Create BCOM.Staff 1 (RAW)\n",
    "Staff_RAW AS ( \n",
    "SELECT [Employee_ID], [Wave #], [Role], [Booking Login ID], [Language Start Date], [TED Name], [CUIC Name], [EnterpriseName], [Hire_Date], [PST_Start_Date], [Production_Start_Date], [Designation], [cnx_email], [Booking Email], [Full name], [IEX], [serial_number], [BKN_ID], [Extension Number] FROM BCOM.Staff \n",
    "),\n",
    "-- Create TL,OM,DPE 1 (RAW)\n",
    "TL_RAW AS (SELECT [Employee_ID],[TED Name] AS [TL_Name] FROM BCOM.Staff),\n",
    "OM_RAW AS (SELECT [Employee_ID],[TED Name] AS [OM_Name] FROM BCOM.Staff),\n",
    "DPE_RAW AS (SELECT [Employee_ID],[TED Name] AS [DPE_Name] FROM BCOM.Staff),\n",
    "-- Create BCOM.CPI_PEGA 1 (RAW)\n",
    "CPI_PEGA_RAW AS ( \n",
    "SELECT \n",
    "[Staff Name], [Operator Def], [Service Case Type New], [Channel Def], [Lang Def], [Reason For No Service Case], \n",
    "[Topic Def New], [Subtopics], [Case Id], [Reservation Id Def], [Day of Date] AS [Date], [# Swivels], [Count of ServiceCase or Interaction],\n",
    "CASE \n",
    "WHEN [# Swivels] > 0 THEN 'PEGA Swiveled to TED'\n",
    "ELSE 'PEGA' END AS [CRM]\n",
    "FROM BCOM.CPI_PEGA \n",
    "WHERE [Count of ServiceCase or Interaction] > 0\n",
    "),\n",
    "-- Create BCOM.CPI 1 (RAW)\n",
    "CPI_RAW AS ( \n",
    "SELECT \n",
    "BCOM.CPI.[Date], BCOM.CPI.[Staff Name], BCOM.CPI.[Hour Interval Selected], \n",
    "BCOM.CPI.[Channel], BCOM.CPI.[Item Label], BCOM.CPI.[Item ID], BCOM.CPI.['Item ID'], BCOM.CPI.[Time Alert], \n",
    "BCOM.CPI.[Nr. Contacts], 'TED' AS [CRM]\n",
    "FROM BCOM.CPI \n",
    "LEFT JOIN CPI_PEGA_RAW ON CPI_PEGA_RAW.[Staff Name] = BCOM.CPI.[Staff Name] AND CPI_PEGA_RAW.[Date] = BCOM.CPI.[Date] AND CPI_PEGA_RAW.[Reservation Id Def] = BCOM.CPI.[Item ID]\n",
    "WHERE CPI_PEGA_RAW.[Reservation Id Def] IS NULL\n",
    "),\n",
    "-- Create BCOM.LogoutCount 1 (RAW)\n",
    "LogoutCount_RAW AS (\n",
    "SELECT [Aggregation] AS [TED_Name], [TimeDimension] AS [Date], SUM([KPI Value Formatted]) AS [Logout_Count] FROM BCOM.LogoutCount GROUP BY [Aggregation], [TimeDimension]\n",
    "),\n",
    "-- Create BCOM.PSAT 1 (RAW)\n",
    "PSAT_RAW AS (\n",
    "SELECT \n",
    "[Sorted By Dimension] AS [Date], Staff_RAW.[Employee_ID], [Staff Name] AS [Staff], '' AS [Team], [Survey Id], [Hotel Id] AS [Reservation], [Channel], \n",
    "[Agent understood my question], [Agent did everything possible to help me], [Final Topics] AS [Topic of the first Ticket], [Language], 'PSAT' AS [CSAT/PSAT]\n",
    "From BCOM.PSAT\n",
    "LEFT JOIN Staff_RAW ON [Staff Name] = Staff_RAW.[TED Name]\n",
    "),\n",
    "-- Create BCOM.ROSTER 2 (Add: Shift)\n",
    "ROSTER_RAW2 AS (\n",
    "SELECT\n",
    "\tROSTER_RAW.[Emp ID], ROSTER_RAW.[Attribute] AS [Date], \n",
    "\tROSTER_RAW.[Value] AS [Original_Shift], ROSTER_RAW.[LOB], ROSTER_RAW.[team_leader], ROSTER_RAW.[week_shift], \n",
    "\tROSTER_RAW.[week_off], ROSTER_RAW.[OM], ROSTER_RAW.[DPE],\n",
    "\tCASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END AS [Shift],\n",
    "\tCASE \n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('OFF', 'AL', 'CO', 'HO', 'UPL', 'VGH') THEN 'OFF'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('Training', 'PEGA') THEN 'Training'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tELSE Null END AS [Shift_type]\n",
    "FROM ROSTER_RAW\n",
    "LEFT JOIN RAMCO_RAW ON ROSTER_RAW.[Emp ID] = RAMCO_RAW.[EID] AND ROSTER_RAW.[Attribute] = RAMCO_RAW.[Date] \n",
    "),\n",
    "-- Create ROSTER_Pre1_RAW 2 (Add: Shift_type)\n",
    "ROSTER_Pre1_RAW2 AS (\n",
    "SELECT\n",
    "\tROSTER_Pre1_RAW.[Emp ID], ROSTER_Pre1_RAW.[Date-1], \n",
    "\tROSTER_Pre1_RAW.[Value] AS [Original_Shift], ROSTER_Pre1_RAW.[LOB], ROSTER_Pre1_RAW.[team_leader], ROSTER_Pre1_RAW.[week_shift], \n",
    "\tROSTER_Pre1_RAW.[week_off], ROSTER_Pre1_RAW.[OM], ROSTER_Pre1_RAW.[DPE],\n",
    "\tCASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END AS [Shift],\n",
    "\tCASE \n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('OFF', 'AL', 'CO', 'HO', 'UPL', 'VGH') THEN 'OFF'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('Training', 'PEGA') THEN 'Training'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tWHEN ROSTER_Pre1_RAW.[week_shift] IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN ROSTER_Pre1_RAW.[week_shift] IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tELSE Null END AS [Shift_type]\n",
    "FROM ROSTER_Pre1_RAW\n",
    "LEFT JOIN RAMCO_RAW ON ROSTER_Pre1_RAW.[Emp ID] = RAMCO_RAW.[EID] AND ROSTER_Pre1_RAW.[Date-1] = RAMCO_RAW.[Date] \n",
    "),\n",
    "-- Create BCOM.ROSTER 3 (Add: [Termination/Transfer])\n",
    "ROSTER_RAW3 AS (\n",
    "SELECT\n",
    "ROSTER_RAW2.[Shift], ROSTER_RAW2.[Shift_type], ROSTER_RAW2.[Original_Shift], ROSTER_RAW2.[LOB], ROSTER_RAW2.[week_shift], ROSTER_RAW2.[week_off], \n",
    "ROSTER_RAW2.[team_leader] AS [TL_ID], TL_RAW.[TL_Name], ROSTER_RAW2.[OM] AS [OM_ID], OM_RAW.[OM_Name], ROSTER_RAW2.[DPE] AS [DPE_ID], DPE_RAW.[DPE_Name],\n",
    "COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) AS [Emp ID], Staff_RAW.[Full name] AS [Emp_Name], \n",
    "Staff_RAW.[Wave #] AS [Wave], Staff_RAW.[Booking Login ID], Staff_RAW.[TED Name], Staff_RAW.[cnx_email], Staff_RAW.[Booking Email], Staff_RAW.[CUIC Name], Staff_RAW.[PST_Start_Date],\n",
    "COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]) AS [Date],\n",
    "CASE \n",
    "    WHEN DATEDIFF(day, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) >= 90 THEN 'TN'\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined' \n",
    "    ELSE 'NH' END AS [Tenure],\n",
    "CASE \n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 30 THEN '00-30'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 60 THEN '31-60'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 90 THEN '61-90'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 120 THEN '91-120'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 120 THEN '120+'\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined'\n",
    "    ELSE 'Undefined' END AS [Tenure days],\n",
    "CASE \n",
    "\tWHEN FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00') < 3 AND MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 10\n",
    "\tTHEN CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]))+1, FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\tELSE CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])), FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\tEND AS [Week_num],\n",
    "CASE\n",
    "WHEN ROSTER_RAW2.[Shift] IN (\n",
    "'0000-0900','0100-1000','0200-1100','0300-1200','0400-1300','0500-1400','0600-1500','0700-1600','0800-1700','0900-1800','1000-1900','1100-2000',\n",
    "'1200-2100','1300-2200','1400-2300','1500-0000','1600-0100','1700-0200','1800-0300','1900-0400','2000-0500','2100-0600','2200-0700','2300-0800'\n",
    ",'HAL','Training','DOWNTIME','PEGA','New Hire Training'\n",
    ") THEN 'WORK'\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('AL', 'CO', 'VGH','HO') THEN 'Planned leave'\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('UPL') THEN 'Unplanned leave' \n",
    "WHEN ROSTER_RAW2.[Shift] IN ('OFF') THEN 'OFF' ELSE NULL END AS [Shift_definition],\n",
    "YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [YEAR],\n",
    "MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [MONTH],\n",
    "DATENAME(weekday, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [Week_day],\n",
    "COALESCE(TRANSFER_RAW.[Remarks], TERMINATION_RAW.[Termination Reason], RESIGNATION_RAW.[Resignation Primary Reason]) AS [Termination/Transfer],\n",
    "CASE \n",
    "    WHEN ROSTER_RAW2.[LOB] IN ('NL', 'ID4', 'HE4', 'XT4', 'EL', 'TR', 'KO', 'IT', 'CS', 'HU', 'FR', 'ZH', 'RU', 'PL', 'PT', 'NO', 'DA', 'DE', 'RO') THEN 'Unbabel'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'EN' THEN 'English'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSP' THEN 'Vietnamese CSP'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSG' THEN 'Vietnamese CSG'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'Senior VICSP' THEN 'Senior VICSP'\n",
    "    ELSE 'Undefined' END AS [LOB Group],\n",
    "-- Set up ScheduleSeconds(s)\n",
    "CASE\n",
    "    WHEN CHARINDEX('-', ROSTER_RAW2.[Original_Shift]) = 5 OR ROSTER_RAW2.[Original_Shift] IN ('UPL', 'PEGA') THEN 9 * 3600\n",
    "    WHEN ROSTER_RAW2.[Original_Shift] IN ('HAL', 'HSL') THEN 4 * 3600\n",
    "    ELSE 0\n",
    "END AS [ScheduleSeconds(s)]\n",
    "FROM ROSTER_RAW2\n",
    "FULL JOIN TRANSFER_RAW ON ROSTER_RAW2.[Emp ID] = TRANSFER_RAW.[EID] And ROSTER_RAW2.[Date] = TRANSFER_RAW.[LWD]\n",
    "FULL JOIN TERMINATION_RAW ON ROSTER_RAW2.[Emp ID] = TERMINATION_RAW.[EMPLOYEE_ID] And ROSTER_RAW2.[Date] = TERMINATION_RAW.[LWD]\n",
    "FULL JOIN RESIGNATION_RAW ON ROSTER_RAW2.[Emp ID] = RESIGNATION_RAW.[Employee ID] And ROSTER_RAW2.[Date] = RESIGNATION_RAW.[Proposed Termination Date]\n",
    "LEFT JOIN TL_RAW ON ROSTER_RAW2.[team_leader] = TL_RAW.[Employee_ID]\n",
    "LEFT JOIN OM_RAW ON ROSTER_RAW2.[OM] = OM_RAW.[Employee_ID]\n",
    "LEFT JOIN DPE_RAW ON ROSTER_RAW2.[DPE] = DPE_RAW.[Employee_ID]\n",
    "LEFT JOIN Staff_RAW ON COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) = Staff_RAW.[Employee_ID]\n",
    "),\n",
    "-- Create BCOM.EPS 2 (Add: Shift)\n",
    "EPS_RAW2 AS ( \n",
    "SELECT \n",
    "ROSTER_RAW2.[Shift], ROSTER_RAW2.[Shift_type], Staff_RAW.[Employee_ID], EPS_RAW.[Username], EPS_RAW.[Session Login], EPS_RAW.[Session Logout], EPS_RAW.[Session Time], EPS_RAW.[BPE Code], EPS_RAW.[Total Time], EPS_RAW.[SessionLogin_VN], EPS_RAW.[Date_Login_VN], \n",
    "EPS_RAW.[PreviousDate_Login_VN], EPS_RAW.[Time_Login_VN], EPS_RAW.[SessionLogout_VN], EPS_RAW.[Date_Logout_VN], EPS_RAW.[Time_Logout_VN], EPS_RAW.[NightTime], EPS_RAW.[DayTime], EPS_RAW.[Night_BPE], EPS_RAW.[Day_BPE] \n",
    "FROM EPS_RAW\n",
    "LEFT JOIN Staff_RAW ON EPS_RAW.[Username] = Staff_RAW.[Booking Login ID] \n",
    "LEFT JOIN ROSTER_RAW2 ON Staff_RAW.[Employee_ID] = ROSTER_RAW2.[Emp ID] And EPS_RAW.[Date_Login_VN] = ROSTER_RAW2.[Date] ),\n",
    "-- Create BCOM.EPS 3 (Add: Final Date)\n",
    "EPS_RAW3 AS (\n",
    "SELECT\n",
    "EPS_RAW2.[Shift], EPS_RAW2.[Shift_type], ROSTER_RAW2.[Shift] AS [Shift-1], ROSTER_RAW2.[Shift_type] AS [Shifttype-1], \n",
    "CASE \n",
    "WHEN (EPS_RAW2.[Shift_type] IS NULL OR EPS_RAW2.[Shift_type] <> 'DS')\n",
    "AND ROSTER_RAW2.[Shift_type] = 'NS'\n",
    "AND EPS_RAW2.[Time_Login_VN] < '12:00:00'\n",
    "THEN EPS_RAW2.[PreviousDate_Login_VN] \n",
    "ELSE EPS_RAW2.[Date_Login_VN] END AS [Date],\n",
    "EPS_RAW2.[Employee_ID], EPS_RAW2.[Username], EPS_RAW2.[Session Login], EPS_RAW2.[Session Logout], EPS_RAW2.[Session Time], EPS_RAW2.[BPE Code], \n",
    "EPS_RAW2.[Total Time], EPS_RAW2.[SessionLogin_VN], EPS_RAW2.[Date_Login_VN], EPS_RAW2.[PreviousDate_Login_VN], EPS_RAW2.[Time_Login_VN], EPS_RAW2.[SessionLogout_VN], \n",
    "EPS_RAW2.[Date_Logout_VN], EPS_RAW2.[Time_Logout_VN], EPS_RAW2.[NightTime], EPS_RAW2.[DayTime], EPS_RAW2.[Night_BPE], EPS_RAW2.[Day_BPE] \n",
    "FROM EPS_RAW2\n",
    "LEFT JOIN ROSTER_RAW2 ON EPS_RAW2.[Employee_ID] = ROSTER_RAW2.[Emp ID] And EPS_RAW2.[PreviousDate_Login_VN] = ROSTER_RAW2.[Date]\n",
    "),\n",
    "-- Create BCOM.EPS 4 (Add: Data's Pivoted)\n",
    "EPS_RAW4 AS (\n",
    "SELECT \n",
    "EPS_RAW3.[Date], EPS_RAW3.[Employee_ID], \n",
    "/*Set up Login Logout*/\n",
    "MIN(EPS_RAW3.[SessionLogin_VN]) AS [Login], MAX(EPS_RAW3.[SessionLogout_VN]) AS [Logout],\n",
    "/*Set up StaffTime*/\n",
    "SUM(EPS_RAW3.[Total Time]) AS [StaffTime(s)], SUM(EPS_RAW3.[Night_BPE]) AS [Night_StaffTime(s)], SUM(EPS_RAW3.[Day_BPE]) AS [Day_StaffTime(s)],  \n",
    "/*Set up Break*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Total Time] else Null end) as [Break(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Break(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Break(s)],\n",
    "/*Set up Global Support*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Total Time] else Null end) as [Global_Support(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Global_Support(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Global_Support(s)],\n",
    "/*Set up Loaner*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Total Time] else Null end) as [Loaner(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Loaner(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Loaner(s)],\n",
    "/*Set up Lunch*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Total Time] else Null end) as [Lunch(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Lunch(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Lunch(s)],\n",
    "/*Set up Mass Issue*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Total Time] else Null end) as [Mass_Issue(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Mass_Issue(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Mass_Issue(s)],\n",
    "/*Set up Meeting*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Total Time] else Null end) as [Meeting(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Meeting(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Meeting(s)],\n",
    "/*Set up Moderation*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Total Time] else Null end) as [Moderation(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Moderation(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Moderation(s)],\n",
    "/*Set up New Hire Training*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Total Time] else Null end) as [New_Hire_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Night_BPE] else Null end) as [Night_New_Hire_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Day_BPE] else Null end) as [Day_New_Hire_Training(s)],\n",
    "/*Set up Not Working Yet*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Total Time] else Null end) as [Not_Working_Yet(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Not_Working_Yet(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Not_Working_Yet(s)],\n",
    "/*Set up Payment Processing*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Total Time] else Null end) as [Payment_Processing(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Payment_Processing(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Payment_Processing(s)],\n",
    "/*Set up Personal Time*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Total Time] else Null end) as [Personal_Time(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Personal_Time(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Personal_Time(s)],\n",
    "/*Set up Picklist - off Phone*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Total Time] else Null end) as [Picklist_off_Phone(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Picklist_off_Phone(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Picklist_off_Phone(s)],\n",
    "/*Set up Project*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Total Time] else Null end) as [Project(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Project(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Project(s)],\n",
    "/*Set up RONA*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Total Time] else Null end) as [RONA(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Night_BPE] else Null end) as [Night_RONA(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Day_BPE] else Null end) as [Day_RONA(s)],\n",
    "/*Set up Ready or Talking*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Total Time] else Null end) as [Ready_Talking(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Ready_Talking(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Ready_Talking(s)],\n",
    "/*Set up Special Task*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Total Time] else Null end) as [Special_Task(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Special_Task(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Special_Task(s)],\n",
    "/*Set up Technical Problems*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Total Time] else Null end) as [Technical_Problems(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Technical_Problems(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Technical_Problems(s)],\n",
    "/*Set up Training*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Total Time] else Null end) as [Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Training(s)],\n",
    "/*Set up Unscheduled Picklist*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Total Time] else Null end) as [Unscheduled_Picklist(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Unscheduled_Picklist(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Unscheduled_Picklist(s)],\n",
    "/*Set up Work Council*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Total Time] else Null end) as [Work_Council(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Work_Council(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Work_Council(s)]\n",
    "FROM EPS_RAW3 GROUP BY EPS_RAW3.[Date], EPS_RAW3.[Employee_ID]\n",
    ")\n",
    "select ROSTER_RAW3.[Emp ID],ROSTER_RAW3.[TED Name],ROSTER_RAW3.[TL_Name],ROSTER_RAW3.[OM_Name],ROSTER_RAW3.[Wave],\n",
    "ROSTER_RAW3.[Date],ROSTER_RAW3.[Shift],RAMCO_RAW.[Ramco_Code] as [RAMCO],\n",
    "Case\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'PO' AND ROSTER_RAW3.[Shift] = 'OFF' THEN 'Valid'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'PR' AND ROSTER_RAW3.[Shift] = 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HAL' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HLWP' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] IS NOT Null THEN Null  \n",
    "    When RAMCO_RAW.[Ramco_Code] IS NOT Null AND ROSTER_RAW3.[Shift] is Null THEN Null\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] is Null THEN 'Valid'\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'AB' AND ROSTER_RAW3.[Shift_definition] = 'WORK' THEN 'Valid'\n",
    "    When (Case When Roster_Raw3.[Shift_definition] = 'WORK' Then 'WORK'\n",
    "               When Roster_Raw3.[Shift_definition] is Null then Null Else 'OFF' End) = RAMCO_RAW.[Ramco_Define] THEN 'Valid'\n",
    "Else 'ATD MM' End As [ATD_Mismatch]\n",
    "from ROSTER_RAW3\n",
    "left join RAMCO_RAW on RAMCO_RAW.[EID]=ROSTER_RAW3.[Emp ID] and RAMCO_RAW.[Date]=ROSTER_RAW3.[Date]\n",
    "where ROSTER_RAW3.[Date]>=DATEADD(DAY, -30,CAST(GETDATE() As Date)) and ROSTER_RAW3.[Date]<=DATEADD(DAY, 0,CAST(GETDATE() As Date))\n",
    "\"\"\"\n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "atdmm_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atdmm_CSV = atdmm_df.write_excel(workbook=\"BKN_ATD_MM.xlsx\",worksheet=\"Sheet1\",table_name='Table1', autofit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "408fdba6-0283-4441-9919-6383b4352464",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#[BKN]ATD MM PIVOT to powwer automate captureüé°\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "WITH\n",
    "-- Create GLB.OT_RAMCO 1 (RAW)\n",
    "OTRAMCO_RAW AS (  --Setup OTRamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [OT_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] in ('OT1.0X','OT1.5X','OT2.0X','OT2.1X','OT2.5X','OT2.7X') And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "PHRAMCO_RAW AS (  --Setup PHRamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [PH_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] in ('OT3.0X','OT3.9X','OT4.0X') And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "NSARAMCO_RAW AS (  --Setup NSARamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [NSA_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] = 'NSA' And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "-- Create GLB.RAMCO 1 (RAW)\n",
    "RAMCO_RAW AS ( \n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define] \n",
    "FROM GLB.RAMCO \n",
    "),\n",
    "-- Create RAMCO Pre1 (RAW)\n",
    "RAMCO_RAW_Pre1 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre1], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre1] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create BCOM.RegisteredOT (RAW)\n",
    "RegisteredOT_RAW AS (\n",
    "SELECT [Date], [Emp ID], [OT]*3600 AS [OT_Registered(s)], [Type] AS [OT_Registered_Type] FROM BCOM.RegisteredOT\n",
    "),\n",
    "-- Create RAMCO Pre2 (RAW)\n",
    "RAMCO_RAW_Pre2 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre2], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre2] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre3 (RAW)\n",
    "RAMCO_RAW_Pre3 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre3], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre3] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre4 (RAW)\n",
    "RAMCO_RAW_Pre4 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre4], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre4] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre5 (RAW)\n",
    "RAMCO_RAW_Pre5 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre5], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre5] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre6 (RAW)\n",
    "RAMCO_RAW_Pre6 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre6], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre6] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create GLB.PremHdays 1 (RAW)\n",
    "PremHday_RAW AS ( SELECT [Date],[Holiday] FROM GLB.PremHdays \n",
    "),\n",
    "-- Create BCOM.ROSTER 1 (RAW)\n",
    "ROSTER_RAW AS ( SELECT [Emp ID], [Attribute], [Value], [LOB], [team_leader], [week_shift], [week_off], [OM], [DPE] FROM BCOM.ROSTER \n",
    "),\n",
    "-- Create ROSTER(n-1) 1 (RAW)\n",
    "ROSTER_Pre1_RAW AS ( SELECT [Emp ID], [Attribute] AS [Date-1], [Value], [LOB], [team_leader], [week_shift], [week_off], [OM], [DPE] FROM BCOM.ROSTER \n",
    "),\n",
    "-- Create BCOM.LTTransfers 1 (RAW)\n",
    "TRANSFER_RAW AS (      \n",
    "SELECT [EID], [LWD], [Remarks] \n",
    "FROM BCOM.LTTransfers\n",
    "),\n",
    "-- Create BCOM.ExceptionReq 1 (RAW)\n",
    "ExceptionReq_RAW AS (\n",
    "SELECT [Date (MM/DD/YYYY)] AS [Date], [Emp ID], SUM([Exception request (Minute)]*60) AS [Req_Second] FROM BCOM.ExceptionReq\n",
    "WHERE [OM] = 'Approve' \n",
    "GROUP BY [Date (MM/DD/YYYY)],[Emp ID] \n",
    "),\n",
    "-- Create GLB.Termination 1 (RAW)\n",
    "TERMINATION_RAW AS (   \n",
    "SELECT [EMPLOYEE_ID], [LWD], [Termination Reason] \n",
    "FROM GLB.Termination \n",
    "WHERE [Client Name ( Process )] = 'Bookingcom' And [JOB_ROLE] = 'Agent' And [COUNTRY] = 'Vietnam'\n",
    "),\n",
    "-- Create GLB.Resignation 1 (RAW)\n",
    "RESIGNATION_RAW AS (   \n",
    "SELECT [Employee ID], [Proposed Termination Date], [Resignation Primary Reason] \n",
    "FROM GLB.Resignation \n",
    "WHERE [MSA Client] = 'Bookingcom' And [Job Family] = 'Contact Center' And [Country] = 'Vietnam'\n",
    "),\n",
    "-- Create BCOM.EPS 1 (RAW)\n",
    "EPS_RAW AS ( \n",
    "SELECT [Username], [Session Login], [Session Logout], [Session Time], [BPE Code], [Total Time], [SessionLogin_VN], CAST([SessionLogin_VN] AS DATE) AS [Date_Login_VN], DATEADD(DAY, -1, CAST([SessionLogin_VN] AS DATE)) AS [PreviousDate_Login_VN], CAST([SessionLogin_VN] AS TIME) AS [Time_Login_VN], [SessionLogout_VN], CAST([SessionLogout_VN] AS DATE) AS [Date_Logout_VN], CAST([SessionLogout_VN] AS TIME) AS [Time_Logout_VN], [NightTime], [DayTime], [Night_BPE], [Day_BPE] FROM BCOM.EPS \n",
    "),\n",
    "-- Create BCOM.Staff 1 (RAW)\n",
    "Staff_RAW AS ( \n",
    "SELECT [Employee_ID], [Wave #], [Role], [Booking Login ID], [Language Start Date], [TED Name], [CUIC Name], [EnterpriseName], [Hire_Date], [PST_Start_Date], [Production_Start_Date], [Designation], [cnx_email], [Booking Email], [Full name], [IEX], [serial_number], [BKN_ID], [Extension Number] FROM BCOM.Staff \n",
    "),\n",
    "-- Create TL,OM,DPE 1 (RAW)\n",
    "TL_RAW AS (SELECT [Employee_ID],[TED Name] AS [TL_Name] FROM BCOM.Staff),\n",
    "OM_RAW AS (SELECT [Employee_ID],[TED Name] AS [OM_Name] FROM BCOM.Staff),\n",
    "DPE_RAW AS (SELECT [Employee_ID],[TED Name] AS [DPE_Name] FROM BCOM.Staff),\n",
    "-- Create BCOM.CPI_PEGA 1 (RAW)\n",
    "CPI_PEGA_RAW AS ( \n",
    "SELECT \n",
    "[Staff Name], [Operator Def], [Service Case Type New], [Channel Def], [Lang Def], [Reason For No Service Case], \n",
    "[Topic Def New], [Subtopics], [Case Id], [Reservation Id Def], [Day of Date] AS [Date], [# Swivels], [Count of ServiceCase or Interaction],\n",
    "CASE \n",
    "WHEN [# Swivels] > 0 THEN 'PEGA Swiveled to TED'\n",
    "ELSE 'PEGA' END AS [CRM]\n",
    "FROM BCOM.CPI_PEGA \n",
    "WHERE [Count of ServiceCase or Interaction] > 0\n",
    "),\n",
    "-- Create BCOM.CPI 1 (RAW)\n",
    "CPI_RAW AS ( \n",
    "SELECT \n",
    "BCOM.CPI.[Date], BCOM.CPI.[Staff Name], BCOM.CPI.[Hour Interval Selected], \n",
    "BCOM.CPI.[Channel], BCOM.CPI.[Item Label], BCOM.CPI.[Item ID], BCOM.CPI.['Item ID'], BCOM.CPI.[Time Alert], \n",
    "BCOM.CPI.[Nr. Contacts], 'TED' AS [CRM]\n",
    "FROM BCOM.CPI \n",
    "LEFT JOIN CPI_PEGA_RAW ON CPI_PEGA_RAW.[Staff Name] = BCOM.CPI.[Staff Name] AND CPI_PEGA_RAW.[Date] = BCOM.CPI.[Date] AND CPI_PEGA_RAW.[Reservation Id Def] = BCOM.CPI.[Item ID]\n",
    "WHERE CPI_PEGA_RAW.[Reservation Id Def] IS NULL\n",
    "),\n",
    "-- Create BCOM.LogoutCount 1 (RAW)\n",
    "LogoutCount_RAW AS (\n",
    "SELECT [Aggregation] AS [TED_Name], [TimeDimension] AS [Date], SUM([KPI Value Formatted]) AS [Logout_Count] FROM BCOM.LogoutCount GROUP BY [Aggregation], [TimeDimension]\n",
    "),\n",
    "-- Create BCOM.PSAT 1 (RAW)\n",
    "PSAT_RAW AS (\n",
    "SELECT \n",
    "[Sorted By Dimension] AS [Date], Staff_RAW.[Employee_ID], [Staff Name] AS [Staff], '' AS [Team], [Survey Id], [Hotel Id] AS [Reservation], [Channel], \n",
    "[Agent understood my question], [Agent did everything possible to help me], [Final Topics] AS [Topic of the first Ticket], [Language], 'PSAT' AS [CSAT/PSAT]\n",
    "From BCOM.PSAT\n",
    "LEFT JOIN Staff_RAW ON [Staff Name] = Staff_RAW.[TED Name]\n",
    "),\n",
    "-- Create BCOM.ROSTER 2 (Add: Shift)\n",
    "ROSTER_RAW2 AS (\n",
    "SELECT\n",
    "\tROSTER_RAW.[Emp ID], ROSTER_RAW.[Attribute] AS [Date], \n",
    "\tROSTER_RAW.[Value] AS [Original_Shift], ROSTER_RAW.[LOB], ROSTER_RAW.[team_leader], ROSTER_RAW.[week_shift], \n",
    "\tROSTER_RAW.[week_off], ROSTER_RAW.[OM], ROSTER_RAW.[DPE],\n",
    "\tCASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END AS [Shift],\n",
    "\tCASE \n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('OFF', 'AL', 'CO', 'HO', 'UPL', 'VGH') THEN 'OFF'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('Training', 'PEGA') THEN 'Training'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tELSE Null END AS [Shift_type]\n",
    "FROM ROSTER_RAW\n",
    "LEFT JOIN RAMCO_RAW ON ROSTER_RAW.[Emp ID] = RAMCO_RAW.[EID] AND ROSTER_RAW.[Attribute] = RAMCO_RAW.[Date] \n",
    "),\n",
    "-- Create ROSTER_Pre1_RAW 2 (Add: Shift_type)\n",
    "ROSTER_Pre1_RAW2 AS (\n",
    "SELECT\n",
    "\tROSTER_Pre1_RAW.[Emp ID], ROSTER_Pre1_RAW.[Date-1], \n",
    "\tROSTER_Pre1_RAW.[Value] AS [Original_Shift], ROSTER_Pre1_RAW.[LOB], ROSTER_Pre1_RAW.[team_leader], ROSTER_Pre1_RAW.[week_shift], \n",
    "\tROSTER_Pre1_RAW.[week_off], ROSTER_Pre1_RAW.[OM], ROSTER_Pre1_RAW.[DPE],\n",
    "\tCASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END AS [Shift],\n",
    "\tCASE \n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('OFF', 'AL', 'CO', 'HO', 'UPL', 'VGH') THEN 'OFF'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('Training', 'PEGA') THEN 'Training'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tWHEN ROSTER_Pre1_RAW.[week_shift] IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN ROSTER_Pre1_RAW.[week_shift] IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tELSE Null END AS [Shift_type]\n",
    "FROM ROSTER_Pre1_RAW\n",
    "LEFT JOIN RAMCO_RAW ON ROSTER_Pre1_RAW.[Emp ID] = RAMCO_RAW.[EID] AND ROSTER_Pre1_RAW.[Date-1] = RAMCO_RAW.[Date] \n",
    "),\n",
    "-- Create BCOM.ROSTER 3 (Add: [Termination/Transfer])\n",
    "ROSTER_RAW3 AS (\n",
    "SELECT\n",
    "ROSTER_RAW2.[Shift], ROSTER_RAW2.[Shift_type], ROSTER_RAW2.[Original_Shift], ROSTER_RAW2.[LOB], ROSTER_RAW2.[week_shift], ROSTER_RAW2.[week_off], \n",
    "ROSTER_RAW2.[team_leader] AS [TL_ID], TL_RAW.[TL_Name], ROSTER_RAW2.[OM] AS [OM_ID], OM_RAW.[OM_Name], ROSTER_RAW2.[DPE] AS [DPE_ID], DPE_RAW.[DPE_Name],\n",
    "COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) AS [Emp ID], Staff_RAW.[Full name] AS [Emp_Name], \n",
    "Staff_RAW.[Wave #] AS [Wave], Staff_RAW.[Booking Login ID], Staff_RAW.[TED Name], Staff_RAW.[cnx_email], Staff_RAW.[Booking Email], Staff_RAW.[CUIC Name], Staff_RAW.[PST_Start_Date],\n",
    "COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]) AS [Date],\n",
    "CASE \n",
    "    WHEN DATEDIFF(day, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) >= 90 THEN 'TN'\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined' \n",
    "    ELSE 'NH' END AS [Tenure],\n",
    "CASE \n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 30 THEN '00-30'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 60 THEN '31-60'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 90 THEN '61-90'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 120 THEN '91-120'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 120 THEN '120+'\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined'\n",
    "    ELSE 'Undefined' END AS [Tenure days],\n",
    "CASE \n",
    "\tWHEN FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00') < 3 AND MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 10\n",
    "\tTHEN CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]))+1, FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\tELSE CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])), FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\tEND AS [Week_num],\n",
    "CASE\n",
    "WHEN ROSTER_RAW2.[Shift] IN (\n",
    "'0000-0900','0100-1000','0200-1100','0300-1200','0400-1300','0500-1400','0600-1500','0700-1600','0800-1700','0900-1800','1000-1900','1100-2000',\n",
    "'1200-2100','1300-2200','1400-2300','1500-0000','1600-0100','1700-0200','1800-0300','1900-0400','2000-0500','2100-0600','2200-0700','2300-0800'\n",
    ",'HAL','Training','DOWNTIME','PEGA','New Hire Training'\n",
    ") THEN 'WORK'\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('AL', 'CO', 'VGH','HO') THEN 'Planned leave'\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('UPL') THEN 'Unplanned leave' \n",
    "WHEN ROSTER_RAW2.[Shift] IN ('OFF') THEN 'OFF' ELSE NULL END AS [Shift_definition],\n",
    "YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [YEAR],\n",
    "MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [MONTH],\n",
    "DATENAME(weekday, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [Week_day],\n",
    "COALESCE(TRANSFER_RAW.[Remarks], TERMINATION_RAW.[Termination Reason], RESIGNATION_RAW.[Resignation Primary Reason]) AS [Termination/Transfer],\n",
    "CASE \n",
    "    WHEN ROSTER_RAW2.[LOB] IN ('NL', 'ID4', 'HE4', 'XT4', 'EL', 'TR', 'KO', 'IT', 'CS', 'HU', 'FR', 'ZH', 'RU', 'PL', 'PT', 'NO', 'DA', 'DE', 'RO') THEN 'Unbabel'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'EN' THEN 'English'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSP' THEN 'Vietnamese CSP'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSG' THEN 'Vietnamese CSG'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'Senior VICSP' THEN 'Senior VICSP'\n",
    "    ELSE 'Undefined' END AS [LOB Group],\n",
    "-- Set up ScheduleSeconds(s)\n",
    "CASE\n",
    "    WHEN CHARINDEX('-', ROSTER_RAW2.[Original_Shift]) = 5 OR ROSTER_RAW2.[Original_Shift] IN ('UPL', 'PEGA') THEN 9 * 3600\n",
    "    WHEN ROSTER_RAW2.[Original_Shift] IN ('HAL', 'HSL') THEN 4 * 3600\n",
    "    ELSE 0\n",
    "END AS [ScheduleSeconds(s)]\n",
    "FROM ROSTER_RAW2\n",
    "FULL JOIN TRANSFER_RAW ON ROSTER_RAW2.[Emp ID] = TRANSFER_RAW.[EID] And ROSTER_RAW2.[Date] = TRANSFER_RAW.[LWD]\n",
    "FULL JOIN TERMINATION_RAW ON ROSTER_RAW2.[Emp ID] = TERMINATION_RAW.[EMPLOYEE_ID] And ROSTER_RAW2.[Date] = TERMINATION_RAW.[LWD]\n",
    "FULL JOIN RESIGNATION_RAW ON ROSTER_RAW2.[Emp ID] = RESIGNATION_RAW.[Employee ID] And ROSTER_RAW2.[Date] = RESIGNATION_RAW.[Proposed Termination Date]\n",
    "LEFT JOIN TL_RAW ON ROSTER_RAW2.[team_leader] = TL_RAW.[Employee_ID]\n",
    "LEFT JOIN OM_RAW ON ROSTER_RAW2.[OM] = OM_RAW.[Employee_ID]\n",
    "LEFT JOIN DPE_RAW ON ROSTER_RAW2.[DPE] = DPE_RAW.[Employee_ID]\n",
    "LEFT JOIN Staff_RAW ON COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) = Staff_RAW.[Employee_ID]\n",
    "),\n",
    "-- Create BCOM.EPS 2 (Add: Shift)\n",
    "EPS_RAW2 AS ( \n",
    "SELECT \n",
    "ROSTER_RAW2.[Shift], ROSTER_RAW2.[Shift_type], Staff_RAW.[Employee_ID], EPS_RAW.[Username], EPS_RAW.[Session Login], EPS_RAW.[Session Logout], EPS_RAW.[Session Time], EPS_RAW.[BPE Code], EPS_RAW.[Total Time], EPS_RAW.[SessionLogin_VN], EPS_RAW.[Date_Login_VN], \n",
    "EPS_RAW.[PreviousDate_Login_VN], EPS_RAW.[Time_Login_VN], EPS_RAW.[SessionLogout_VN], EPS_RAW.[Date_Logout_VN], EPS_RAW.[Time_Logout_VN], EPS_RAW.[NightTime], EPS_RAW.[DayTime], EPS_RAW.[Night_BPE], EPS_RAW.[Day_BPE] \n",
    "FROM EPS_RAW\n",
    "LEFT JOIN Staff_RAW ON EPS_RAW.[Username] = Staff_RAW.[Booking Login ID] \n",
    "LEFT JOIN ROSTER_RAW2 ON Staff_RAW.[Employee_ID] = ROSTER_RAW2.[Emp ID] And EPS_RAW.[Date_Login_VN] = ROSTER_RAW2.[Date] ),\n",
    "-- Create BCOM.EPS 3 (Add: Final Date)\n",
    "EPS_RAW3 AS (\n",
    "SELECT\n",
    "EPS_RAW2.[Shift], EPS_RAW2.[Shift_type], ROSTER_RAW2.[Shift] AS [Shift-1], ROSTER_RAW2.[Shift_type] AS [Shifttype-1], \n",
    "CASE \n",
    "WHEN (EPS_RAW2.[Shift_type] IS NULL OR EPS_RAW2.[Shift_type] <> 'DS')\n",
    "AND ROSTER_RAW2.[Shift_type] = 'NS'\n",
    "AND EPS_RAW2.[Time_Login_VN] < '12:00:00'\n",
    "THEN EPS_RAW2.[PreviousDate_Login_VN] \n",
    "ELSE EPS_RAW2.[Date_Login_VN] END AS [Date],\n",
    "EPS_RAW2.[Employee_ID], EPS_RAW2.[Username], EPS_RAW2.[Session Login], EPS_RAW2.[Session Logout], EPS_RAW2.[Session Time], EPS_RAW2.[BPE Code], \n",
    "EPS_RAW2.[Total Time], EPS_RAW2.[SessionLogin_VN], EPS_RAW2.[Date_Login_VN], EPS_RAW2.[PreviousDate_Login_VN], EPS_RAW2.[Time_Login_VN], EPS_RAW2.[SessionLogout_VN], \n",
    "EPS_RAW2.[Date_Logout_VN], EPS_RAW2.[Time_Logout_VN], EPS_RAW2.[NightTime], EPS_RAW2.[DayTime], EPS_RAW2.[Night_BPE], EPS_RAW2.[Day_BPE] \n",
    "FROM EPS_RAW2\n",
    "LEFT JOIN ROSTER_RAW2 ON EPS_RAW2.[Employee_ID] = ROSTER_RAW2.[Emp ID] And EPS_RAW2.[PreviousDate_Login_VN] = ROSTER_RAW2.[Date]\n",
    "),\n",
    "-- Create BCOM.EPS 4 (Add: Data's Pivoted)\n",
    "EPS_RAW4 AS (\n",
    "SELECT \n",
    "EPS_RAW3.[Date], EPS_RAW3.[Employee_ID], \n",
    "/*Set up Login Logout*/\n",
    "MIN(EPS_RAW3.[SessionLogin_VN]) AS [Login], MAX(EPS_RAW3.[SessionLogout_VN]) AS [Logout],\n",
    "/*Set up StaffTime*/\n",
    "SUM(EPS_RAW3.[Total Time]) AS [StaffTime(s)], SUM(EPS_RAW3.[Night_BPE]) AS [Night_StaffTime(s)], SUM(EPS_RAW3.[Day_BPE]) AS [Day_StaffTime(s)],  \n",
    "/*Set up Break*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Total Time] else Null end) as [Break(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Break(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Break(s)],\n",
    "/*Set up Global Support*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Total Time] else Null end) as [Global_Support(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Global_Support(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Global_Support(s)],\n",
    "/*Set up Loaner*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Total Time] else Null end) as [Loaner(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Loaner(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Loaner(s)],\n",
    "/*Set up Lunch*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Total Time] else Null end) as [Lunch(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Lunch(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Lunch(s)],\n",
    "/*Set up Mass Issue*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Total Time] else Null end) as [Mass_Issue(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Mass_Issue(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Mass_Issue(s)],\n",
    "/*Set up Meeting*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Total Time] else Null end) as [Meeting(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Meeting(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Meeting(s)],\n",
    "/*Set up Moderation*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Total Time] else Null end) as [Moderation(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Moderation(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Moderation(s)],\n",
    "/*Set up New Hire Training*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Total Time] else Null end) as [New_Hire_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Night_BPE] else Null end) as [Night_New_Hire_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Day_BPE] else Null end) as [Day_New_Hire_Training(s)],\n",
    "/*Set up Not Working Yet*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Total Time] else Null end) as [Not_Working_Yet(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Not_Working_Yet(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Not_Working_Yet(s)],\n",
    "/*Set up Payment Processing*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Total Time] else Null end) as [Payment_Processing(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Payment_Processing(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Payment_Processing(s)],\n",
    "/*Set up Personal Time*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Total Time] else Null end) as [Personal_Time(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Personal_Time(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Personal_Time(s)],\n",
    "/*Set up Picklist - off Phone*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Total Time] else Null end) as [Picklist_off_Phone(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Picklist_off_Phone(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Picklist_off_Phone(s)],\n",
    "/*Set up Project*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Total Time] else Null end) as [Project(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Project(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Project(s)],\n",
    "/*Set up RONA*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Total Time] else Null end) as [RONA(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Night_BPE] else Null end) as [Night_RONA(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Day_BPE] else Null end) as [Day_RONA(s)],\n",
    "/*Set up Ready or Talking*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Total Time] else Null end) as [Ready_Talking(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Ready_Talking(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Ready_Talking(s)],\n",
    "/*Set up Special Task*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Total Time] else Null end) as [Special_Task(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Special_Task(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Special_Task(s)],\n",
    "/*Set up Technical Problems*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Total Time] else Null end) as [Technical_Problems(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Technical_Problems(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Technical_Problems(s)],\n",
    "/*Set up Training*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Total Time] else Null end) as [Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Training(s)],\n",
    "/*Set up Unscheduled Picklist*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Total Time] else Null end) as [Unscheduled_Picklist(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Unscheduled_Picklist(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Unscheduled_Picklist(s)],\n",
    "/*Set up Work Council*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Total Time] else Null end) as [Work_Council(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Work_Council(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Work_Council(s)]\n",
    "FROM EPS_RAW3 GROUP BY EPS_RAW3.[Date], EPS_RAW3.[Employee_ID]\n",
    ")\n",
    "select ROSTER_RAW3.[OM_Name],ROSTER_RAW3.[TL_Name],\n",
    "count(Case\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'PO' AND ROSTER_RAW3.[Shift] = 'OFF' THEN 'Valid'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'PR' AND ROSTER_RAW3.[Shift] = 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HAL' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HLWP' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] IS NOT Null THEN Null  \n",
    "    When RAMCO_RAW.[Ramco_Code] IS NOT Null AND ROSTER_RAW3.[Shift] is Null THEN Null\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] is Null THEN 'Valid'\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'AB' AND ROSTER_RAW3.[Shift_definition] = 'WORK' THEN 'Valid'\n",
    "\twhen RAMCO_RAW.[Ramco_Code] ='WO' AND ROSTER_RAW3.[Shift_definition] = 'OFF' THEN 'Valid'\n",
    "    When (Case When Roster_Raw3.[Shift_definition] = 'WORK' Then 'WORK'\n",
    "               When Roster_Raw3.[Shift_definition] is Null then Null Else 'OFF' End) = RAMCO_RAW.[Ramco_Define] THEN 'Valid'\n",
    "Else 'ATD MM' End) As [MM Cases]\n",
    "from ROSTER_RAW3\n",
    "left join RAMCO_RAW on RAMCO_RAW.[EID]=ROSTER_RAW3.[Emp ID] and RAMCO_RAW.[Date]=ROSTER_RAW3.[Date]\n",
    "where ROSTER_RAW3.[Date]>=DATEADD(DAY, -30,CAST(GETDATE() As Date)) and ROSTER_RAW3.[Date]<=DATEADD(DAY, 0,CAST(GETDATE() As Date))\n",
    "and \n",
    "Case\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'PO' AND ROSTER_RAW3.[Shift] = 'OFF' THEN 'Valid'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'PR' AND ROSTER_RAW3.[Shift] = 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HAL' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HLWP' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] IS NOT Null THEN Null  \n",
    "    When RAMCO_RAW.[Ramco_Code] IS NOT Null AND ROSTER_RAW3.[Shift] is Null THEN Null\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] is Null THEN 'Valid'\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'AB' AND ROSTER_RAW3.[Shift_definition] = 'WORK' THEN 'Valid'\n",
    "\twhen RAMCO_RAW.[Ramco_Code] ='WO' AND ROSTER_RAW3.[Shift_definition] = 'OFF' THEN 'Valid'\n",
    "    When (Case When Roster_Raw3.[Shift_definition] = 'WORK' Then 'WORK'\n",
    "               When Roster_Raw3.[Shift_definition] is Null then Null Else 'OFF' End) = RAMCO_RAW.[Ramco_Define] THEN 'Valid'\n",
    "Else 'ATD MM' End = 'ATD MM'\n",
    "group by ROSTER_RAW3.[OM_Name],ROSTER_RAW3.[TL_Name]\n",
    "order by \n",
    "count(Case\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'PO' AND ROSTER_RAW3.[Shift] = 'OFF' THEN 'Valid'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'PR' AND ROSTER_RAW3.[Shift] = 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HAL' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HLWP' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] IS NOT Null THEN Null  \n",
    "    When RAMCO_RAW.[Ramco_Code] IS NOT Null AND ROSTER_RAW3.[Shift] is Null THEN Null\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] is Null THEN 'Valid'\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'AB' AND ROSTER_RAW3.[Shift_definition] = 'WORK' THEN 'Valid'\n",
    "    When (Case When Roster_Raw3.[Shift_definition] = 'WORK' Then 'WORK'\n",
    "               When Roster_Raw3.[Shift_definition] is Null then Null Else 'OFF' End) = RAMCO_RAW.[Ramco_Define] THEN 'Valid'\n",
    "Else 'ATD MM' End) desc\n",
    "\n",
    "\"\"\"\n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "ATD_MM_pivot = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "ATD_MM_pivot=ATD_MM_pivot.to_pandas()\n",
    "# Export to CSV\n",
    "os.chdir(DF_ATD_DF)\n",
    "# Export to xlsx\n",
    "writer = pd.ExcelWriter(\"BKN_ATD_MM_pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "ATD_MM_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "(max_row, max_col) = ATD_MM_pivot.shape\n",
    "column_settings = [{\"header\": column} for column in ATD_MM_pivot.columns]\n",
    "worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings,\"style\": \"Table Style Light 9\"})\n",
    "worksheet.set_column(0, max_col - 1, 12)\n",
    "worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2434e5ec-9d7c-48f3-8aa5-8ad530402070",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]NM REPORT Link detailüé°\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "WITH\n",
    "MASTER_EMP AS (\n",
    "SELECT [EMPLOYEE_NUMBER] AS [EID], [FULL_NAME], [Employee Status], [PERSON_TYPE], [WORKER_CATEGORY], [Job Title] as [Job_Title], [MSA Client],\n",
    "[Compensation Grade] As [Grade], [JOB_FUNCTION_DESCRIPTION] As [Function],\n",
    "REPLACE([SUPERVISOR_EMAIL_ID],'@concentrix.com','') As [Supervisor], REPLACE([MANAGER_02_EMAIL_ID],'@concentrix.com','') As [Upline_Sup]\n",
    "FROM GLB.EmpMaster WHERE [Country] = 'Vietnam')\n",
    "SELECT GLB.RAMCO.[Date],\n",
    "CASE WHEN DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date)) >=0 AND DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date))<=2 THEN '00-02 Days'\n",
    "WHEN DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date)) >2 AND DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date))<=5 THEN '03-05 Days'\n",
    "WHEN DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date)) >5 AND DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date))<=10 THEN '06-10 Days'\n",
    "WHEN DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date)) >10 THEN '10 Days +'\n",
    "ELSE NULL END AS [Date_Type],\n",
    "GLB.RAMCO.[EID],MASTER_EMP.[FULL_NAME],GLB.RAMCO.[Code] AS [Ramco],\n",
    "CASE WHEN GLB.RAMCO.[Code]='NM' THEN 1 ELSE 0 END AS [NM_Count],\n",
    "MASTER_EMP.[Employee Status],MASTER_EMP.[PERSON_TYPE],MASTER_EMP.[WORKER_CATEGORY],MASTER_EMP.[Job_Title],\n",
    "MASTER_EMP.[MSA Client],MASTER_EMP.[Grade],MASTER_EMP.[Function],MASTER_EMP.[Supervisor],MASTER_EMP.[Upline_Sup]\n",
    "from GLB.RAMCO\n",
    "LEFT JOIN MASTER_EMP ON MASTER_EMP.[EID]=GLB.RAMCO.[EID]\n",
    "WHERE DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date))<=62 AND DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date))>=0 and GLB.RAMCO.[Code]='NM'\n",
    "\"\"\"\n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "NM_REPORT = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(DF_NM_REPORT)\n",
    "NM_REPORT_CSV = NM_REPORT.write_excel(\"GLB_NM_REPORT.xlsx\", worksheet=\"Sheet1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82ad59ef-cc63-432a-8e5b-c7b9d75f0964",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Function</th><th>00-02 Days</th><th>03-05 Days</th><th>06-10 Days</th><th>10 Days +</th><th>Total</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Operations Group&quot;</td><td>2021</td><td>391</td><td>40</td><td>20</td><td>2472</td></tr><tr><td>&quot;Training &amp; Quality Group&quot;</td><td>116</td><td>13</td><td>0</td><td>1</td><td>130</td></tr><tr><td>&quot;WFM Group&quot;</td><td>24</td><td>0</td><td>0</td><td>0</td><td>24</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 6)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ Function                 ‚îÜ 00-02 Days ‚îÜ 03-05 Days ‚îÜ 06-10 Days ‚îÜ 10 Days + ‚îÜ Total ‚îÇ\n",
       "‚îÇ ---                      ‚îÜ ---        ‚îÜ ---        ‚îÜ ---        ‚îÜ ---       ‚îÜ ---   ‚îÇ\n",
       "‚îÇ str                      ‚îÜ i64        ‚îÜ i64        ‚îÜ i64        ‚îÜ i64       ‚îÜ i64   ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ Operations Group         ‚îÜ 2021       ‚îÜ 391        ‚îÜ 40         ‚îÜ 20        ‚îÜ 2472  ‚îÇ\n",
       "‚îÇ Training & Quality Group ‚îÜ 116        ‚îÜ 13         ‚îÜ 0          ‚îÜ 1         ‚îÜ 130   ‚îÇ\n",
       "‚îÇ WFM Group                ‚îÜ 24         ‚îÜ 0          ‚îÜ 0          ‚îÜ 0         ‚îÜ 24    ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[BKN]NM PIVOT to teamüé°\n",
    "filtered_NM_REPORT = NM_REPORT.filter(\n",
    "    (pl.col(\"MSA Client\") == \"Bookingcom\") & \n",
    "    (pl.col(\"Ramco\") == \"NM\") &\n",
    "    (pl.col(\"Employee Status\") == \"Active\")\n",
    ")\n",
    "pivot_NM_REPORT = filtered_NM_REPORT.pivot(\n",
    "    values=[\"NM_Count\",],\n",
    "    index=[\"MSA Client\",\"Function\",],\n",
    "    on=\"Date_Type\",\n",
    "    aggregate_function=\"sum\" # WE can use 'first' n·∫øu ch·ªâ c√≥ 1 gi√° tr·ªã duy nh·∫•t cho m·ªói t·ªï h·ª£p index/columns\n",
    ")\n",
    " \n",
    "#Edit Column\n",
    "unique_date_types = filtered_NM_REPORT[\"Date_Type\"].unique().to_list()\n",
    "pivot_NM_REPORT = pivot_NM_REPORT.with_columns([pl.col(unique_date_types).fill_null(0)])\n",
    "pivot_NM_REPORT = pivot_NM_REPORT.with_columns(pl.fold(0, lambda acc, s: acc + s, pl.exclude(\"MSA Client\",\"Function\",)).alias(\"Total\"))\n",
    "columns_to_select = [\"Function\",\"00-02 Days\", \"03-05 Days\", \"06-10 Days\", \"10 Days +\",\"Total\"]\n",
    "try:\n",
    "    pivot_NM_REPORT = pivot_NM_REPORT.select(columns_to_select)\n",
    "except:\n",
    "    for col in columns_to_select:\n",
    "        try:\n",
    "            pivot_NM_REPORT.select(col)\n",
    "        except:\n",
    "            pivot_NM_REPORT = pivot_NM_REPORT.with_columns(pl.lit(0).cast(pl.Int64).alias(col))\n",
    "    pivot_NM_REPORT = pivot_NM_REPORT.select(columns_to_select)\n",
    " \n",
    "# Export to CSV\n",
    "os.chdir(DF_NM_REPORT)\n",
    "pivot_NM_REPORT_CSV = pivot_NM_REPORT.write_excel(\"GLB_pivot_NM_REPORT.xlsx\", worksheet=\"Sheet1\")\n",
    " \n",
    "#RUN\n",
    "pivot_NM_REPORT_CSV\n",
    "pivot_NM_REPORT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a797e635-8071-4aaf-acc3-b2feda2d859e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]OT_NSA link detailüé°\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "WITH\n",
    "MASTER_EMP AS (\n",
    "SELECT [EMPLOYEE_NUMBER] AS [EID], [FULL_NAME], [Employee Status], [PERSON_TYPE], [WORKER_CATEGORY], [Job Title] as [Job_Title], [MSA Client],\n",
    "[Compensation Grade] As [Grade], [JOB_FUNCTION_DESCRIPTION] As [Function],\n",
    "REPLACE([SUPERVISOR_EMAIL_ID],'@concentrix.com','') As [Supervisor], REPLACE([MANAGER_02_EMAIL_ID],'@concentrix.com','') As [Upline_Sup]\n",
    "FROM GLB.EmpMaster WHERE [Country] = 'Vietnam')\n",
    "\n",
    "SELECT GLB.OT_RAMCO.[Date],\n",
    "CASE WHEN DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date)) >=0 AND DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date))<=2 THEN '00-02 Days'\n",
    "WHEN DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date)) >2 AND DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date))<=5 THEN '03-05 Days'\n",
    "WHEN DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date)) >5 AND DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date))<=10 THEN '06-10 Days'\n",
    "WHEN DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date)) >10 THEN '10 Days +'\n",
    "ELSE NULL END AS [Date_Type],\n",
    "GLB.OT_RAMCO.[employee_code] as [EID],MASTER_EMP.[FULL_NAME],GLB.OT_RAMCO.[OT Type] AS [OT_Type],GLB.OT_RAMCO.[Status],GLB.OT_RAMCO.[Hours] AS [OT_Hours],\n",
    "MASTER_EMP.[Employee Status],MASTER_EMP.[PERSON_TYPE],MASTER_EMP.[WORKER_CATEGORY],MASTER_EMP.[Job_Title],\n",
    "MASTER_EMP.[MSA Client],MASTER_EMP.[Grade],MASTER_EMP.[Function],MASTER_EMP.[Supervisor],MASTER_EMP.[Upline_Sup]\n",
    "from GLB.OT_RAMCO\n",
    "LEFT JOIN MASTER_EMP ON MASTER_EMP.[EID]=GLB.OT_RAMCO.[employee_code]\n",
    "WHERE DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date))<=62 AND DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date))>=0\n",
    "and GLB.OT_RAMCO.[Status]='Pending'\n",
    "\"\"\"\n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "OT_REPORT = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(DF_OT_REPORT)\n",
    "OT_REPORT_CSV = OT_REPORT.write_excel(\"GLB_OT_REPORT.xlsx\", worksheet=\"Sheet1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc7a6eca-a5c5-44e1-abab-cc923f65c6cf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]NSA PIVOT to teamüé°\n",
    "filtered_NSA_REPORT = OT_REPORT.filter(\n",
    "    (pl.col(\"MSA Client\") == \"Bookingcom\") & \n",
    "    (pl.col(\"Employee Status\") == \"Active\") & \n",
    "    (pl.col(\"OT_Type\") == \"NSA\") & \n",
    "    (pl.col(\"Status\") == \"Pending\")\n",
    ")\n",
    "pivot_NSA_REPORT = filtered_NSA_REPORT.pivot(\n",
    "    values=[\"Upline_Sup\",],\n",
    "    index=[\"MSA Client\",\"Function\",],\n",
    "    on=\"Date_Type\",\n",
    "    aggregate_function=\"len\" # WE can use 'first' n·∫øu ch·ªâ c√≥ 1 gi√° tr·ªã duy nh·∫•t cho m·ªói t·ªï h·ª£p index/columns\n",
    ")\n",
    " \n",
    "#Edit Column\n",
    "unique_date_types = filtered_NSA_REPORT[\"Date_Type\"].unique().to_list()\n",
    "pivot_NSA_REPORT = pivot_NSA_REPORT.with_columns([pl.col(unique_date_types).fill_null(0)])\n",
    "pivot_NSA_REPORT = pivot_NSA_REPORT.with_columns(pl.fold(0, lambda acc, s: acc + s, pl.exclude(\"MSA Client\", \"Function\",)).alias(\"Total\"))\n",
    "\n",
    "columns_to_select = [\"Function\",\"00-02 Days\", \"03-05 Days\", \"06-10 Days\", \"10 Days +\",\"Total\"]\n",
    "try:\n",
    "    pivot_NSA_REPORT = pivot_NSA_REPORT.select(columns_to_select)\n",
    "except:\n",
    "    for col in columns_to_select:\n",
    "        try:\n",
    "            pivot_NSA_REPORT.select(col)\n",
    "        except:\n",
    "            pivot_NSA_REPORT = pivot_NSA_REPORT.with_columns(pl.lit(0).cast(pl.Int64).alias(col))\n",
    "    pivot_NSA_REPORT = pivot_NSA_REPORT.select(columns_to_select)\n",
    " \n",
    "# Export to CSV\n",
    "os.chdir(DF_OT_REPORT)\n",
    "pivot_NSA_REPORT_CSV = pivot_NSA_REPORT.write_excel(\"GLB_pivot_NSA_REPORT.xlsx\", worksheet=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb114422-1c4d-4a63-88d1-0912a036f4cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]OT PIVOT to teamüé°\n",
    "filtered_OT_REPORT = OT_REPORT.filter(\n",
    "    (pl.col(\"MSA Client\") == \"Bookingcom\") & \n",
    "    (pl.col(\"Employee Status\") == \"Active\") & \n",
    "    (pl.col(\"Status\") == \"Pending\") &\n",
    "    (pl.col(\"OT_Type\").is_in([\"OT1.5X\", \"OT2.0X\", \"OT2.1X\", \"OT2.7X\", \"OT3.0X\", \"OT3.9X\"]))\n",
    ")\n",
    "pivot_OT_REPORT = filtered_OT_REPORT.pivot(\n",
    "    values=[\"Upline_Sup\",],\n",
    "    index=[\"MSA Client\",\"Function\",],\n",
    "    on=\"Date_Type\",\n",
    "    aggregate_function=\"len\" # WE can use 'first' n·∫øu ch·ªâ c√≥ 1 gi√° tr·ªã duy nh·∫•t cho m·ªói t·ªï h·ª£p index/columns\n",
    ")\n",
    " \n",
    "#Edit Column\n",
    "unique_date_types = filtered_OT_REPORT[\"Date_Type\"].unique().to_list()\n",
    "pivot_OT_REPORT = pivot_OT_REPORT.with_columns([pl.col(unique_date_types).fill_null(0)])\n",
    "pivot_OT_REPORT = pivot_OT_REPORT.with_columns(pl.fold(0, lambda acc, s: acc + s, pl.exclude(\"MSA Client\", \"Function\",)).alias(\"Total\"))\n",
    "columns_to_select = [\"Function\",\"00-02 Days\", \"03-05 Days\", \"06-10 Days\", \"10 Days +\",\"Total\"]\n",
    "try:\n",
    "    pivot_OT_REPORT = pivot_OT_REPORT.select(columns_to_select)\n",
    "except:\n",
    "    for col in columns_to_select:\n",
    "        try:\n",
    "            pivot_OT_REPORT.select(col)\n",
    "        except:\n",
    "            pivot_OT_REPORT = pivot_OT_REPORT.with_columns(pl.lit(0).cast(pl.Int64).alias(col))\n",
    "    pivot_OT_REPORT = pivot_OT_REPORT.select(columns_to_select)\n",
    " \n",
    "# Export to CSV\n",
    "os.chdir(DF_OT_REPORT)\n",
    "pivot_OT_REPORT_CSV = pivot_OT_REPORT.write_excel(\"GLB_pivot_OT_REPORT.xlsx\", worksheet=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c2d0b4f-84bb-4477-a7d0-dcb9f4f1e2e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[GLB]Pending Detail Fileüé° Combine link detail\n",
    "with xlsxwriter.Workbook(link_PENDINGDETAIL) as workbook:\n",
    "    worksheet = workbook.add_worksheet('NM Pending Detail') # Create a new worksheet.\n",
    "    filtered_NM_REPORT.write_excel(workbook=workbook, worksheet=\"NM Pending Detail\", position=\"A1\") # Do something with the worksheet.\n",
    " \n",
    "    worksheet = workbook.add_worksheet('OT Pending Detail') # Create a new worksheet.\n",
    "    filtered_OT_REPORT.write_excel(workbook=workbook, worksheet=\"OT Pending Detail\", position=\"A1\") # Do something with the worksheet.\n",
    " \n",
    "    worksheet = workbook.add_worksheet('NSA Pending Detail') # Create a new worksheet.\n",
    "    filtered_NSA_REPORT.write_excel(workbook=workbook, worksheet=\"NSA Pending Detail\", position=\"A1\") # Do something with the worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5c2eae5-36df-4468-917f-0b4fc6dc1ce8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]Login report link Detailüé° (Dillip team)\n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    "select [Date],[Week_day] as [Weekday],[Emp ID],[Emp_Name] as [Name],[Booking login ID] as [Username], [Wave],[TL_Name] as [Sup],[LOB] as [LOBs],[Shift],\n",
    " \n",
    "[Productive(s)]/3600.0 as [THT (In hours)],CAST([Stafftime(s)]+[ExceptionReq(s)] as float)/3600.0 as [Staffed hours],\n",
    " \n",
    "[Break(s)]/3600.0 as [Non Productive Aux(In Hours)],[Delivery(s)]/3600.0 as [Delivered hours],\n",
    " \n",
    "[Phone_#TED]+[Phone_#PEGA] as [Total Phone Tickets], [NonPhone_#TED]+[NonPhone_#PEGA] as [Total Non-phone Tickets],[AgentAvailTime(s)]/3600.0 as [Avail Time(In Hours)],\n",
    " \n",
    "[Downtime(s)]/3600.0 as [Other Productive Aux(In Hours)],(CAST([Break(s)]as float)+CAST([Lunch(s)] as float))/3600.0 as [Total break (In hours)]\n",
    " \n",
    "FROM BCOM.EEAAO\n",
    " \n",
    "where Date < DATEADD(DAY, -1,CAST(GETDATE() As Date)) and Date> DATEADD(DAY, -30,CAST(GETDATE() As Date)) and [Stafftime(s)]>0\n",
    "\n",
    " \n",
    "\n",
    "\"\"\"\n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "Login_detail_raw = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "Login_detail = Login_detail_raw.to_pandas()\n",
    "Login_detail['Date']=pd.to_datetime(Login_detail['Date']).dt.date\n",
    "Login_detail=Login_detail[['Date','Weekday','Emp ID','Name','Username','Wave','Sup','LOBs','Shift','Delivered hours',\n",
    "                           'Staffed hours','Total Phone Tickets','Total Non-phone Tickets']]\n",
    "Login_detail = pl.from_pandas(Login_detail)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7ec00f8-acf9-4c53-8934-9ebc84e42a34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]Login Summary Pivot (Dillip team)üé°\n",
    "Login_summary = Login_detail_raw.to_pandas()\n",
    "Login_summary['Date']=pd.to_datetime(Login_summary['Date']).dt.date\n",
    "Login_summary=Login_summary[['Date','Staffed hours','Total break (In hours)','THT (In hours)','Avail Time(In Hours)',\n",
    "                             'Other Productive Aux(In Hours)','Non Productive Aux(In Hours)']]\n",
    "Login_summary['Location'] = 'HCM'\n",
    "Login_summary['Country'] = 'Vietnam'\n",
    "Login_summary['Account'] = 'Booking.com'\n",
    "Login_summary['Work Status'] = 'WFO'\n",
    "Login_summary['Present for calculation'] = 1\n",
    "Login_summary=Login_summary.groupby(['Date','Location','Country','Account','Work Status'],as_index=False).sum()\n",
    "Login_summary=Login_summary.sort_values(by='Date',ascending=True)\n",
    "Login_summary = pl.from_pandas(Login_summary)\n",
    "\n",
    "\n",
    "# Export to xlsx\n",
    "# os.chdir(DF_LOGIN_DF)\n",
    "# writer = pd.ExcelWriter(\"Booking - Agent Wise Login Detail.xlsx\", engine=\"xlsxwriter\")\n",
    "# Login_summary.to_excel(writer, sheet_name=\"Overall Login\", startrow=1, header=False, index=False)\n",
    "# workbook = writer.book\n",
    "# worksheet = writer.sheets[\"Overall Login\"]\n",
    "# (max_row, max_col) = Login_summary.shape\n",
    "# column_settings = [{\"header\": column} for column in Login_summary.columns]\n",
    "# worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings})\n",
    "# worksheet.set_column(0, max_col - 1, 12)\n",
    "# writer.close()\n",
    "\n",
    "with xlsxwriter.Workbook(DF_LOGIN_DF) as workbook:\n",
    "    worksheet = workbook.add_worksheet('Overall Login') # Create a new worksheet.\n",
    "    Login_summary.write_excel(workbook=workbook, worksheet=\"Overall Login\", position=\"A1\") # Do something with the worksheet.\n",
    "\n",
    "    worksheet = workbook.add_worksheet('Agent wise Login') # Create a new worksheet.\n",
    "    Login_detail.write_excel(workbook=workbook, worksheet=\"Agent wise Login\", position=\"A1\") # Do something with the worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "254da566-1a8a-4f06-b0bc-34141ae1999f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call out Login-Logout\n",
    "today = datetime.date.today()\n",
    "weekday=today.weekday()\n",
    "last_week = today - datetime.timedelta(days=4) \n",
    "weeknum_last_week = last_week.isocalendar().week \n",
    "year_last_week = last_week.year\n",
    "# T·∫°o chu·ªói k·∫øt h·ª£p nƒÉm v√† weeknum, ƒë·∫£m b·∫£o weeknum c√≥ 2 ch·ªØ s·ªë\n",
    "result =f\"{year_last_week}{weeknum_last_week:02d}\"\n",
    "text=\"Call out Login_Logout W\"\n",
    "path=\".xlsx\"\n",
    "filename= text+result+path\n",
    "\n",
    "def find_excel_files(folder_path):  \n",
    "  excel_files = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.xls', '.xlsx')):\n",
    "      excel_files.append(os.path.basename(filename))  # Ch·ªâ l·∫•y t√™n file\n",
    "  return excel_files\n",
    "folder_path = Login_Logout_Folder  # Thay th·∫ø b·∫±ng ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c c·ªßa b·∫°n\n",
    "excel_files = find_excel_files(folder_path)\n",
    "\n",
    "if weekday==2:\n",
    "    def check_file_in_list(filename, list_filenames):\n",
    "        return filename in list_filenames\n",
    "    result = check_file_in_list(filename, excel_files)  # result s·∫Ω l√† True\n",
    "    if result==False:\n",
    "        sql_query = \"\"\"\n",
    "\n",
    "\t\tSELECT [Emp ID],[Week_num],[Date],[LOB],[Tenure days],[OM_Name],[TL_Name],[TED Name],[shift],[Login],[Logout],[Late-Soon] \n",
    "\t\tFROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "\t\tand [Late-Soon] <>'' and [Shift]<>'New Hire Training'\n",
    "\t\torder by [Date] asc\n",
    "\n",
    "        \"\"\"\n",
    "        # ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "        login_logout = pl.read_database(query=sql_query, connection=engine)\n",
    "        engine.dispose()\n",
    "\n",
    "        # Export to Pivot\n",
    "        login_logout_pivot = login_logout.pivot(\n",
    "            values=[\"Emp ID\",],\n",
    "            index=[\"OM_Name\",\"TL_Name\",],\n",
    "            on=\"Late-Soon\",\n",
    "            aggregate_function=\"len\" # WE can use 'first' n·∫øu ch·ªâ c√≥ 1 gi√° tr·ªã duy nh·∫•t cho m·ªói t·ªï h·ª£p index/columns\n",
    "        )\n",
    "        login_logout_pivot = login_logout_pivot.fill_null(0).select([pl.all().sort_by(\"OM_Name\")]) \n",
    "        login_logout_pivot = login_logout_pivot.to_pandas()\n",
    "\n",
    "        # Export to xlsx\n",
    "        os.chdir(BKN_Folder)\n",
    "        # login_logout_pivot = login_logout_pivot.write_excel(\"Login_Logout_Pivot.xlsx\", worksheet=\"Pivot\", autofit=True)        \n",
    "        writer = pd.ExcelWriter(\"Login_Logout_Pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "        login_logout_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "        (max_row, max_col) = login_logout_pivot.shape\n",
    "        column_settings = [{\"header\": column} for column in login_logout_pivot.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "        worksheet.set_column(0, max_col - 1, 13)\n",
    "        worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "        writer.close()          \n",
    "        \n",
    "        # Export to Detail\n",
    "        login_logout = login_logout.to_pandas()\n",
    "        writer = pd.ExcelWriter(Login_Logout_Folder+\"//\"+filename, engine='xlsxwriter') \n",
    "        login_logout.to_excel(writer, sheet_name=\"Detail\", startrow=0, index=False)\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Detail']        \n",
    "        worksheet.set_column('A:N', 11)\n",
    "        \n",
    "        #Adding the header and Datavalidation list\n",
    "        worksheet.write('M1', 'Reason')\n",
    "        worksheet.data_validation('M2:M1000', {'validate': 'list',\n",
    "                                          'source': ['Seat Issue','Technical Issue','Non-adherence shift'\n",
    "                                                    ,'Traffic Issue','Personal Issue'\n",
    "                                                     ,'Parking Issue','Badge Issue'\n",
    "                                                    ,'Weather Issue','No insight given','Yubikey + Prepare for shift']})\n",
    "        worksheet.write('N1', 'Please provide insight here')\n",
    "        workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a66849e-bfe8-42d2-9656-8d17f1ee9553",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Call out Stafftime\n",
    "today = datetime.date.today()\n",
    "weekday=today.weekday()\n",
    "last_week = today - datetime.timedelta(days=4) \n",
    "weeknum_last_week = last_week.isocalendar().week \n",
    "year_last_week = last_week.year\n",
    "# T·∫°o chu·ªói k·∫øt h·ª£p nƒÉm v√† weeknum, ƒë·∫£m b·∫£o weeknum c√≥ 2 ch·ªØ s·ªë\n",
    "result =f\"{year_last_week}{weeknum_last_week:02d}\"\n",
    "text=\"Call out Shortage of Stafftime W\"\n",
    "path=\".xlsx\"\n",
    "filename= text+result+path\n",
    "\n",
    "def find_excel_files(folder_path):  \n",
    "  excel_files = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.xls', '.xlsx')):\n",
    "      excel_files.append(os.path.basename(filename))  # Ch·ªâ l·∫•y t√™n file\n",
    "  return excel_files\n",
    "folder_path = Stafftime_Folder  # Thay th·∫ø b·∫±ng ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c c·ªßa b·∫°n\n",
    "excel_files = find_excel_files(folder_path)\n",
    "\n",
    "if weekday==2:\n",
    "    def check_file_in_list(filename, list_filenames):\n",
    "        return filename in list_filenames\n",
    "    result = check_file_in_list(filename, excel_files)  # result s·∫Ω l√† True\n",
    "    if result==False:\n",
    "        sql_query = \"\"\"   \n",
    "        SELECT [Week_num],[Date],[LOB],[OM_Name],[TL_Name],[shift],[Emp ID],[Emp_Name],[Ramco_Code] as [RAMCO],[Login],[Logout],\n",
    "        CAST([Stafftime(s)] as float)/3600 as [Stafftime(H)],CAST([ExceptionReq(s)] as float)/3600 as [ExceptionReq(H)],CAST([Stafftime(s)] +[ExceptionReq(s)] as float)/3600 as [Total Present time]\n",
    "        FROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "\t\tand CAST([Stafftime(s)] +[ExceptionReq(s)] as float)/3600 <7.5 and [Ramco_Code]='PR' and [Shift]<>'New Hire Training' and [Work Type]<>'Part time'\n",
    "\t\torder by [Date] asc\n",
    "        \"\"\"\n",
    "        stafftime = pl.read_database(query=sql_query, connection=engine)\n",
    "        engine.dispose()\n",
    "        # Export to Pivot\n",
    "        stafftime_pivot = (\n",
    "            stafftime.group_by([\"OM_Name\", \"TL_Name\"])\n",
    "            .agg(\n",
    "                [\n",
    "                    pl.col(\"Emp ID\").count().alias(\"Cases\")\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        stafftime_pivot = stafftime_pivot.fill_null(0).select([pl.all().sort_by(\"OM_Name\")]) \n",
    "        stafftime_pivot = stafftime_pivot.to_pandas()\n",
    "        stafftime_pivot = stafftime_pivot.sort_values(by='Cases',ascending=False)\n",
    "        # Export to xlsx\n",
    "        os.chdir(BKN_Folder)\n",
    "        writer = pd.ExcelWriter(\"Stafftime_Pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "        stafftime_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "        (max_row, max_col) = stafftime_pivot.shape\n",
    "        column_settings = [{\"header\": column} for column in stafftime_pivot.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "        worksheet.set_column(0, max_col - 1, 13)\n",
    "        worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "        writer.close()          \n",
    "        \n",
    "        # Export to Detail\n",
    "        stafftime = stafftime.to_pandas()\n",
    "        writer = pd.ExcelWriter(Stafftime_Folder+\"//\"+filename, engine='xlsxwriter') \n",
    "        stafftime.to_excel(writer, sheet_name=\"Detail\", startrow=0, index=False)\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Detail']        \n",
    "        worksheet.set_column('A:P', 11)\n",
    "        \n",
    "        #Adding the header and Datavalidation list\n",
    "        worksheet.write('O1', 'Reason')\n",
    "        worksheet.data_validation('O2:O1000', {'validate': 'list',\n",
    "                                          'source': ['HAL','Non-adherence shift','Personal Issue'\n",
    "                                                    ,'Ramco mismatch','Technical issue','No insight given','Mismatch RAMCO']})\n",
    "        worksheet.write('P1', 'Please provide insight here')\n",
    "        workbook.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c80c173-a5b1-40a3-80e1-63cdeefff6d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Call out LOW_CPH\n",
    "today = datetime.date.today()\n",
    "weekday=today.weekday()\n",
    "last_week = today - datetime.timedelta(days=4) \n",
    "weeknum_last_week = last_week.isocalendar().week \n",
    "year_last_week = last_week.year\n",
    "# T·∫°o chu·ªói k·∫øt h·ª£p nƒÉm v√† weeknum, ƒë·∫£m b·∫£o weeknum c√≥ 2 ch·ªØ s·ªë\n",
    "result =f\"{year_last_week}{weeknum_last_week:02d}\"\n",
    "text=\"Low_CPH_Insight_W\"\n",
    "path=\".xlsx\"\n",
    "filename= text+result+path\n",
    "\n",
    "def find_excel_files(folder_path):  \n",
    "  excel_files = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.xls', '.xlsx')):\n",
    "      excel_files.append(os.path.basename(filename))  # Ch·ªâ l·∫•y t√™n file\n",
    "  return excel_files\n",
    "folder_path = Low_CPH_Folder  # Thay th·∫ø b·∫±ng ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c c·ªßa b·∫°n\n",
    "excel_files = find_excel_files(folder_path)\n",
    "\n",
    "if weekday==2:\n",
    "    def check_file_in_list(filename, list_filenames):\n",
    "        return filename in list_filenames\n",
    "    result = check_file_in_list(filename, excel_files)  # result s·∫Ω l√† True\n",
    "    if result==False:\n",
    "        sql_query = \"\"\"  \n",
    "        SELECT [Week_num],[OM_Name],[TL_Name],[Emp ID],[Emp_Name],\n",
    "        CASE WHEN SUM([Productive(s)])=0 THEN 0 ELSE Sum([Total_Cases])/(Sum(CAST([Productive(s)] as float))/3600) END as [CPH],\n",
    "        sum(CAST([Productive(s)] as float))/3600 as [Productive (H)],\n",
    "\t\tsum([Total_Cases]) as [Case],\n",
    "        CASE WHEN SUM([Csat Survey])=0 THEN 0 ELSE CAST(sum(CAST([Csat Score] AS FLOAT))/sum(CAST([Csat Survey] AS FLOAT)) AS FLOAT) END as [CSAT],\n",
    "        sum([Csat Survey]) as [Survey]\n",
    "               \n",
    "        FROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "        and LOB <> 'Senior VICSP' and [Shift]<>'New Hire Training'\n",
    "        group by [Week_num],[OM_Name],[TL_Name],[Emp ID],[Emp_Name] \n",
    "                \"\"\"\n",
    "        Low_CPH = pl.read_database(query=sql_query, connection=engine)\n",
    "        engine.dispose()\n",
    "        Low_CPH =Low_CPH.filter((pl.col(\"CPH\")<1.5)&(pl.col(\"Productive (H)\")>0))\n",
    "        # Export to Pivot\n",
    "        Low_CPH_pivot = (\n",
    "            Low_CPH.group_by([\"OM_Name\", \"TL_Name\"])\n",
    "            .agg(\n",
    "                [\n",
    "                    pl.col(\"Emp ID\").count().alias(\"Cases\")\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        Low_CPH_pivot = Low_CPH_pivot.fill_null(0).select([pl.all().sort_by(\"OM_Name\")]) \n",
    "        Low_CPH_pivot = Low_CPH_pivot.to_pandas()\n",
    "        Low_CPH_pivot = Low_CPH_pivot.sort_values(by='Cases',ascending=False)\n",
    "        # Export to xlsx\n",
    "        os.chdir(BKN_Folder)\n",
    "        writer = pd.ExcelWriter(\"Low_CPH_Pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "        Low_CPH_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "        (max_row, max_col) = Low_CPH_pivot.shape\n",
    "        column_settings = [{\"header\": column} for column in Low_CPH_pivot.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                         ,\"style\": \"Table Style Light 9\"})\n",
    "        worksheet.set_column(0, max_col - 1, 13)\n",
    "        worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "        writer.close()          \n",
    "        \n",
    "        # Export to Detail\n",
    "        Low_CPH = Low_CPH.to_pandas()\n",
    "        writer = pd.ExcelWriter(Low_CPH_Folder+\"//\"+filename, engine='xlsxwriter') \n",
    "        Low_CPH.to_excel(writer, sheet_name=\"Detail\", startrow=0, index=False)\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Detail']        \n",
    "        worksheet.set_column('A:L', 11)\n",
    "        \n",
    "        #Adding the header and Datavalidation list\n",
    "        worksheet.write('K1', 'Reason')\n",
    "        worksheet.data_validation('K2:K1000', {'validate': 'list',\n",
    "                                          'source': ['Bad Quality','Behavior Issue','Cases not counted to CPH'\n",
    "                                                     ,'Complicated cases','Control CSAT','Health Issue'\n",
    "                                                     ,'Long leave','Newbie','Newly Transferred'\n",
    "                                                    ,'Promoted','Resigned','No insight given'\n",
    "                                                    ,'Skill Issue','Support Newbie','Technical Issue'\n",
    "                                                     ]})\n",
    "        worksheet.write('L1', 'Please provide insight here')\n",
    "        workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f19a248a-a87f-48f9-88a4-628c02d644ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Call out OOH\n",
    "today = datetime.date.today()\n",
    "weekday=today.weekday()\n",
    "last_week = today - datetime.timedelta(days=4) \n",
    "weeknum_last_week = last_week.isocalendar().week \n",
    "year_last_week = last_week.year\n",
    "# T·∫°o chu·ªói k·∫øt h·ª£p nƒÉm v√† weeknum, ƒë·∫£m b·∫£o weeknum c√≥ 2 ch·ªØ s·ªë\n",
    "result =f\"{year_last_week}{weeknum_last_week:02d}\"\n",
    "text=\"Call out Out of Hoop_W\"\n",
    "path=\".xlsx\"\n",
    "filename= text+result+path\n",
    "\n",
    "def find_excel_files(folder_path):  \n",
    "  excel_files = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.xls', '.xlsx')):\n",
    "      excel_files.append(os.path.basename(filename))  # Ch·ªâ l·∫•y t√™n file\n",
    "  return excel_files\n",
    "folder_path = Low_CPH_Folder  # Thay th·∫ø b·∫±ng ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c c·ªßa b·∫°n\n",
    "excel_files = find_excel_files(folder_path)\n",
    "\n",
    "if weekday==2:\n",
    "    def check_file_in_list(filename, list_filenames):\n",
    "        return filename in list_filenames\n",
    "    result = check_file_in_list(filename, excel_files)  # result s·∫Ω l√† True\n",
    "    if result==False:\n",
    "        sql_query = \"\"\"  \t\t\n",
    "        with LI as (\n",
    "\t\tSELECT [Date],[Week_num],[OM_Name],[TL_Name],[Emp ID],[Emp_Name],[Shift],[LOB],[Login],[Logout],\n",
    "        case when [LoggedInBeforeShift]='1' then 'Logged in soon' else '' end as [WFM_Note]               \n",
    "        FROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "        and [LoggedInBeforeShift]='1' \n",
    "        and [LOB]<>'EN'),\n",
    "\t\tLO as (\n",
    "\t\tSELECT [Date],[Week_num],[OM_Name],[TL_Name],[Emp ID],[Emp_Name],[Shift],[LOB],[Login],[Logout],\n",
    "        case when [NotLoggedOutAfterShift]='1' then 'Logged out late' else '' end as [WFM_Note]          \n",
    "        FROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "        and [NotLoggedOutAfterShift]='1' \n",
    "        and [LOB]<>'EN')\n",
    "\t\tselect * from LI\n",
    "\t\tunion all\n",
    "        SELECT * FROM LO\n",
    "        \"\"\"\n",
    "        OOH = pl.read_database(query=sql_query, connection=engine)\n",
    "        engine.dispose()\n",
    "\n",
    "        # Export to Pivot\n",
    "        OOH_pivot =(\n",
    "            OOH.group_by([\"OM_Name\", \"TL_Name\"])\n",
    "            .agg(\n",
    "                [\n",
    "                    pl.col(\"Emp ID\").count().alias(\"Cases\")\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        OOH_pivot = OOH_pivot.fill_null(0).select([pl.all().sort_by(\"OM_Name\")]) \n",
    "        OOH_pivot = OOH_pivot.to_pandas()\n",
    "        OOH_pivot = OOH_pivot.sort_values(by='Cases',ascending=False)\n",
    "        # Export to xlsx\n",
    "        os.chdir(BKN_Folder)\n",
    "        writer = pd.ExcelWriter(\"OOH_Pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "        OOH_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "        (max_row, max_col) = OOH_pivot.shape\n",
    "        column_settings = [{\"header\": column} for column in OOH_pivot.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                         ,\"style\": \"Table Style Light 9\"})\n",
    "        worksheet.set_column(0, max_col - 1, 13)\n",
    "        worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "        writer.close()          \n",
    "        \n",
    "        # Export to Detail\n",
    "        OOH = OOH.to_pandas()\n",
    "        writer = pd.ExcelWriter(OOH_Folder+\"//\"+filename, engine='xlsxwriter') \n",
    "        OOH.to_excel(writer, sheet_name=\"Detail\", startrow=0, index=False)\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Detail']        \n",
    "        worksheet.set_column('A:L', 11)\n",
    "        \n",
    "        #Adding the header and Datavalidation list\n",
    "        worksheet.write('L1', 'Reason')\n",
    "        worksheet.data_validation('L2:L1000', {'validate': 'list',\n",
    "                                          'source': ['Scheduling misinformation'\n",
    "                                                     ,'Missing logout time','Technical issue'\n",
    "                                                     ,'Handling case over logout time','Prepare for the shift'\n",
    "                                                    ,'No insight given','Non-adherence shift time'\n",
    "                                                     ]})\n",
    "        worksheet.write('M1', 'Please provide insight here')\n",
    "        workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ea3bf91-1e35-4123-ad11-373bee9e63f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Call out LOGOUTCOUNT\n",
    "today = datetime.date.today()\n",
    "weekday=today.weekday()\n",
    "last_week = today - datetime.timedelta(days=4) \n",
    "weeknum_last_week = last_week.isocalendar().week \n",
    "year_last_week = last_week.year\n",
    "# T·∫°o chu·ªói k·∫øt h·ª£p nƒÉm v√† weeknum, ƒë·∫£m b·∫£o weeknum c√≥ 2 ch·ªØ s·ªë\n",
    "result =f\"{year_last_week}{weeknum_last_week:02d}\"\n",
    "text=\"Call out LOGOUT_COUNT W\"\n",
    "path=\".xlsx\"\n",
    "filename= text+result+path\n",
    "\n",
    "def find_excel_files(folder_path):  \n",
    "  excel_files = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.xls', '.xlsx')):\n",
    "      excel_files.append(os.path.basename(filename))  # Ch·ªâ l·∫•y t√™n file\n",
    "  return excel_files\n",
    "folder_path = Logout_Count_Folder  # Thay th·∫ø b·∫±ng ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c c·ªßa b·∫°n\n",
    "excel_files = find_excel_files(folder_path)\n",
    "\n",
    "if weekday==2:\n",
    "    def check_file_in_list(filename, list_filenames):\n",
    "        return filename in list_filenames\n",
    "    result = check_file_in_list(filename, excel_files)  # result s·∫Ω l√† True\n",
    "    if result==False:\n",
    "        sql_query = \"\"\" \t\t\n",
    "        select [Week_num],[Date],[Emp ID],[Emp_Name],[TED Name],[shift],[OM_Name],[TL_Name],[Login],[Logout],[Logout_Count]       \n",
    "        FROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "        and [Logout_Count]>=50\n",
    "                  \"\"\"\n",
    "        Logout_Count = pl.read_database(query=sql_query, connection=engine)\n",
    "        engine.dispose()\n",
    "        # Export to Pivot\n",
    "        Logout_Count_pivot = (\n",
    "            Logout_Count.group_by([\"OM_Name\", \"TL_Name\"])\n",
    "            .agg(\n",
    "                [\n",
    "                    pl.col(\"Emp ID\").count().alias(\"Cases\")\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        Logout_Count_pivot = Logout_Count_pivot.to_pandas()\n",
    "        Logout_Count_pivot = Logout_Count_pivot.sort_values(by='Cases',ascending=False)\n",
    "\n",
    "        # Export to xlsx\n",
    "        os.chdir(BKN_Folder)\n",
    "        writer = pd.ExcelWriter(\"Logout_Count_Pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "        Logout_Count_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "        (max_row, max_col) = Logout_Count_pivot.shape\n",
    "        column_settings = [{\"header\": column} for column in Logout_Count_pivot.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "        worksheet.set_column(0, max_col - 1, 13)\n",
    "        worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "        writer.close()          \n",
    "        \n",
    "        # Export to Detail\n",
    "        Logout_Count = Logout_Count.to_pandas()\n",
    "        writer = pd.ExcelWriter(Logout_Count_Folder+\"//\"+filename, engine='xlsxwriter') \n",
    "        Logout_Count.to_excel(writer, sheet_name=\"Count>=50\", startrow=0, index=False)\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Count>=50']        \n",
    "        worksheet.set_column('A:M', 11)\n",
    "        \n",
    "        #Adding the header and Datavalidation list\n",
    "        worksheet.write('L1', 'Reason')\n",
    "        worksheet.data_validation('L2:L1000', {'validate': 'list',\n",
    "                                          'source': ['Behavior','Low Volume','Personal Issue'\n",
    "                                                    ,'Ramco mismatch','Technical issue','No insight given']})\n",
    "        worksheet.write('M1', 'Please provide insight here')\n",
    "        workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7678ebe5-d9b6-423e-9647-e0320aeb7293",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Stability Report\n",
    "import os, glob, re\n",
    "from datetime import timedelta, datetime as dt, time as t, date as d\n",
    "import polars as pl\n",
    "from sqlalchemy import create_engine, text\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Source collection\n",
    "\n",
    "user_credential = os.path.join(os.environ['USERPROFILE'],r'Concentrix Corporation//CNXVN - WFM Team - Documents//')\n",
    "\n",
    "# INPUT-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ-----üíæ\n",
    "# [BKN]Error Log\n",
    "LOG_LINK = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN//MODIFIED_LOG//*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "184fe5a7-d4dc-48e4-af8b-9fde26218255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data code 1\n",
    " \n",
    "# C√¢u l·ªánh SQL\n",
    "sql_query = \"\"\"\n",
    " \n",
    " \n",
    "WITH CombinedData AS (\n",
    "-- 01/ BCOM.AHT \n",
    "    SELECT 'BKN' AS [SCHEMA], 'AHT' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.AHT2\n",
    "    UNION ALL\n",
    "-- 02/ BCOM.CapHC \n",
    "    SELECT 'BKN' AS [SCHEMA], 'CapHC' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CapHC\n",
    "    UNION ALL\n",
    "-- 03/ BCOM.Contrack\n",
    "    SELECT 'BKN' AS [SCHEMA], 'Contrack' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.Contrack\n",
    "    UNION ALL\n",
    "-- 04/ BCOM.CPI\n",
    "    SELECT 'BKN' AS [SCHEMA], 'CPI' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CPI\n",
    "    UNION ALL\n",
    "-- 05/ BCOM.CPI_PEGA\n",
    "    SELECT 'BKN' AS [SCHEMA], 'CPI_PEGA' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CPI_PEGA\n",
    "    UNION ALL\n",
    "-- 06/ BCOM.CSAT_RS\n",
    "    SELECT 'BKN' AS [SCHEMA], 'CSAT_RS' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CSAT_RS\n",
    "    UNION ALL\n",
    "-- 07/ BCOM.CSAT_TP\n",
    "    SELECT 'BKN' AS [SCHEMA], 'CSAT_TP' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CSAT_TP\n",
    "    UNION ALL\n",
    "-- 08/ BCOM.CUIC\n",
    "    SELECT 'BKN' AS [SCHEMA], 'CUIC' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CUIC\n",
    "    UNION ALL\n",
    "-- 10/ BCOM.DailyReq\n",
    "    SELECT 'BKN' AS [SCHEMA], 'DailyReq' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.DailyReq\n",
    "    UNION ALL\n",
    "-- 11/ BCOM.EPS\n",
    "    SELECT 'BKN' AS [SCHEMA], 'EPS' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.EPS\n",
    "    UNION ALL\n",
    "-- 12/ BCOM.ExceptionReq\n",
    "    SELECT 'BKN' AS [SCHEMA], 'ExceptionReq' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.ExceptionReq\n",
    "    UNION ALL\n",
    "-- 13/ BCOM.IEX_Hrs\n",
    "    SELECT 'BKN' AS [SCHEMA], 'IEX_Hrs' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.IEX_Hrs\n",
    "    UNION ALL\n",
    "-- 14/ BCOM.IntervalReq\n",
    "    SELECT 'BKN' AS [SCHEMA], 'IntervalReq' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.IntervalReq\n",
    "    UNION ALL\n",
    "-- 15/ BCOM.KPI_Target\n",
    "    SELECT 'BKN' AS [SCHEMA], 'KPI_Target' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.KPI_Target\n",
    "    UNION ALL\n",
    "-- 16/ BCOM.LogoutCount\n",
    "    SELECT 'BKN' AS [SCHEMA], 'LogoutCount' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.LogoutCount\n",
    "    UNION ALL\n",
    "-- 17/ BCOM.LTTransfers\n",
    "    SELECT 'BKN' AS [SCHEMA], 'LTTransfers' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.LTTransfers\n",
    "    UNION ALL\n",
    "-- 18/ BCOM.OTReq\n",
    "    SELECT 'BKN' AS [SCHEMA], 'OTReq' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.OTReq\n",
    "    UNION ALL\n",
    "-- 19/ BCOM.ProjectedHC\n",
    "    SELECT 'BKN' AS [SCHEMA], 'ProjectedHC' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.ProjectedHC\n",
    "    UNION ALL\n",
    "-- 20/ BCOM.ProjectedShrink\n",
    "    SELECT 'BKN' AS [SCHEMA], 'ProjectedShrink' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.ProjectedShrink\n",
    "    UNION ALL\n",
    "-- 21/ BCOM.PSAT\n",
    "    SELECT 'BKN' AS [SCHEMA], 'PSAT' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.PSAT\n",
    "    UNION ALL\n",
    "-- 22/ BCOM.Quality\n",
    "    SELECT 'BKN' AS [SCHEMA], 'Quality' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.Quality\n",
    "    UNION ALL\n",
    "-- 23/ BCOM.RegisteredOT\n",
    "    SELECT 'BKN' AS [SCHEMA], 'RegisteredOT' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.RegisteredOT\n",
    "    UNION ALL\n",
    "-- 24/ BCOM.RONA\n",
    "    SELECT 'BKN' AS [SCHEMA], 'RONA' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.RONA\n",
    "    UNION ALL\n",
    "-- 25/ BCOM.ROSTER\n",
    "    SELECT 'BKN' AS [SCHEMA], 'ROSTER' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.ROSTER\n",
    "    UNION ALL\n",
    "-- 26/ BCOM.Staff\n",
    "    SELECT 'BKN' AS [SCHEMA], 'Staff' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.Staff\n",
    "    UNION ALL\n",
    "-- 27/ BCOM.WpDetail\n",
    "    SELECT 'BKN' AS [SCHEMA], 'WpDetail' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.WpDetail\n",
    "    UNION ALL\n",
    "-- 28/ BCOM.WpSummary\n",
    "    SELECT 'BKN' AS [SCHEMA], 'WpSummary' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.WpSummary\n",
    "    UNION ALL\n",
    "-- 29/ GLB.EmpMaster\n",
    "    SELECT 'GLB' AS [SCHEMA], 'EmpMaster' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.EmpMaster\n",
    "    UNION ALL\n",
    "-- 30/ GLB.NormHdays\n",
    "    SELECT 'GLB' AS [SCHEMA], 'NormHdays' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.NormHdays\n",
    "    UNION ALL\n",
    "-- 31/ GLB.OT_RAMCO\n",
    "    SELECT 'GLB' AS [SCHEMA], 'OT_RAMCO' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.OT_RAMCO\n",
    "    UNION ALL\n",
    "-- 32/ GLB.PremHdays\n",
    "    SELECT 'GLB' AS [SCHEMA], 'PremHdays' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.PremHdays\n",
    "    UNION ALL\n",
    "-- 33/ GLB.RAMCO\n",
    "    SELECT 'GLB' AS [SCHEMA], 'RAMCO' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.RAMCO\n",
    "    UNION ALL\n",
    "-- 34/ GLB.Resignation\n",
    "    SELECT 'GLB' AS [SCHEMA], 'Resignation' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.Resignation\n",
    "    UNION ALL\n",
    "-- 35/ GLB.Termination\n",
    "    SELECT 'GLB' AS [SCHEMA], 'Termination' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.Termination\n",
    "),\n",
    "FileNameCheck AS (\n",
    "    SELECT [SCHEMA],[FOLDER NAME],[FileName] + ' - ' + CONVERT(VARCHAR, [ModifiedDate], 120) AS [FileName - ModifiedDate],COUNT(*) \n",
    "\tAS [ROW_NUMBER]\n",
    "    FROM CombinedData\n",
    "    GROUP BY [SCHEMA], [FOLDER NAME], [FileName] + ' - ' + CONVERT(VARCHAR, [ModifiedDate], 120)\n",
    "    HAVING COUNT(*) > 1\n",
    ")\n",
    "SELECT * FROM FileNameCheck\n",
    "ORDER BY [SCHEMA] ASC, [FOLDER NAME] DESC, [FileName - ModifiedDate] ASC\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "Code1_Result = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b793adc6-f6ba-4e4a-b3b8-a3d4ae32a4ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Data code 2\n",
    "engine = create_engine(connection_string)\n",
    " \n",
    "# C√¢u l·ªánh SQL\n",
    "\n",
    "sql_query2 = \"\"\"\n",
    "with\n",
    "-- 1. Agent Raw\n",
    "Agents_Raw1 as\n",
    "(Select Employee_ID, COUNT(*) as [Count]\n",
    "From BCOM.Staff\n",
    "Group by Employee_ID Having COUNT(*)>1),\n",
    "-- 2. AHT Raw üìù\n",
    "AHT_Raw1 as\n",
    "(Select  [Agent Name Display]+cast([Date] AS varchar)+[Answered Language Name]+[Measure Names] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.AHT2\n",
    "Where    [Agent Name Display]+cast([Date] AS varchar)+[Answered Language Name]+[Measure Names] Is not Null\n",
    "Group by [Agent Name Display]+cast([Date] AS varchar)+[Answered Language Name]+[Measure Names] Having COUNT(*)>1),\n",
    "-- 3. Capacity HC üìù\n",
    "CapacityHC_Raw1 as\n",
    "(Select  [LOB]+cast([Date] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CapHC\n",
    "Where    [LOB]+cast([Date] as varchar) is not Null\n",
    "Group by [LOB]+cast([Date] as varchar) Having COUNT(*)>1),\n",
    "-- 4. CSAT Raw üìù\n",
    "CSAT_Raw1 as\n",
    "(Select  cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CSAT_TP\n",
    "Where    cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] is not Null\n",
    "Group by cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] Having COUNT(*)>1),\n",
    "-- 5. CSAT Reso Raw üìù\n",
    "CSAT_Reso_Raw as\n",
    "(Select  cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CSAT_RS\n",
    "Where    cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] is not Null\n",
    "Group by cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] Having COUNT(*)>1),\n",
    "-- 6. CUIC Raw üìù\n",
    "CUIC_Raw1 as\n",
    "(Select [FullName]+[LoginName]+cast([Interval] as varchar)+cast([AgentLoggedOnTime] as varchar)+cast([AgentAvailTime] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CUIC\n",
    "Where    [FullName]+[LoginName]+cast([Interval] as varchar)+cast([AgentLoggedOnTime] as varchar)+cast([AgentAvailTime] as varchar) is not Null\n",
    "Group by [FullName]+[LoginName]+cast([Interval] as varchar)+cast([AgentLoggedOnTime] as varchar)+cast([AgentAvailTime] as varchar) Having COUNT(*)>1),\n",
    "-- 7. EEAAO üìù\n",
    "\n",
    "-- 8. EPS Raw üìù\n",
    "EPS_Raw1 as\n",
    "(Select  [Username]+cast([Session Login] as varchar)+cast([Session Logout] as varchar)+[BPE Code]+[Session Time]+cast([Total Time] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.EPS\n",
    "Where    [Username]+cast([Session Login] as varchar)+cast([Session Logout] as varchar)+[BPE Code]+[Session Time]+cast([Total Time] as varchar) is not Null\n",
    "Group by [Username]+cast([Session Login] as varchar)+cast([Session Logout] as varchar)+[BPE Code]+[Session Time]+cast([Total Time] as varchar) Having COUNT(*)>1),\n",
    "-- 9. Exception Req üìù\n",
    "Exception_Req as\n",
    "(Select [Emp ID]+cast([Date (MM/DD/YYYY)] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From BCOM.ExceptionReq\n",
    "Where [Emp ID]+cast([Date (MM/DD/YYYY)] as varchar) is not null\n",
    "Group by [Emp ID]+cast([Date (MM/DD/YYYY)] as varchar) Having COUNT(*)>1),\n",
    "-- 10. HC Transfer üìù\n",
    "HC_Transfer as\n",
    "(Select  [EID]+cast([LWD] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.LTTransfers\n",
    "Where    [EID]+cast([LWD] as varchar) is not Null\n",
    "Group by [EID]+cast([LWD] as varchar) Having COUNT(*)>1),\n",
    "-- 11. Holiday Raw üìù\n",
    "Holiday_Raw1 as\n",
    "(Select cast([Date] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From GLB.PremHdays\n",
    "Group by cast([Date] as varchar) Having COUNT(*)>1),\n",
    "-- 12. IEX Raw üìù\n",
    "\n",
    "-- 13. IntervalReq_Raw1 üìù\n",
    "IntervalReq_Raw1 as\n",
    "(Select  [LOB]+cast([Datetime_VN] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.IntervalReq\n",
    "Where    [LOB]+cast([Datetime_VN] as varchar) is not Null\n",
    "Group by [LOB]+cast([Datetime_VN] as varchar) Having COUNT(*)>1),\n",
    "-- 14. KPI Targer (LOB) üìù\n",
    "LOB_Tar as\n",
    "(Select  cast([Week] as varchar)+[LOB]+[Tenure days] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.KPI_Target\n",
    "Where    cast([Week] as varchar)+[LOB]+[Tenure days] is not Null\n",
    "Group by cast([Week] as varchar)+[LOB]+[Tenure days] Having COUNT(*)>1),\n",
    "-- 15. KPI Targer (LOB Group) üìù\n",
    "LOBGR_Tar as\n",
    "(Select  cast([Week] as varchar)+[LOB Group]+[Tenure days] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.KPI_Target\n",
    "where    cast([Week] as varchar)+[LOB Group]+[Tenure days] is not Null And [LOB] is Null\n",
    "Group by cast([Week] as varchar)+[LOB Group]+[Tenure days] Having COUNT(*)>1),\n",
    "-- 16. Logout Count üìù\n",
    "LOGOUT_COUNT as\n",
    "(Select  [Aggregation]+cast([TimeDimension] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.LogoutCount\n",
    "Where    [Aggregation]+cast([TimeDimension] as varchar) is not Null\n",
    "Group by [Aggregation]+cast([TimeDimension] as varchar) Having COUNT(*)>1),\n",
    "-- 17. OT Ramco üìù\n",
    "OT_Ramco as\n",
    "(Select  cast([Date] as varchar)+[employee_code]+[OT Type] as [Concat], COUNT(*) as [Count]\n",
    "From     GLB.OT_RAMCO\n",
    "Where    cast([Date] as varchar)+[employee_code]+[OT Type] is not Null\n",
    "Group by cast([Date] as varchar)+[employee_code]+[OT Type] Having COUNT(*)>1),\n",
    "-- 18. OverTime Raw üìù\n",
    "OverTime_Raw1 as\n",
    "(Select  cast([Date] as varchar)+[Emp ID] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.RegisteredOT\n",
    "WHere    cast([Date] as varchar)+[Emp ID] is not Null\n",
    "Group by cast([Date] as varchar)+[Emp ID] Having COUNT(*)>1),\n",
    "-- 19. PSAT üìù\n",
    "PSAT_Raw1 as\n",
    "(Select  cast([Date] as varchar)+[Survey Id]+[Has Comment]+[Channel]+[Final Topics] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.PSAT\n",
    "Where    cast([Date] as varchar)+[Survey Id]+[Has Comment]+[Channel]+[Final Topics] Is not Null\n",
    "Group by cast([Date] as varchar)+[Survey Id]+[Has Comment]+[Channel]+[Final Topics] Having COUNT(*)>1),\n",
    "-- 20. Quality_Raw1 üìù\n",
    "Quality_Raw1 as\n",
    "(Select  cast([eval_date] as varchar)+[eval_id]+[agent_username]+[final_question_grouping]+[sections]+[template_group]+[csat_satisfied]+[tix_final_subtopic]+cast([score_n] as varchar)+cast([score_question_weight] as varchar)+[eval_language]+[eval_reference]+[csat_language_code]+[tix_final_topic] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.Quality\n",
    "Where    cast([eval_date] as varchar)+[eval_id]+[agent_username]+[final_question_grouping]+[sections]+[template_group]+[csat_satisfied]+[tix_final_subtopic]+cast([score_n] as varchar)+cast([score_question_weight] as varchar)+[eval_language]+[eval_reference]+[csat_language_code]+[tix_final_topic] Is not Null\n",
    "Group by cast([eval_date] as varchar)+[eval_id]+[agent_username]+[final_question_grouping]+[sections]+[template_group]+[csat_satisfied]+[tix_final_subtopic]+cast([score_n] as varchar)+cast([score_question_weight] as varchar)+[eval_language]+[eval_reference]+[csat_language_code]+[tix_final_topic] Having COUNT(*)>1),\n",
    "-- 21. Ramco Raw üìù\n",
    "Ramco_Raw1 as\n",
    "(Select  cast([Date] as varchar)+[EID] as [Concat], COUNT(*) as [Count]\n",
    "From     GLB.RAMCO\n",
    "Where    cast([Date] as varchar)+[EID] is not Null\n",
    "Group by cast([Date] as varchar)+[EID] Having COUNT(*)>1),\n",
    "-- 22. RamUp HC üìù\n",
    "\n",
    "-- 23. Requirement Hours üìù\n",
    "Requirement_Hours as\n",
    "(Select  [LOB]+cast([Date] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.DailyReq\n",
    "Where    [LOB]+cast([Date] as varchar) is not Null\n",
    "Group by [LOB]+cast([Date] as varchar) Having COUNT(*)>1),\n",
    "-- 24. Resignation Dump üìù\n",
    "Resignation_Dump as\n",
    "(Select [Employee ID], COUNT(*) as [Count]\n",
    "From GLB.Resignation\n",
    "Group by [Employee ID] Having COUNT(*)>1),\n",
    "-- 25. RONA üìù\n",
    "RONA_Raw1 as\n",
    "(Select  [Agent]+cast([RONA] as varchar)+cast([DateTime] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.RONA\n",
    "where    [Agent]+cast([RONA] as varchar)+cast([DateTime] as varchar) is not null\n",
    "Group by [Agent]+cast([RONA] as varchar)+cast([DateTime] as varchar) Having COUNT(*)>1),\n",
    "-- 26. Roster Raw üìù\n",
    "Roster_Raw as\n",
    "(Select [Emp ID]+cast([Attribute] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From BCOM.ROSTER\n",
    "Where [Emp ID]+cast([Attribute] as varchar) is not Null\n",
    "Group by [Emp ID]+cast([Attribute] as varchar) Having COUNT(*)>1),\n",
    "-- 27. SC Labels üìù\n",
    "\n",
    "-- 28. Shrinkage Target üìù\n",
    "Shrinkage_Target as\n",
    "(Select  [LOB]+cast([Week] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.ProjectedShrink\n",
    "Where    [LOB]+cast([Week] as varchar) is not Null\n",
    "Group by [LOB]+cast([Week] as varchar) Having COUNT(*)>1),\n",
    "-- 29. Termination Dump üìù\n",
    "Termination_Dump as\n",
    "(Select [EMPLOYEE_ID]+cast([Termination Date] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From GLB.Termination\n",
    "Where [EMPLOYEE_ID]+cast([Termination Date] as varchar) is not Null\n",
    "Group by [EMPLOYEE_ID]+cast([Termination Date] as varchar) Having COUNT(*)>1),\n",
    "-- 30. Ticket Raw üìù\n",
    "Ticket_Raw1 as\n",
    "(Select  cast([Date] as varchar)+[Staff Name]+cast([Hour Interval Selected] as varchar)+[Channel]+[Item Label]+[Item ID]+['Item ID']+[Time Alert]+cast([Nr. Contacts] as varchar)+[Item Link]+[Time] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CPI\n",
    "Where    cast([Date] as varchar)+[Staff Name]+cast([Hour Interval Selected] as varchar)+[Channel]+[Item Label]+[Item ID]+['Item ID']+[Time Alert]+cast([Nr. Contacts] as varchar)+[Item Link]+[Time] is not Null\n",
    "Group by cast([Date] as varchar)+[Staff Name]+cast([Hour Interval Selected] as varchar)+[Channel]+[Item Label]+[Item ID]+['Item ID']+[Time Alert]+cast([Nr. Contacts] as varchar)+[Item Link]+[Time] Having COUNT(*)>1),\n",
    "-- 31. Workplan Raw üìù\n",
    "Workplan_Raw1 as\n",
    "(Select  [LOB]+[ID]+cast([DateTime_Act_Start] as varchar)+cast([DateTime_Act_End] as varchar)+cast([Act_Dur] as varchar)+[Action] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.WpDetail\n",
    "Where    [LOB]+[ID]+cast([DateTime_Act_Start] as varchar)+cast([DateTime_Act_End] as varchar)+cast([Act_Dur] as varchar)+[Action] is not Null\n",
    "Group by [LOB]+[ID]+cast([DateTime_Act_Start] as varchar)+cast([DateTime_Act_End] as varchar)+cast([Act_Dur] as varchar)+[Action] Having COUNT(*)>1),\n",
    "-- 32. Workplan Summary Raw üìù\n",
    "Workplan_Summary as\n",
    "(Select  cast([Date] as varchar)+[LOB]+[Agent ID]+[Agent Name]+[Scheduled Activity]+cast([Length] as varchar)+cast([Percent] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.WpSummary\n",
    "Where    cast([Date] as varchar)+[LOB]+[Agent ID]+[Agent Name]+[Scheduled Activity]+cast([Length] as varchar)+cast([Percent] as varchar) is not Null\n",
    "Group by cast([Date] as varchar)+[LOB]+[Agent ID]+[Agent Name]+[Scheduled Activity]+cast([Length] as varchar)+cast([Percent] as varchar) Having COUNT(*)>1),\n",
    "-- 33. CSAT PEGA üìù\n",
    "\n",
    "-- 34. IPH PEGA üìù\n",
    "IPH_PEGA as\n",
    "(Select  cast([Day of Date] as varchar)+[Staff Name]+[Operator Def]+[Service Case Type New]+[Channel Def]+[Reason For No Service Case]+[Topic Def New]+[Subtopics]+[Case Id]+[Reservation Id Def]+cast([# Swivels] as varchar)+cast([Count of ServiceCase or Interaction] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CPI_PEGA\n",
    "Where    cast([Day of Date] as varchar)+[Staff Name]+[Operator Def]+[Service Case Type New]+[Channel Def]+[Reason For No Service Case]+[Topic Def New]+[Subtopics]+[Case Id]+[Reservation Id Def]+cast([# Swivels] as varchar)+cast([Count of ServiceCase or Interaction] as varchar)  is not Null\n",
    "Group by cast([Day of Date] as varchar)+[Staff Name]+[Operator Def]+[Service Case Type New]+[Channel Def]+[Reason For No Service Case]+[Topic Def New]+[Subtopics]+[Case Id]+[Reservation Id Def]+cast([# Swivels] as varchar)+cast([Count of ServiceCase or Interaction] as varchar)  Having COUNT(*)>1),\n",
    "-- 35. Agents Raw(TEDNAME) üìù\n",
    "TEDNAME as\n",
    "(Select [TED Name], COUNT(*) as [Count]\n",
    "From BCOM.Staff where [TED Name] IS NOT NULL\n",
    "Group by [TED Name] Having COUNT(*)>1),\n",
    "-- 36. OTREQ üìù\n",
    "OTREQ as\n",
    "(Select  cast([Date] as varchar)+[LOB]+[Type] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.OTReq\n",
    "Where    cast([Date] as varchar)+[LOB]+[Type] is not Null\n",
    "Group by cast([Date] as varchar)+[LOB]+[Type] Having COUNT(*)>1),\n",
    "-- 37. PROHC üìù\n",
    "PROHC as\n",
    "(Select  cast([Date] as varchar)+[LOB] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.ProjectedHC\n",
    "Where    cast([Date] as varchar)+[LOB] is not Null\n",
    "Group by cast([Date] as varchar)+[LOB] Having COUNT(*)>1)\n",
    "--\n",
    "--------------------------------------------------------[Nvidia]Prcess---------------------------------------------------------------\n",
    "--\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Agents_Raw1\n",
    "Select    '01' as [No.],    Count(*) as [CheckDup],    'Agents Raw' as [Table]            ,    'IMPORTANT' as [Note]\n",
    "From       Agents_Raw1                    UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   AHT_Raw1\n",
    "Select    '02' as [No.],    Count(*) as [CheckDup],    'AHT Raw' as [Table]               ,    '' as [Note]\n",
    "From       AHT_Raw1                       UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   CapacityHC_Raw1\n",
    "Select    '03' as [No.],    Count(*) as [CheckDup],    'Capacity HC' as [Table]           ,    '' as [Note]\n",
    "From       CapacityHC_Raw1                UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   CSAT_Raw1\n",
    "Select    '04' as [No.],    Count(*) as [CheckDup],    'CSAT Raw' as [Table]              ,    '' as [Note]\n",
    "From       CSAT_Raw1                      UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   CSAT_Reso_Raw\n",
    "Select    '05' as [No.],    Count(*) as [CheckDup],    'CSAT Reso Raw' as [Table]         ,    '' as [Note]\n",
    "From       CSAT_Reso_Raw                 UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   CUIC_Raw1\n",
    "Select    '06' as [No.],    Count(*) as [CheckDup],    'CUIC Raw' as [Table]              ,    '' as [Note]\n",
    "From       CUIC_Raw1                      UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   EPS_Raw1\n",
    "Select    '08' as [No.],    Count(*) as [CheckDup],    'EPS Raw' as [Table]               ,    '' as [Note]\n",
    "From       EPS_Raw1                       UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Exception_Req\n",
    "Select    '09' as [No.],    Count(*) as [CheckDup],    'Exception Req' as [Table]         ,    '' as [Note]\n",
    "From       Exception_Req                 UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   HC_Transfer\n",
    "Select    '10' as [No.],    Count(*) as [CheckDup],    'HC Transfer' as [Table]           ,    '' as [Note]\n",
    "From       HC_Transfer                   UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Holiday_Raw1\n",
    "Select    '11' as [No.],    Count(*) as [CheckDup],    'Holiday Raw' as [Table]           ,    '' as [Note]\n",
    "From       Holiday_Raw1                   UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   IntervalReq_Raw1\n",
    "Select    '13' as [No.],    Count(*) as [CheckDup],    'IntervalReq' as [Table]       ,    'IMPORTANT' as [Note]\n",
    "From       IntervalReq_Raw1               UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   LOB_Tar\n",
    "Select    '14' as [No.],    Count(*) as [CheckDup],    'KPI Targer (LOB)' as [Table]      ,    'IMPORTANT' as [Note]\n",
    "From       LOB_Tar                       UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   LOBGR_Tar\n",
    "Select    '15' as [No.],    Count(*) as [CheckDup],    'KPI Targer (LOB Group)' as [Table],    'IMPORTANT' as [Note]\n",
    "From       LOBGR_Tar                     UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   LOGOUT_COUNT\n",
    "Select    '16' as [No.],    Count(*) as [CheckDup],    'Logout Count' as [Table]          ,    'IMPORTANT' as [Note]\n",
    "From       LOGOUT_COUNT                  UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   OT_Ramco\n",
    "Select    '17' as [No.],    Count(*) as [CheckDup],    'OT Ramco' as [Table]              ,    'IMPORTANT' as [Note]\n",
    "From       OT_Ramco                      UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   OverTime_Raw1\n",
    "Select    '18' as [No.],    Count(*) as [CheckDup],    'OverTime Raw' as [Table]          ,    'IMPORTANT' as [Note]\n",
    "From       OverTime_Raw1                  UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   PSAT_Raw1\n",
    "Select    '19' as [No.],    Count(*) as [CheckDup],    'PSAT' as [Table]                  ,    '' as [Note]\n",
    "From       PSAT_Raw1                      UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Quality_Raw1\n",
    "Select    '20' as [No.],    Count(*) as [CheckDup],    'Quality_Raw' as [Table]           ,    '' as [Note]\n",
    "From       Quality_Raw1                   UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Ramco_Raw1\n",
    "Select    '21' as [No.],    Count(*) as [CheckDup],    'Ramco Raw' as [Table]             ,    'IMPORTANT' as [Note]\n",
    "From       Ramco_Raw1                     UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Requirement_Hours\n",
    "Select    '23' as [No.],    Count(*) as [CheckDup],    'Daily Requirement' as [Table]     ,    'IMPORTANT' as [Note]\n",
    "From       Requirement_Hours             UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Resignation_Dump\n",
    "Select    '24' as [No.],    Count(*) as [CheckDup],    'Resignation Dump' as [Table]      ,    '' as [Note]\n",
    "From       Resignation_Dump              UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   RONA_Raw1\n",
    "Select    '25' as [No.],    Count(*) as [CheckDup],    'RONA' as [Table]                  ,    '' as [Note]\n",
    "From       RONA_Raw1                      UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Roster_Raw\n",
    "Select    '26' as [No.],    Count(*) as [CheckDup],    'Roster Raw' as [Table]            ,    'IMPORTANT' as [Note]\n",
    "From       Roster_Raw                    UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Shrinkage_Target\n",
    "Select    '28' as [No.],    Count(*) as [CheckDup],    'Shrinkage Target' as [Table]      ,    '' as [Note]\n",
    "From       Shrinkage_Target              UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Termination_Dump\n",
    "Select    '29' as [No.],    Count(*) as [CheckDup],    'Termination Dump' as [Table]      ,    '' as [Note]\n",
    "From       Termination_Dump              UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Ticket_Raw1\n",
    "Select    '30' as [No.],    Count(*) as [CheckDup],    'Ticket Raw' as [Table]            ,    '' as [Note]\n",
    "From       Ticket_Raw1                    UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Workplan_Raw1\n",
    "Select    '31' as [No.],    Count(*) as [CheckDup],    'Workplan Raw' as [Table]          ,    '' as [Note]\n",
    "From       Workplan_Raw1                  UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   Workplan_Summary\n",
    "Select    '32' as [No.],    Count(*) as [CheckDup],    'Workplan Summary Raw' as [Table]  ,    '' as [Note]\n",
    "From       Workplan_Summary              UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   IPH_PEGA\n",
    "Select    '34' as [No.],    Count(*) as [CheckDup],    'IPH_PEGA' as [Table]              ,    '' as [Note]\n",
    "From       IPH_PEGA                     UNION ALL     \n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   TED Name\n",
    "Select    '35' as [No.],    Count(*) as [CheckDup],    'TEDNAME' as [Table]              ,    'IMPORTANT' as [Note]\n",
    "From       TEDNAME                      UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   TED Name\n",
    "Select    '36' as [No.],    Count(*) as [CheckDup],    'OTREQ' as [Table]              ,      'IMPORTANT' as [Note]\n",
    "From       OTREQ                        UNION ALL\n",
    "------[üì•]--(üëâÔæü„ÉÆÔæü)üëâ                   TED Name\n",
    "Select    '37' as [No.],    Count(*) as [CheckDup],    'PROHC' as [Table]              ,      'IMPORTANT' as [Note]\n",
    "From       PROHC\n",
    "--          \n",
    "\"\"\"\n",
    "# ƒê·ªçc d·ªØ li·ªáu v√†o DataFrame\n",
    "Code2_Result = pl.read_database(query=sql_query2, connection=engine)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1671ae9a-9f1f-4c69-baf6-6dd256add201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINITION üåêüåêüåê\n",
    "#Name Pattern definition\n",
    "def Namepattern(folder_name):\n",
    "    match folder_name:\n",
    "        case \"Staff\":\n",
    "            pattern = r\"CNX Global Master Roster.xlsx\"\n",
    "        case \"ProjectedShrink\":\n",
    "            pattern = r\"IO Shrinkage.xlsx\"\n",
    "        case \"LTTransfers\":\n",
    "            pattern = r\"transfer.xlsx\"\n",
    "        case \"KPI_Target\":\n",
    "            pattern = r\"kpi_target.xlsx\"\n",
    "        case \"EPS\":\n",
    "            pattern = r\"EPS Tableau - (\\d{8})\\.csv\"\n",
    "        case \"DailyReq\":\n",
    "            pattern = r\"(\\d{6})(_(\\d{6}))?\\..{4}\"\n",
    "        case \"IntervalReq\":\n",
    "            pattern = r\"(\\d{6,8})(_(\\d{6,8}))?\\..{4}\"   \n",
    "        case \"Contrack\":\n",
    "        \n",
    "            pattern = r\"(\\[WFM\\] Contact Tracker|WFM_Contact Tracker|WFM Contact Tracker|(\\d{8})(_(\\d{8}))?|W(\\d{2})-(\\d{4}))\\..{4}\"  \n",
    "        case \"CapHC\":\n",
    "            pattern = r\"(\\d{4})(_(\\d{4}))?\\..{4}\"  \n",
    "        case \"AHT\":\n",
    "            pattern = r\"(\\d{8})_(\\d{8})_(...)?phone\\..{3}\"  \n",
    "        case \"Termination\":\n",
    "            pattern = r\"WDD.xlsx\" \n",
    "        case \"Resignation\":\n",
    "            pattern = r\"WDD.xlsx\" \n",
    "        case \"PremHdays\":\n",
    "            pattern = r\"Holiday Mapping.csv\" \n",
    "        case \"NormHdays\":\n",
    "            pattern = r\"Holiday Nonbillable.csv\"\n",
    "        case \"EmpMaster\":\n",
    "            pattern = r\"WDD.xlsx\"\n",
    "        case \"CUIC_RTMonitor\":\n",
    "            pattern = r\"00_RTA_View-Agent Team Real Time.xlsx\"\n",
    "        case \"CUIC\":\n",
    "            pattern = r\"(\\d{4,8})_(\\d{2,8})(_(\\d{2}))?(_\\d)?\\..{4}\"\n",
    "        case \"WpSummary\":\n",
    "            pattern = r\"(\\d{4})-(\\d{2})\"\n",
    "        case \"WpDetail\":\n",
    "            pattern = r\"(\\d{4})-(\\d{2})\"\n",
    "        case \"IEX_Hrs\":\n",
    "            pattern = r\"(\\d{4})-(\\d{2})\"\n",
    "        case _:\n",
    "            pattern = r\"(\\d{8})(_(\\d{8}))?\\..{3,4}\"\n",
    "    return pattern\n",
    "\n",
    "#table1 from code 1\n",
    "Folder_column_name = 'FOLDER NAME'\n",
    "Name_Coumn_name = 'FileName - ModifiedDate'\n",
    "Row_column_name = 'ROW_NUMBER'\n",
    "#table2 from code 2\n",
    "important_column= 'Note'\n",
    "Check_dup_column = 'CheckDup'\n",
    "Table_column = 'Table'\n",
    "#log file that we read\n",
    "Error_log_column ='Error'\n",
    "Log_name_column='FileName'\n",
    "\n",
    "\n",
    "#Color code\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    FAILVIOLET = '\\033[35m'\n",
    "\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28bd9dcc-642a-47dc-a570-e74eb48831e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìùException list, use it to ignore a file that has been confirmed OKüìù\n",
    "\n",
    "#Exception for inconsistent row\n",
    "Expection_list_checkrow=[\n",
    "    \"EPS Tableau - 20240831\",\n",
    "    \"20231001_20231231\",\n",
    "    \"20250330\",\"20250421\",\n",
    "    \"20220919_20230930\",\n",
    "    \"20250331_20250406\",\n",
    "    \"20250515\",\"20250516\",\"20250517\",\n",
    "    \"EPS Tableau - 20241229\",\n",
    "    \"20240101_20250223\",    \n",
    "    \"20220919_20231231\",\n",
    "    \"20230101_20231231\",\n",
    "    \"W29-2025\",\n",
    "    \"20250803\"\n",
    "    ]\n",
    "Expection_list_checkupdate=[\n",
    "    \"20240101_20250223\",\n",
    "    \"20250224_20250302\"\n",
    "]\n",
    "\n",
    "Expection_list_checkmissing=[\n",
    "    \"[WFM] Contact Tracker\",\n",
    "    \"20220919_20230930\",\n",
    "    \"20231001_20231231\",\n",
    "    \"20240101_20240630\",\n",
    "    \"20240701_20241229\",\n",
    "    \"20221231\",\n",
    "    \"20230630\",\n",
    "    \"20230930\",\n",
    "    \"20231231\",\n",
    "    \"20240430\",\n",
    "    \"20240831\",\n",
    "    \"20241229\",\n",
    "    \"20240101_20241231_nonphone\", \n",
    "    \"20240101_20241231_phone\",\n",
    "    \"20250101_20250629\",\n",
    "    \"20220919_20231231\",\n",
    "    \"20240101_20241231\",\n",
    "    \"20250101_20250622\"\n",
    "]\n",
    "\n",
    "ROSTER_FIRST_FILE = \"20250623_20250629\"\n",
    "WP_FIRST_FILE=\"2025-23\"\n",
    "CPI_FIRST_FILE ='20250101'\n",
    "EPS_FIRST_FILE ='20250105'\n",
    "AHT_FIRST_FILE = \"20250101_20250131\"\n",
    "Exception_pattern = r\"\\..{3,4}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80d377a7-5a02-4995-b3f7-f98d76c80d72",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Func Compare row with non pattern file name\n",
    "def Row_Compare_Special(Dataframe,Extract_file):\n",
    "    rowdata = Dataframe[Row_column_name].to_list()\n",
    "    # Standard Deviation Math\n",
    "    mean = statistics.mean(rowdata)  \n",
    "    std_dev = statistics.stdev(rowdata) \n",
    "#Tweak the sensitivity of the comparison, lower = more strict\n",
    "    tolerance = 2.5\n",
    "    catch_list=[]\n",
    "    for row in rowdata:\n",
    "         distance = abs(row -mean)\n",
    "         if distance > tolerance * std_dev:\n",
    "              catch_list.append(row)\n",
    "\n",
    "              \n",
    "    if not(catch_list):\n",
    "         return\n",
    "\n",
    "    # Filter the file has been mark out\n",
    "    Sus_file = Dataframe.filter(pl.col(Row_column_name).is_in(catch_list))\n",
    "    for row in Sus_file.iter_rows(named= True):\n",
    "        check =re.split(Exception_pattern,row[Name_Coumn_name])\n",
    "        if check[0] not in Expection_list_checkrow:\n",
    "            Extract_file.append((row[Name_Coumn_name],row[Folder_column_name],\"Inconsistent row\"))\n",
    "            print(f'{bcolors.WARNING}File {row[Name_Coumn_name]} in {row[Folder_column_name]} has inconsistent number of rows {bcolors.ENDC}')\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "44f5c4b1-8cae-458a-a739-3878eb203b86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Func Compare Row with pattern file name\n",
    "def Row_Compare(Dataframe,Extract_file,Folder):\n",
    "    desired_pattern = r\"(\\d{8})_(\\d{8})\"\n",
    "    FilteredDataframe= Dataframe.sort(Name_Coumn_name,descending=False)\n",
    "    rowdivdate =[]\n",
    "    namefilter=[]\n",
    "    row_avg = []\n",
    "    #calculate average number for row in one day we should expected\n",
    "    for row  in FilteredDataframe.iter_rows(named= True):\n",
    "         \n",
    "        match = re.match(desired_pattern,row[Name_Coumn_name])\n",
    "        start_date_string,end_date_start_date_string = match.groups()\n",
    "        try:\n",
    "            start_date = dt.strptime(start_date_string,\"%Y%m%d\").date()\n",
    "            end_date = dt.strptime(end_date_start_date_string,\"%Y%m%d\").date()\n",
    "            #average number of rows should have per day\n",
    "            namefilter.append(row[Name_Coumn_name])\n",
    "            row_avg.append((row[Row_column_name]/((end_date - start_date).days)))\n",
    "        \n",
    "        #Find out if file has the same start date and end date  \n",
    "        except ZeroDivisionError:\n",
    "            print(f\"{bcolors.OKBLUE}File {row[Name_Coumn_name]} in {Folder} has the same start and end date{bcolors.ENDC}\")\n",
    "            Extract_file.append((row[Name_Coumn_name],Folder,\"Same Start and End date\"))\n",
    "            continue\n",
    "\n",
    "    namefilter_series = pl.Series(\"File_name\", namefilter)\n",
    "    row_avg_series = pl.Series(\"Average_Row\", row_avg)\n",
    "    #If none calculated, return\n",
    "    if len(namefilter)<2:\n",
    "        return\n",
    "\n",
    "     #Create Dataframe\n",
    "\n",
    "    dffinal = pl.DataFrame([namefilter_series,row_avg_series])\n",
    "    rowdata = dffinal['Average_Row'].to_list()\n",
    "    # Standard Deviation Math\n",
    "    mean = statistics.mean(rowdata)  \n",
    "    std_dev = statistics.stdev(rowdata) \n",
    "    #Tweak the sensitivity of the comparison, lower = more strict\n",
    "    tolerance = 2.5\n",
    "    catch_list=[]\n",
    "\n",
    "    for row in rowdata:\n",
    "        distance = abs(row -mean)\n",
    "        if distance > tolerance * std_dev:\n",
    "            catch_list.append(row)\n",
    "\n",
    "    \n",
    "    if not(catch_list):\n",
    "        return\n",
    "     \n",
    "     # Filter the file has been mark out\n",
    "    Sus_file = dffinal.filter(pl.col('Average_Row').is_in(catch_list))\n",
    "    for row in Sus_file.iter_rows(named= True):\n",
    "        check =re.split(Exception_pattern,row['File_name'])\n",
    "        if check[0] not in Expection_list_checkrow:\n",
    "            Extract_file.append((row['File_name'],Folder,\"Inconsistent average row\"))\n",
    "            print(f'{bcolors.FAIL}File {row['File_name']} in {Folder} has inconsistent number of rows {bcolors.ENDC}')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21138fed-212b-4927-9cd7-55606f0ffb85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Func Duplicate date check\n",
    "def Duplicate_Date_Check(list_name,extract_list,folder):\n",
    "    file_ranges = []\n",
    "    Valid_list = []\n",
    "    desired_pattern = r\"(\\d{8})_(\\d{8})\"\n",
    "    \n",
    "    for file_name in list_name:\n",
    "        match = re.match(desired_pattern,file_name)\n",
    "        if match:\n",
    "                start_date_string,end_date_start_date_string = match.groups()\n",
    "                try:\n",
    "                    start_date = dt.strptime(start_date_string,\"%Y%m%d\").date()\n",
    "                    end_date = dt.strptime(end_date_start_date_string,\"%Y%m%d\").date()\n",
    "                    #Put date into a list to compare\n",
    "                    file_ranges.append((start_date,end_date,file_name))\n",
    "                    # Valid file will be use to further check\n",
    "                    Valid_list.append(file_name)\n",
    "                except ValueError:\n",
    "                    print(f\"{bcolors.OKBLUE} {file_name} has invalid name format in {folder}, cannot compare date for further check{bcolors.ENDC}\")\n",
    "\n",
    "    file_ranges.sort()\n",
    "    \n",
    "    for i in range(len(file_ranges)):\n",
    "        start_i, end_i, file_i = file_ranges[i]\n",
    "        overlap_count =0\n",
    "        for j in range(len(file_ranges)):\n",
    "            if i!= j:\n",
    "                start_j, end_j, file_j = file_ranges[j]\n",
    "                if folder == 'AHT' and file_i==file_j:\n",
    "                    extract_list.append((file_i,folder,\"Duplicate file\"))\n",
    "                    print(f'{bcolors.FAIL}Duplicate date file: {file_i}{bcolors.ENDC}')\n",
    "                    break\n",
    "                #Check if current file is totally in another file\n",
    "                if start_j <= start_i <= end_j and start_j <= end_i <= end_j and folder !='AHT':\n",
    "                    extract_list.append((file_i,folder,\"Duplicate file\"))\n",
    "                    print(f'{bcolors.FAIL}Duplicate date file: {file_i}{bcolors.ENDC}')\n",
    "                else:\n",
    "                # Check if currentfile has a part in another file\n",
    "                    if start_i <= end_j and end_i >= start_j:\n",
    "                        overlap_count +=1\n",
    "                if overlap_count >=2:\n",
    "                    extract_list.append((file_i,folder,\"Has overlap days\"))\n",
    "                    print(f'{bcolors.WARNING}File might have issue with overlapping date: {file_i}{bcolors.ENDC}')\n",
    "\n",
    "                    break\n",
    "    \n",
    "    return Valid_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6c62518-41db-4bb3-a589-1b57e0a2c3b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:90: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:140: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:90: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:140: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\tungquan.le\\AppData\\Local\\Temp\\ipykernel_17632\\2289369839.py:90: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  checkyear = re.search('\\d{4}',clean_named[index-lingering])\n",
      "C:\\Users\\tungquan.le\\AppData\\Local\\Temp\\ipykernel_17632\\2289369839.py:140: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  checkyear = re.search('(\\d{8})_(\\d{8})',clean_named[index-lingering])\n"
     ]
    }
   ],
   "source": [
    "#Missing file check\n",
    "def Missing_File_check(list_name,extract_list,folder):\n",
    "    clean_named=[]\n",
    "#clear datetime modified from the file name, remove exception file\n",
    "    if folder == 'EPS':#entire new scenario for EPS\n",
    "        for name in list_name:\n",
    "            match = re.search(r'\\d{8}',name)\n",
    "            cleaned_date = match.group()\n",
    "            if cleaned_date not in Expection_list_checkmissing:\n",
    "                clean_named.append(cleaned_date)\n",
    "        \n",
    "    else: \n",
    "        for name in list_name:\n",
    "            split = re.split(Exception_pattern,name)\n",
    "            if split[0] not in Expection_list_checkmissing:\n",
    "                clean_named.append(split[0])\n",
    "                \n",
    "                \n",
    "    clean_named.sort()\n",
    "\n",
    "\n",
    "#sort and checking missing file\n",
    "    current_date =dt.now() \n",
    "    match folder:\n",
    "        case'WpDetail'|'WpSummary'|'IEX_Hrs':\n",
    "            #edit here if first file is differ follow format YYYY-WW ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è\n",
    "            first_file =  WP_FIRST_FILE\n",
    "\n",
    "            #check how many week between the first file and today (week 23 of 2025)\n",
    "            start_end_pattern = r'(\\d{4})-(\\d{2})'\n",
    "            matchformat = re.search(start_end_pattern,first_file)\n",
    "            year_string,weeknum_string = matchformat.groups()\n",
    "            fulldate = f'{year_string}-W{weeknum_string}'\n",
    "            reference_date = dt.strptime(fulldate+'-1',\"%Y-W%W-%w\")\n",
    "            number_of_week = math.floor((current_date-reference_date).days /7)\n",
    "            #lingering to make sure we didnt skip file that actual exist\n",
    "            lingering =0\n",
    "            for index in range(number_of_week+1):\n",
    "                    #if out of index, that's mean we missed alot of file so registered it\n",
    "                    try:\n",
    "                        if clean_named[index-lingering] != first_file:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                        #check the next file after the first file\n",
    "                        matchformat = re.search(Namepattern(folder),first_file)\n",
    "                        year_string,weeknum_string = matchformat.groups()\n",
    "                        weeknum_string = int(weeknum_string)+1\n",
    "                        #if over next year, increase year and reset week num\n",
    "                        if weeknum_string == 53:\n",
    "                            weeknum_string = 1\n",
    "                            year_string = int(year_string)+1\n",
    "                        if weeknum_string <10:\n",
    "                            first_file = f'{year_string}-0{weeknum_string}'\n",
    "\n",
    "                        else:\n",
    "                            first_file = f'{year_string}-{weeknum_string}'\n",
    "                        # senario where list is missing a lot of file and this will help the code continue to run\n",
    "                    except IndexError:\n",
    "                        print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                        extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                        matchformat = re.search(Namepattern(folder),first_file)\n",
    "                        year_string,weeknum_string = matchformat.groups()\n",
    "                        weeknum_string = int(weeknum_string)+1\n",
    "                        if weeknum_string == 53:\n",
    "                            weeknum_string = 1\n",
    "                            year_string = int(year_string)+1\n",
    "                        if weeknum_string <10:\n",
    "                            first_file = f'{year_string}-0{weeknum_string}'\n",
    "                        else:\n",
    "                            first_file = f'{year_string}-{weeknum_string}'\n",
    "                    continue\n",
    "        case 'CSAT_RS'|'OT_RAMCO'|'RAMCO'|'LogoutCount'|'PSAT'|'CPI_PEGA'|'CSAT_TP':\n",
    "            #edit here if first file is differ follow format YYYY-WW ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è\n",
    "            first_file = '20250101_20250131'\n",
    "\n",
    "            #check how many month between the first file and today (Jan of 2025)\n",
    "            start_end_pattern = r'(\\d{8})_(\\d{8})'\n",
    "            matchformat = re.search(start_end_pattern,first_file)\n",
    "            start_string,end_string = matchformat.groups()\n",
    "            start_string = dt.strptime(start_string,\"%Y%m%d\")\n",
    "            first_file_month= start_string.month\n",
    "            first_file_year= start_string.year\n",
    "            number_of_month = math.floor((current_date-start_string).days/30)\n",
    "            year_pass =0\n",
    "            lingering =0\n",
    "            for index in range(number_of_month+1):\n",
    "                try:\n",
    "                    #if file is not after first file year, bye bye\n",
    "                    checkyear = re.search('\\d{4}',clean_named[index-lingering])\n",
    "                    if int(checkyear.group(0))< first_file_year:     \n",
    "                        continue\n",
    "                    if clean_named[index-lingering] != first_file:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                    #if year is passing, we increase year pass and reset the month\n",
    "                    if first_file_month == 12:\n",
    "                         first_file_month = 1\n",
    "                         year_pass = year_pass+1\n",
    "                    else:\n",
    "                        first_file_month = first_file_month +1\n",
    "                    #get next file name\n",
    "                    firstday_month = dt(first_file_year+year_pass, first_file_month, 1)\n",
    "                    lastday_month = firstday_month + pd.offsets.MonthEnd(1)\n",
    "                    if first_file_month < 10:\n",
    "                        first_file = f'{firstday_month.year}0{firstday_month.month}01_{lastday_month.year}0{lastday_month.month}{lastday_month.day}'\n",
    "                    else:\n",
    "                        first_file = f'{firstday_month.year}{firstday_month.month}01_{lastday_month.year}{lastday_month.month}{lastday_month.day}'\n",
    "                     \n",
    "                   \n",
    "                except IndexError:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            if first_file_month == 12:\n",
    "                                first_file_month = 1\n",
    "                                year_pass = year_pass+1\n",
    "                            else:\n",
    "                                first_file_month = first_file_month +1\n",
    "                    #get next file name\n",
    "                            firstday_month = dt(first_file_year+year_pass, first_file_month, 1)\n",
    "                            lastday_month = firstday_month + pd.offsets.MonthEnd(1)\n",
    "                            if first_file_month < 10:\n",
    "                                first_file = f'{firstday_month.year}0{firstday_month.month}01_{lastday_month.year}0{lastday_month.month}{lastday_month.day}'\n",
    "                            else:\n",
    "                                first_file = f'{firstday_month.year}{firstday_month.month}01_{lastday_month.year}{lastday_month.month}{lastday_month.day}'\n",
    "                continue\n",
    "\n",
    "        case 'CPI':   \n",
    "            first_file = CPI_FIRST_FILE\n",
    "\n",
    "            #check how many date between the first file and today (01 Jan of 2025)\n",
    "\n",
    "            start_string = dt.strptime(first_file,\"%Y%m%d\")\n",
    "            number_of_dates = (current_date-start_string).days\n",
    "            lingering =0\n",
    "            for index in range(number_of_dates+1):\n",
    "                try:\n",
    "                    #if file is follow patter xxxxxxxx_xxxxxxxx, bye bye\n",
    "                    checkyear = re.search('(\\d{8})_(\\d{8})',clean_named[index-lingering])\n",
    "                    if checkyear:     \n",
    "                        continue\n",
    "                    #check for all file follow the date pattern \n",
    "                    if clean_named[index-lingering] != first_file:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                    #check next date\n",
    "                    checkdate = dt.strptime(first_file,\"%Y%m%d\")\n",
    "                    date_string = checkdate+timedelta(1)\n",
    "                    date_string = dt.strftime(date_string,\"%Y%m%d\")\n",
    "                    first_file = f'{date_string}'\n",
    "                     \n",
    "                   \n",
    "                except IndexError:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            checkdate = dt.strptime(first_file,\"%Y%m%d\")\n",
    "                            date_string = checkdate+timedelta(1)\n",
    "                            date_string = dt.strftime(date_string,\"%Y%m%d\")\n",
    "                            first_file = f'{date_string}'\n",
    "                            \n",
    "                continue\n",
    "        case 'EPS':   \n",
    "            first_file = EPS_FIRST_FILE\n",
    "\n",
    "            #check how many date between the first file and today (01 Jan of 2025)\n",
    "\n",
    "            start_string = dt.strptime(first_file,\"%Y%m%d\")\n",
    "            number_of_week = math.floor((current_date-start_string).days /7)\n",
    "\n",
    "            lingering =0\n",
    "            for index in range(number_of_week+1):\n",
    "                try:\n",
    "                    #check for all file follow the date pattern \n",
    "                    if clean_named[index-lingering] != first_file:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                    #check next date\n",
    "                    checkdate = dt.strptime(first_file,\"%Y%m%d\")\n",
    "                    date_string = checkdate+timedelta(7)\n",
    "                    date_string = dt.strftime(date_string,\"%Y%m%d\")\n",
    "                    first_file = f'{date_string}'\n",
    "                     \n",
    "                   \n",
    "                except IndexError:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            checkdate = dt.strptime(first_file,\"%Y%m%d\")\n",
    "                            date_string = checkdate+timedelta(7)\n",
    "                            date_string = dt.strftime(date_string,\"%Y%m%d\")\n",
    "                            first_file = f'{date_string}'\n",
    "                            \n",
    "                continue\n",
    "                \n",
    "        case 'ROSTER':\n",
    "\n",
    "            first_file = ROSTER_FIRST_FILE\n",
    "            #check how many month between the first file and today (Jan of 2025)\n",
    "            start_end_pattern = r'(\\d{8})_(\\d{8})'\n",
    "            matchformat = re.search(start_end_pattern,first_file)\n",
    "            start_string,end_string = matchformat.groups()\n",
    "            start_string = dt.strptime(start_string,\"%Y%m%d\")\n",
    "            end_string = dt.strptime(end_string,\"%Y%m%d\")\n",
    "            number_of_week = math.floor((current_date-start_string).days/7)\n",
    "            lingering =0\n",
    "            for index in range(number_of_week+1):\n",
    "                try:\n",
    "                    if clean_named[index-lingering] != first_file:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                    #check next date week\n",
    "                    recheck = re.search(start_end_pattern,first_file)\n",
    "                    start_string,end_string = recheck.groups()\n",
    "                    start_string = dt.strptime(start_string,\"%Y%m%d\")\n",
    "                    end_string = dt.strptime(end_string,\"%Y%m%d\")\n",
    "                    start_string = start_string+timedelta(7)\n",
    "                    end_string = end_string+timedelta(7)\n",
    "                    start_string = dt.strftime(start_string,\"%Y%m%d\")\n",
    "                    end_string = dt.strftime(end_string,\"%Y%m%d\")\n",
    "                    first_file = f'{start_string}_{end_string}'\n",
    "                except IndexError:\n",
    "                    print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                    extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                    #check next date week\n",
    "                    recheck = re.search(start_end_pattern,first_file)\n",
    "                    start_string,end_string = recheck.groups()\n",
    "                    start_string = dt.strptime(start_string,\"%Y%m%d\")\n",
    "                    end_string = dt.strptime(end_string,\"%Y%m%d\")\n",
    "                    start_string = start_string+timedelta(7)\n",
    "                    end_string = end_string+timedelta(7)\n",
    "                    start_string = dt.strftime(start_string,\"%Y%m%d\")\n",
    "                    end_string = dt.strftime(end_string,\"%Y%m%d\")\n",
    "                    first_file = f'{start_string}_{end_string}'                    \n",
    "                continue\n",
    "        case 'AHT':\n",
    "            first_file = AHT_FIRST_FILE\n",
    "            file_type = [\"_nonphone\",\"_phone\"]\n",
    "            #check how many month between the first file and today (Jan of 2025)\n",
    "            start_end_pattern = r'(\\d{8})_(\\d{8})'\n",
    "            matchformat = re.search(start_end_pattern,first_file)\n",
    "            start_string,end_string = matchformat.groups()\n",
    "            start_string = dt.strptime(start_string,\"%Y%m%d\")\n",
    "            first_file_month= start_string.month\n",
    "            first_file_year= start_string.year\n",
    "            number_of_month = math.floor((current_date-start_string).days/30)\n",
    "            year_pass= 0\n",
    "            lingering =0\n",
    "            for index in range(number_of_month+1):\n",
    "                try:\n",
    "                    if clean_named[index-lingering] != f'{first_file}{file_type[index%2]}':\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file}{file_type[index%2]} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((f'{first_file}{file_type[index%2]}',folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                    #check twice then increase\n",
    "                    if index%2 ==1:\n",
    "                    #if year is passing, we increase year pass and reset the month\n",
    "                        if first_file_month == 12:\n",
    "                            first_file_month = 1\n",
    "                            year_pass = year_pass+1\n",
    "                        else:\n",
    "                            first_file_month = first_file_month +1\n",
    "                        #get next file name\n",
    "                        firstday_month = dt(first_file_year+year_pass, first_file_month, 1)\n",
    "                        lastday_month = firstday_month + pd.offsets.MonthEnd(1)\n",
    "                        if first_file_month < 10:\n",
    "                            first_file = f'{firstday_month.year}0{firstday_month.month}01_{lastday_month.year}0{lastday_month.month}{lastday_month.day}'\n",
    "                        else:\n",
    "                            first_file = f'{firstday_month.year}{firstday_month.month}01_{lastday_month.year}{lastday_month.month}{lastday_month.day}'\n",
    "                    \n",
    "                except IndexError:\n",
    "                    print(f\"{bcolors.FAILVIOLET}Missing {first_file}{file_type[index%2]} in folder {folder}{bcolors.ENDC}\")\n",
    "                    extract_list.append((f'{first_file}{file_type[index%2]}',folder,\"Missing file\"))\n",
    "                    #check twice then increase\n",
    "\n",
    "                    if index%2 ==1:\n",
    "                    #if year is passing, we increase year pass and reset the month\n",
    "\n",
    "                        if first_file_month == 12:\n",
    "                            first_file_month = 1\n",
    "                            year_pass = year_pass+1\n",
    "                        else:\n",
    "                            first_file_month = first_file_month +1\n",
    "                        #get next file name\n",
    "                            firstday_month = dt(first_file_year+year_pass, first_file_month, 1)\n",
    "                            lastday_month = firstday_month + pd.offsets.MonthEnd(1)\n",
    "                        if first_file_month < 10:\n",
    "                            first_file = f'{firstday_month.year}0{firstday_month.month}01_{lastday_month.year}0{lastday_month.month}{lastday_month.day}'\n",
    "                        else:\n",
    "                            first_file = f'{firstday_month.year}{firstday_month.month}01_{lastday_month.year}{lastday_month.month}{lastday_month.day}'        \n",
    "                continue\n",
    "        case _:\n",
    "            print(f'{bcolors.OKCYAN}Skip {folder} for missing check {bcolors.ENDC}')\n",
    "            return\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d05ca292-406e-4c4a-ae14-c9efae7b1894",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Func Check update \n",
    "\n",
    "def File_need_update_check(list_name,extract_list,Folder):\n",
    "    #pattern to get the modified date\n",
    "    time_pattern = r\"(\\d{4})\\-(\\d{1,2})\\-(\\d{1,2})\"\n",
    "    current_date = dt.now()\n",
    "    #flag to report\n",
    "    Most_recent_CUIC_file = 1\n",
    "    Most_recent_EPS_file = 5\n",
    "    Most_recent_Quality_file = 5\n",
    "    Most_recent_WpDetail_file = 7\n",
    "    Prepresent_file = \"\"\n",
    "    How_Long_Prepresent_file_have_not_update=60\n",
    "    for name in list_name:\n",
    "        #Check last time file was modified by seaching the pattern, assume that file is up to date\n",
    "        match = re.search(time_pattern,name)\n",
    "        How_Long_have_not_update=0\n",
    "        if match:\n",
    "            year_string,month_string,day_string = match.groups()\n",
    "            last_edit = dt(int(year_string),int(month_string),int(day_string))\n",
    "            How_Long_have_not_update = (current_date-last_edit).days\n",
    "            check =re.split(Exception_pattern,name)\n",
    "            if check[0] not in Expection_list_checkupdate:\n",
    "                #Threshhold for each type of folder\n",
    "                match Folder:\n",
    "                    case 'ExceptionReq':\n",
    "                        if  How_Long_have_not_update >1:\n",
    "                            print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                            extract_list.append((name,Folder,\"May need update\"))           \n",
    "                    #Update CPI\n",
    "                    case 'CPI':\n",
    "                        How_old_is_this_file =4\n",
    "                        # Calculate how old is this file and should it be neccessary to update it\n",
    "                        yyyymmdd_pattern = r'(\\d{8})'\n",
    "                        matchformat = re.search(yyyymmdd_pattern,name)\n",
    "                        if matchformat:\n",
    "                            start_date_string = matchformat.group()\n",
    "                            start_date = dt.strptime(start_date_string,\"%Y%m%d\")\n",
    "                            How_old_is_this_file = (current_date-start_date).days\n",
    "\n",
    "                        if  How_old_is_this_file < 3 and How_Long_have_not_update >=1:\n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "                    #Update CUIC\n",
    "                    case 'CUIC':\n",
    "                        How_old_is_this_file =4\n",
    "                        # Calculate how old is this file and should it be neccessary to update it\n",
    "                    \n",
    "                        yyyy_dd_mm_pattern = r'(\\d{4})_(\\d{2})_(\\d{2})'\n",
    "                        matchformat = re.match(yyyy_dd_mm_pattern,name)\n",
    "                        if matchformat:\n",
    "                            year_s,mon_s,day_s = matchformat.groups()\n",
    "                            start_2 = dt(int(year_s),int(mon_s),int(day_s))\n",
    "                            How_old_is_this_file = (current_date-start_2).days\n",
    "\n",
    "                            #Flag to check for the newest file\n",
    "                            if How_old_is_this_file <=0:\n",
    "                                Most_recent_CUIC_file = 0\n",
    "\n",
    "                        if  How_old_is_this_file < 3 and How_Long_have_not_update >1:\n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #update 1-3 days\n",
    "                    case 'CSAT_RS'|'CSAT_TP'|'LogoutCount'|'PSAT'|'RAMCO'|'ROSTER'|'AHT':\n",
    "\n",
    "                        # Calculate how old is this file and should it be neccessary to update it\n",
    "                        start_end_pattern = r'(\\d{8})_(\\d{8})'\n",
    "                        How_old_is_this_file =8\n",
    "                        matchformat = re.search(start_end_pattern,name)\n",
    "                        \n",
    "                        if matchformat:\n",
    "                            start_date_string,end_date_string = matchformat.groups()\n",
    "                            end_date = dt.strptime(end_date_string,\"%Y%m%d\")\n",
    "                            How_old_is_this_file = (current_date-end_date).days\n",
    "\n",
    "                            if  How_Long_have_not_update > 2 and How_old_is_this_file <4:  \n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #update weekly\n",
    "                    case 'CPI_PEGA'|'OT_RAMCO'|'OTReq'|'RegisteredOT'|'RONA':\n",
    "                        # Calculate how old is this file and should it be neccessary to update it\n",
    "                        start_end_pattern = r'(\\d{8})_(\\d{8})'\n",
    "                        How_old_is_this_file =8\n",
    "                        matchformat = re.search(start_end_pattern,name)\n",
    "                        if matchformat:\n",
    "                            start_date_string,end_date_string = matchformat.groups()\n",
    "                            end_date = dt.strptime(end_date_string,\"%Y%m%d\")\n",
    "                            How_old_is_this_file = (current_date-end_date).days\n",
    "                        \n",
    "                            if  How_Long_have_not_update > 5 and How_old_is_this_file <7:  \n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #update Contract\n",
    "                    case 'Contrack':\n",
    "                        # Calculate how old is this file and should it be neccessary to update it\n",
    "                        wfm_pattern = r'[WFM] Contact Tracker'\n",
    "                        matchformat = re.search(wfm_pattern,name)  \n",
    "                        if How_Long_have_not_update> 2 and matchformat:  \n",
    "                            print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                            extract_list.append((name,Folder,\"May need update\"))\n",
    "            \n",
    "\n",
    "                    #update monthly\n",
    "                    case 'CapHC'|'DailyReq'|'IntervalReq'|'KPI_Target'|'LTTransfers'|'ProjectedHC':\n",
    "                        if  How_Long_have_not_update < How_Long_Prepresent_file_have_not_update:  \n",
    "                            Prepresent_file = name\n",
    "                            How_Long_Prepresent_file_have_not_update=How_Long_have_not_update\n",
    "\n",
    "                    #update yearly\n",
    "                    case 'PremHdays'|'NormHdays':\n",
    "                        if How_Long_have_not_update > 364:\n",
    "                            print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                            extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #update WDD/ProjectedShrink/Staff\n",
    "                    case 'EmpMaster'|'Resignation'|'Termination'|'ProjectedShrink'|'Staff':\n",
    "                        if How_Long_have_not_update > 8 and Folder != 'ProjectedShrink' :\n",
    "                            print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                            extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #Update EPS\n",
    "                    case 'EPS':\n",
    "                        How_old_is_this_file =5\n",
    "                        yyyymmdd_pattern = r'(\\d{8})'\n",
    "                        matchformat = re.search(yyyymmdd_pattern,name)\n",
    "                        if matchformat:\n",
    "                            start_date_string = matchformat.group()\n",
    "                            start_date = dt.strptime(start_date_string,\"%Y%m%d\")\n",
    "                            How_old_is_this_file = (current_date-start_date).days\n",
    "                        # Flag the folder if the file is not newest\n",
    "                            if How_old_is_this_file < Most_recent_EPS_file:\n",
    "                                Most_recent_EPS_file = How_old_is_this_file\n",
    "                        \n",
    "                        if  How_old_is_this_file < 4 and How_Long_have_not_update >=3:\n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #Update Quality\n",
    "                    case 'Quality':\n",
    "                        How_old_is_this_file =5\n",
    "                        yyyymmdd_pattern = r'(\\d{8})'\n",
    "                        matchformat = re.search(yyyymmdd_pattern,name)\n",
    "                        if matchformat:\n",
    "                            start_date_string = matchformat.group()\n",
    "                            start_date = dt.strptime(start_date_string,\"%Y%m%d\")\n",
    "                            How_old_is_this_file = (current_date-start_date).days\n",
    "                        # Flag the folder if the file is not newest\n",
    "                            if How_old_is_this_file < Most_recent_Quality_file:\n",
    "                                Most_recent_Quality_file = How_old_is_this_file\n",
    "\n",
    "                        if  How_old_is_this_file < 4 and How_Long_have_not_update >=3:\n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #Update WpDetail\n",
    "                    case 'WpDetail':\n",
    "                        start_end_pattern = r'(\\d{4})-(\\d{2})'\n",
    "                        How_old_is_this_file =7\n",
    "                        matchformat = re.search(start_end_pattern,name)\n",
    "                        if matchformat:\n",
    "                            year_string,weeknum_string = matchformat.groups()\n",
    "                            fulldate = f'{year_string}-W{weeknum_string}'\n",
    "                            end_date = dt.strptime(fulldate+'-1',\"%Y-W%W-%w\")\n",
    "                            How_old_is_this_file = (current_date-end_date).days\n",
    "\n",
    "                        # Flag the folder if the file is not newest\n",
    "                        if  How_old_is_this_file < Most_recent_WpDetail_file:\n",
    "                            Most_recent_WpDetail_file= How_old_is_this_file\n",
    "        \n",
    "                    #folder not found\n",
    "                    case _:\n",
    "                        print(f'{bcolors.OKCYAN}{Folder} is not expected for the update check {bcolors.ENDC}')\n",
    "                        return\n",
    "    \n",
    "    # Raise notify base on flag \n",
    "    if Most_recent_CUIC_file!=0 and Folder==\"CUIC\":\n",
    "        print(f'{bcolors.OKCYAN}{Folder} need to be updated to the newest data {bcolors.ENDC}')\n",
    "        extract_list.append((\"Missing Today File\",Folder,\"Need update\"))\n",
    "    if Most_recent_EPS_file>=3 and Folder==\"EPS\":\n",
    "        print(f'{bcolors.OKCYAN}{Folder} need to be updated to the newest data {bcolors.ENDC}')\n",
    "        extract_list.append((\"Missing This Week File\",Folder,\"Need update\"))\n",
    "    if Most_recent_Quality_file>=3 and Folder==\"Quality\":\n",
    "        print(f'{bcolors.OKCYAN}{Folder} need to be updated to the newest data {bcolors.ENDC}')\n",
    "        extract_list.append((\"Missing This Week File\",Folder,\"Need update\"))\n",
    "    if Most_recent_WpDetail_file >7 and Folder==\"WpDetail\":\n",
    "        print(f'{bcolors.OKCYAN}{Folder} need to be updated to the newest data {bcolors.ENDC}')\n",
    "        extract_list.append((\"Missing This Week File\",Folder,\"Need update\"))    \n",
    "    if How_Long_Prepresent_file_have_not_update>30 and Prepresent_file:\n",
    "        print(f'{bcolors.OKCYAN}{Prepresent_file} in {Folder} need to be updated to the newest data {bcolors.ENDC}')\n",
    "        extract_list.append((Prepresent_file,Folder,f'Last update {How_Long_Prepresent_file_have_not_update} days ago'))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9866700b-3f6d-4d1f-80a7-2a0515649259",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Category check cho to√†n b·ªô Func tr√™n d·ª±a tr√™n k·∫øt qu·∫£ code 1\n",
    "def CategoryCheck (your_dataframe,file_error):\n",
    "     #Check each folder \n",
    "     for folder_name in your_dataframe[Folder_column_name].unique():\n",
    "               #Current folder checking\n",
    "               current_check = your_dataframe.filter(pl.col(Folder_column_name) == folder_name)\n",
    "               current_extract_grp=[]\n",
    "               #Check naming rule\n",
    "               for file_name in current_check[Name_Coumn_name]:\n",
    "                    match = re.match(Namepattern(folder_name),file_name)\n",
    "                    if match:\n",
    "                          #Extract valid file name to check further\n",
    "                        current_extract_grp.append(f\"{file_name}\")\n",
    "                    else:\n",
    "                        print(f\"{bcolors.FAILVIOLET}Weird Name Pattern at {file_name} in folder {folder_name}{bcolors.ENDC}\")\n",
    "                        current_extract_grp.append(f\"{file_name}\")\n",
    "                        file_error.append((file_name,folder_name,\"Weird Name\"))\n",
    "               #Check Missing File if current folder only have 1 file, skip this\n",
    "               if current_check.count()[0,1]>1:\n",
    "                    Missing_File_check(current_extract_grp,file_error,folder_name)\n",
    "               #Check update\n",
    "               File_need_update_check(current_extract_grp,file_error,folder_name)\n",
    "               \n",
    "               #Check Duplicate Date, if current folder only have 1 file, skip this\n",
    "               filter_file = []\n",
    "               if current_check.count()[0,1]>1:\n",
    "                    filter_file = Duplicate_Date_Check(current_extract_grp,file_error,folder_name)\n",
    "                    \n",
    "               #Deviation in row check using valid list with format yyyymmdd_yyyymmdd from previous func\n",
    "               if filter_file:\n",
    "                    filtered_DF_standard_pattern = current_check.filter(pl.col(Name_Coumn_name).is_in(filter_file))\n",
    "                    Row_Compare(filtered_DF_standard_pattern,file_error,folder_name)\n",
    "               \n",
    "               #Row check for wild file name\n",
    "               filtered_DF_other_pattern = current_check.filter(pl.col(Name_Coumn_name).is_in(filter_file).not_())\n",
    "               if filtered_DF_other_pattern.count()[0,1]>1 and folder_name != \"CUIC\": \n",
    "                    #Delete the [and folder_name != \"CUIC\"] when feel like it's time (üëâÔæü„ÉÆÔæü)üëâDue to CUIC format is under renovation, temporarely remove it from the check so the number of file with new rows pattern will soon be sufficient to not bluffing during this report\n",
    "                    Row_Compare_Special(filtered_DF_other_pattern,file_error)\n",
    "\n",
    "                \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3fba4f1-13b5-4409-af5d-c370b1784089",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Error check CODE 2 and read LOG\n",
    "def Error_Check(Dataframe,extract_file,LINK):\n",
    "    #Check code 2\n",
    "    Only_Important = Dataframe.filter(pl.col(important_column)==\"IMPORTANT\",pl.col(Check_dup_column)>0)\n",
    "    if Only_Important.count()[0,1]>0:\n",
    "        for row in Only_Important.iter_rows(named=True):\n",
    "                print(f\"{bcolors.FAIL}Folder {row[Table_column]} has {row[Check_dup_column]} duplicate row{\"s\"if row[Check_dup_column]>1 else \" \"}{bcolors.ENDC}\")\n",
    "                extract_file.append((\"\",row[Table_column],F\"{row[Check_dup_column]} row(s) of duplicate data\"))\n",
    "    \n",
    "    #Check log\n",
    "    for file in glob.glob(LINK):\n",
    "        #Get file name -> folder name\n",
    "        Current_file = pl.read_excel(file)\n",
    "        filename = os.path.basename(file)\n",
    "        foldername = re.split('_log',filename)\n",
    "        # Looking out for error in error column of log file\n",
    "        try:\n",
    "            if Current_file.filter(pl.col(Error_log_column)!=\"\").count()[0,1]>0:\n",
    "                for row in Current_file.filter(pl.col(Error_log_column)!=\"\").iter_rows(named=True):\n",
    "                    print(f\"{bcolors.FAIL}Folder {row[Log_name_column]} in {foldername[0]} a has fatal error{bcolors.ENDC}\")\n",
    "                    extract_file.append((row[Log_name_column],foldername[0],\"Fatal Error\"))        \n",
    "        except Exception:\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ded2948-b601-4729-a84e-ee8c85f37f5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mSkip CUIC for missing check \u001b[0m\n",
      "\u001b[96mCUIC need to be updated to the newest data \u001b[0m\n",
      "\u001b[96mSkip CapHC for missing check \u001b[0m\n",
      "\u001b[96mSkip RONA for missing check \u001b[0m\n",
      "\u001b[96mSkip Quality for missing check \u001b[0m\n",
      "\u001b[96mQuality need to be updated to the newest data \u001b[0m\n",
      "\u001b[93mFile 20250831.xlsx - 2025-09-10 07:58:04 in Quality has inconsistent number of rows \u001b[0m\n",
      "\u001b[96mSkip IntervalReq for missing check \u001b[0m\n",
      "\u001b[96mFile 20251001_20251031.csv - 2025-10-14 17:50:07 in RAMCO might need to update\u001b[0m\n",
      "\u001b[96mSkip RegisteredOT for missing check \u001b[0m\n",
      "\u001b[96mFile 20251006_20251012.xlsx - 2025-10-10 15:23:17 in RegisteredOT might need to update\u001b[0m\n",
      "\u001b[96mSkip DailyReq for missing check \u001b[0m\n",
      "\u001b[93mFile 202303_202502.xlsx - 2025-02-27 20:34:37 in DailyReq has inconsistent number of rows \u001b[0m\n",
      "\u001b[96mWpSummary is not expected for the update check \u001b[0m\n",
      "\u001b[35mMissing 20250601_20250630 in folder CSAT_TP\u001b[0m\n",
      "\u001b[35mMissing 20250701_20250731 in folder CSAT_TP\u001b[0m\n",
      "\u001b[35mMissing 20250801_20250831 in folder CSAT_TP\u001b[0m\n",
      "\u001b[35mMissing 20251014 in folder CPI\u001b[0m\n",
      "\u001b[35mMissing 20251015 in folder CPI\u001b[0m\n",
      "\u001b[96mSkip ProjectedHC for missing check \u001b[0m\n",
      "\u001b[96mSkip Contrack for missing check \u001b[0m\n",
      "\u001b[96mIEX_Hrs is not expected for the update check \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#MAIN RUN\n",
    "file_error= []\n",
    "CategoryCheck(Code1_Result,file_error)\n",
    "Error_Check(Code2_Result,file_error,LOG_LINK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f8714ba-b4c6-4da5-ba2b-cde69e18f72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tungquan.le\\AppData\\Local\\Temp\\ipykernel_17632\\2347980961.py:3: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  error_report = pl.DataFrame(file_error, schema=[\"File Name\",\"Folder\",\"Reason\"],)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xlsxwriter.workbook.Workbook at 0x230d5df73b0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Final Report\n",
    "#T·∫°o dataframe tr·ªëng v·ªõi 3 c·ªôt\n",
    "error_report = pl.DataFrame(file_error, schema=[\"File Name\",\"Folder\",\"Reason\"],)\n",
    "#ƒê∆∞·ªùng d·∫´n \n",
    "Output_path = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN')\n",
    "#T√™n file xu·∫•t\n",
    "Output_file = os.path.join(Output_path,\n",
    "                            r'Mod_Log.xlsx')\n",
    "#L·ªánh xu·∫•t\n",
    "error_report.write_excel(Output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f11a83fb-3808-4ddb-adf1-40bbd4b9efab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Allow leaves\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import ColorScaleRule\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "\n",
    "personal_path = os.environ['USERPROFILE']\n",
    "middle_path = r'Concentrix Corporation\\CNXVN - WFM Team - Documents\\DataBase'\n",
    "user_credential = os.path.join(os.environ['USERPROFILE'], middle_path)\n",
    "\n",
    "# LinküìÉ\n",
    "requirement_path = os.path.join(user_credential, r'DataRaw\\BKN\\REQUIREMENT_HOURS')\n",
    "mr_path = os.path.join(user_credential, r'DataRaw\\BKN\\AGENTS')\n",
    "schedule_path = os.path.join(user_credential, r'DataRaw\\BKN\\ROSTER')\n",
    "ot_path = os.path.join(user_credential, r'DataRaw\\BKN\\OVERTIME')\n",
    "wp_path = os.path.join(user_credential, r'DataRaw\\BKN\\WP_SUMMARY')\n",
    "\n",
    "\n",
    "dtype_error_map = [['float64', 'int64'], ['datetime64[ns]', 'object'], ['object', 'float64'], ['int64', 'object']]\n",
    "\n",
    "def import_xlsx(path, **kwargs):\n",
    "    list_dir = sorted([x for x in os.listdir(path) if x.endswith('.xlsx')])\n",
    "    raw = []\n",
    "    standard_cols = pd.read_excel(os.path.join(path, list_dir[0]), engine=\"openpyxl\", sheet_name = list(kwargs.values())[0]).columns.to_list()\n",
    "    standard_dtype = pd.read_excel(os.path.join(path, list_dir[0]), engine=\"openpyxl\", sheet_name = list(kwargs.values())[0]).dtypes.to_dict()\n",
    "    change_log = []\n",
    "    global go\n",
    "    for file in list_dir:\n",
    "        file_path = os.path.join(path, file)\n",
    "        try:\n",
    "            next = True\n",
    "            sheetname_position = 0\n",
    "            while next == True and sheetname_position<= len(kwargs.values()):\n",
    "                try: \n",
    "                    file_data = pd.read_excel(file_path, engine=\"openpyxl\", sheet_name = list(kwargs.values())[sheetname_position])\n",
    "                    next = False\n",
    "                except:\n",
    "\n",
    "                    sheetname_position += 1\n",
    "                \n",
    "            file_data_dtype =  file_data.dtypes.to_dict()\n",
    "            for col in file_data.columns.to_list(): #check unexpected columns\n",
    "                if col not in standard_cols:\n",
    "                    print(f'{file} contains unexpected column {col}')\n",
    "                    change_log.append([dt.now().strftime(\"%Y-%m-%d %H:%M:%S\"), personal_path, file, \"unexpected column\", col])\n",
    "            for col in standard_cols: #check missing columns\n",
    "                if col not in file_data.columns.to_list():\n",
    "                    print(f'{file} has a missing column {col}')\n",
    "                    change_log.append([dt.now().strftime(\"%Y-%m-%d %H:%M:%S\"), personal_path, file, \"missing column\", col])\n",
    "            for key in standard_dtype:\n",
    "                if key in file_data.columns.to_list() and standard_dtype[key] != file_data_dtype[key]:\n",
    "                    if [standard_dtype[key], file_data_dtype[key]] in dtype_error_map or [file_data_dtype[key], standard_dtype[key]] in dtype_error_map:\n",
    "                        pass\n",
    "                    else:\n",
    "                        print(f'{file} {key}:{standard_dtype[key]} -> {file_data_dtype[key]}')\n",
    "                        change_log.append([dt.now().strftime(\"%Y-%m-%d %H:%M:%S\"), personal_path, file, \"wrong dtype\", key])\n",
    "            file_data[\"filename\"] = file\n",
    "            raw.append(file_data)\n",
    "        except:\n",
    "            print(f'Cannot input {file} into dataframe')\n",
    "\n",
    "    final_raw = pd.concat(raw, ignore_index=True)\n",
    "    return final_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "006b38a7-e0cf-4f4f-afe8-8baa9de63a1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mr = import_xlsx(mr_path, sheet_name=\"Sheet1\")\n",
    "schedule = import_xlsx(schedule_path, sheet_name=\"Sheet1\")\n",
    "schedule = schedule[schedule['Attribute'].dt.year >= 2025]\n",
    "ot = import_xlsx(ot_path, sheet_name=\"Sheet1\")\n",
    "ot = ot[ot['Date'].dt.year >= 2025]\n",
    "wp = import_xlsx(wp_path, sheet_name=\"Sheet1\")\n",
    "wp = wp[wp['Date'].dt.year >= 2025]\n",
    "req = import_xlsx(requirement_path, sheet_name=\"Sheet1\")\n",
    "req = req[req['Date'].dt.year >= 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75882470-18e2-42cc-8bde-f6cadcb353e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# mr['Employee_ID'] = mr['Employee_ID'].astype('int64')\n",
    "schedule = schedule.rename(columns={'Attribute':'Date','Value':'Shift'})\n",
    "schedule['Emp ID'] = schedule['Emp ID'].astype('int64')\n",
    "# Get TL Tedname\n",
    "schedule = pd.merge(schedule, mr[['Employee_ID', 'TED Name']], left_on='team_leader', right_on='Employee_ID', how='left')\n",
    "schedule = schedule.rename(columns={'TED Name':'TL'})\n",
    "schedule = schedule.drop(columns=['team_leader','Employee_ID'])\n",
    "ot = pd.merge(ot, schedule[['Emp ID','Date','LOB']], on=['Emp ID','Date'], how='left')\n",
    "ot = ot.drop(columns=['LOB_y'])\n",
    "ot = ot.rename(columns={'LOB_x':'LOB'})\n",
    "# sum ot per day, lob\n",
    "ot_date_lob = ot.groupby(['Date','LOB'], as_index=False)['OT'].sum()\n",
    "projected_AR = pd.DataFrame({'LOB':['EN','IT','FR','NO','CS','DE','NL','RU','RO','VICSG','VICSP','Senior VICSP'],\n",
    "                'Projected AR':['0.07','0.07','0.07','0.1','0.1','0.07','0.07','0.1','0.1','0.1','0.1','0.1']})\n",
    "projected_AR['Projected AR'] = projected_AR['Projected AR'].astype('float')\n",
    "wp = wp[wp['Scheduled Activity'].isin([\"Team Meeting\", \"Coaching 1:1\", \"Training Offline\",\"Training N\",\"Training U\",\"Training A\",\"Coaching 1:1 Offline\",\"Training Q\"])]\n",
    "wp = wp.groupby(['Date','LOB'], as_index=False)['Length'].sum()\n",
    "wp['Length'] = wp['Length']*24\n",
    "wp = wp.rename(columns={'Length':'Downtime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bed3b4a2-921b-4f2c-bd2c-274bd08befcb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "schedule = schedule[(schedule.Shift != 'OFF') & (schedule.Shift != 'Training')]\n",
    "schedule['Leaves'] = schedule.apply(lambda x: 1 if x['Shift'] in ['UPL','AL','CO'] else 0, axis=1)\n",
    "# total leaves per catogory\n",
    "leaves_date_lob = schedule.groupby(['Date','LOB'], as_index=False)['Leaves'].sum()\n",
    "leaves_date_lob = leaves_date_lob.rename(columns={'Leaves':'Leaves per LOB'})\n",
    "leaves_tl_date_lob = schedule.groupby(['Date','LOB','TL'], as_index=False)['Leaves'].sum()\n",
    "leaves_tl_date_lob = leaves_tl_date_lob.rename(columns={'Leaves':'Leaves per TL'})\n",
    "# total hc per catogory\n",
    "hc_by_date_lob = schedule.groupby(['Date','LOB'], as_index=False)['Emp ID'].count()\n",
    "hc_by_date_lob = hc_by_date_lob.rename(columns={'Emp ID':'HC per LOB'})\n",
    "hc_by_date_lob = pd.merge(hc_by_date_lob, leaves_date_lob, on = ['Date','LOB'], how='left')\n",
    "hc_by_tl_date_lob = schedule.groupby(['Date','LOB','TL'], as_index=False)['Emp ID'].count()\n",
    "hc_by_tl_date_lob = hc_by_tl_date_lob.rename(columns={'Emp ID':'HC per TL'})\n",
    "hc_by_tl_date_lob = pd.merge(hc_by_tl_date_lob, leaves_tl_date_lob, on = ['Date','LOB','TL'], how='left')\n",
    "# mapping hc vs leaves VS OT\n",
    "mapping_hc = pd.merge(hc_by_date_lob, hc_by_tl_date_lob, on = ['Date','LOB'], how='left')\n",
    "mapping_hc = pd.merge(mapping_hc, req, on = ['Date','LOB'], how='left')\n",
    "mapping_hc = pd.merge(mapping_hc, ot_date_lob, on = ['Date','LOB'], how='left')\n",
    "mapping_hc['Week'] = mapping_hc['Date'].dt.strftime('%Y%W').astype('int64')\n",
    "mapping_hc = pd.merge(mapping_hc, projected_AR, on='LOB', how='left')\n",
    "mapping_hc = pd.merge(mapping_hc, wp, on = ['Date','LOB'], how='left')\n",
    "mapping_hc['Downtime'] = mapping_hc['Downtime'].fillna(0)\n",
    "mapping_hc['Projected prod hrs'] = mapping_hc['HC per LOB']*7.5*(1-mapping_hc['Projected AR'])- mapping_hc['Downtime']\n",
    "mapping_hc['O/U'] = mapping_hc['Projected prod hrs'] - mapping_hc['Prod Requirement']\n",
    "mapping_hc['Allowed leaves_HC_tl'] = ((mapping_hc['HC per TL']/mapping_hc['HC per LOB'])*mapping_hc['O/U'])/7.5\n",
    "mapping_hc['Allowed leaves_HC_tl'] = mapping_hc.apply(lambda x: x['Allowed leaves_HC_tl'] if x['Allowed leaves_HC_tl'] >= 0 else 0, axis=1)\n",
    "mapping_hc['Deficit'] = (mapping_hc['Allowed leaves_HC_tl'] - mapping_hc['Leaves per TL']).round(2)\n",
    "mapping_hc['Negative deficit'] = mapping_hc.apply(lambda x: 'Yes' if x['Deficit'] < 0 else '', axis=1)\n",
    "mapping_hc = mapping_hc[mapping_hc['Date'].dt.year >= 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bb6ebfea-ec46-4d81-a80b-1f2e9f45d4e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_path = os.path.join(user_credential, r'DataRaw\\BKN\\Change LOB')\n",
    "allow_leave = mapping_hc[['Week','Date','LOB','TL','Deficit']]\n",
    "# pivot_table = pivot_table[pivot_table['Deficit'] < 0]\n",
    "allow_leave['Week'] = allow_leave['Date'].dt.strftime('%Y%W')\n",
    "allow_leave['Date'] = allow_leave['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "current_week = datetime.now().strftime('%Y%W')\n",
    "allow_leave = allow_leave.loc[(allow_leave['Week'] == current_week)]\n",
    "pivot_table = allow_leave[['Date','LOB','TL','Deficit']]\n",
    "pivot_table=pl.from_pandas(pivot_table)\n",
    "pivot_table = pivot_table.pivot(\n",
    "    index=[\"Date\",\"TL\",],\n",
    "    on=\"LOB\",\n",
    "    aggregate_function=\"sum\" # WE can use 'first' n·∫øu ch·ªâ c√≥ 1 gi√° tr·ªã duy nh·∫•t cho m·ªói t·ªï h·ª£p index/columns\n",
    ")\n",
    "\n",
    "pivot_table=pivot_table.to_pandas()\n",
    "\n",
    "# Export to xlsx\n",
    "os.chdir(output_path)\n",
    "writer = pd.ExcelWriter(\"Allowed leaves pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "pivot_table.to_excel(writer, sheet_name=\"Sheet1\", startrow=1,header=False ,index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "(max_row, max_col) = pivot_table.shape\n",
    "column_settings = [{\"header\": column} for column in pivot_table.columns]\n",
    "worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "worksheet.set_column(0, 1, 19)\n",
    "worksheet.set_column(2, max_col - 1, 5)\n",
    "worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#F8696B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#63BE7B'})\n",
    "writer.close()\n",
    "\n",
    "pivot_total = allow_leave[['LOB','TL','Deficit']]\n",
    "pivot_total=pl.from_pandas(pivot_total)\n",
    "pivot_total = pivot_total.pivot(\n",
    "    index=[\"TL\",],\n",
    "    on=\"LOB\",\n",
    "    aggregate_function=\"sum\" # WE can use 'first' n·∫øu ch·ªâ c√≥ 1 gi√° tr·ªã duy nh·∫•t cho m·ªói t·ªï h·ª£p index/columns\n",
    ")\n",
    "\n",
    "pivot_total=pivot_total.to_pandas()\n",
    "\n",
    "# Export to xlsx\n",
    "os.chdir(output_path)\n",
    "writer = pd.ExcelWriter(\"Allowed leaves total.xlsx\", engine=\"xlsxwriter\")\n",
    "pivot_total.to_excel(writer, sheet_name=\"Sheet1\", startrow=1,header=False ,index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "(max_row, max_col) = pivot_total.shape\n",
    "column_settings = [{\"header\": column} for column in pivot_total.columns]\n",
    "worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "worksheet.set_column(0, 0, 19)\n",
    "worksheet.set_column(1, max_col - 1, 5)\n",
    "worksheet.conditional_format(1, 1, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#F8696B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#63BE7B'})\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ec9a2b4-7b78-4d0d-bbf2-c3bd406eab00",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#OT_DETAIL (Aimee ask for report OT > 40H)\n",
    "sql_query=\"\"\"\n",
    "with ot_raw as (\n",
    "select [OM_Name],[TL_Name],[Emp_Name] as [Agent_Name],[Week_num],[OT_Registered(s)],DATENAME(month,[Date]) as [MONTH],month([Date]) as [#MONTH],[Date]\n",
    "from BCOM.EEAAO\n",
    "where [Date]>=DATEADD(DAY, -100,CAST(GETDATE() As Date)) \n",
    "and [OT_Registered(s)]>0 and MONTH([Date])>=month(CAST(GETDATE() As Date))-2),\n",
    "ot as (\n",
    "select [OM_Name],[TL_Name],[Agent_Name],[MONTH], [#MONTH],sum(cast([OT_Registered(s)] as float)/3600) as [OT]\n",
    "from ot_raw\n",
    "group by  [OM_Name],[TL_Name],[Agent_Name],[MONTH], [#MONTH])\n",
    "select * from ot where [OT]>40\n",
    "\"\"\"\n",
    "ot = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(ot_report)\n",
    "ot_CSV = ot.write_excel(workbook=\"BKN_OT.xlsx\",worksheet=\"Sheet1\",table_name='Frame0', autofit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9fbb679a-50ba-41d4-bc8c-391c5191baba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#OT_MONTH (Aimee ask for report OT > 40H) group by month\n",
    "sql_query=\"\"\"\n",
    "with ot_raw as (\n",
    "select [OM_Name],[TL_Name],[Emp_Name] as [Agent_Name],[Week_num],[OT_Registered(s)],DATENAME(month,[Date]) as [MONTH],month([Date]) as [#MONTH],[Date]\n",
    "from BCOM.EEAAO\n",
    "where [Date]>=DATEADD(DAY, -100,CAST(GETDATE() As Date)) \n",
    "and [OT_Registered(s)]>0 and MONTH([Date])>=month(CAST(GETDATE() As Date))-2),\n",
    "ot as (\n",
    "select [OM_Name],[TL_Name],[Agent_Name],[MONTH], [#MONTH],sum(cast([OT_Registered(s)] as float)/3600) as [OT],\n",
    "case when sum(cast([OT_Registered(s)] as float)/3600)>40 then 1 else 0 end as [Cases]\n",
    "from ot_raw\n",
    "group by  [OM_Name],[TL_Name],[Agent_Name],[MONTH], [#MONTH]),\n",
    "ot_month as (\n",
    "select [OM_Name],[TL_Name],[MONTH], [#MONTH],sum([Cases]) as [Cases]\n",
    "from ot\n",
    "group by [OM_Name],[TL_Name],[MONTH], [#MONTH])\n",
    "select * from ot_month where [Cases]>0\n",
    "\"\"\"\n",
    "ot_month = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "ot_month=ot_month.to_pandas()\n",
    "ot_month['#MONTH']=ot_month['#MONTH'].astype(\"int64\")\n",
    "ot_month=ot_month.sort_values(by='#MONTH',ascending=True)\n",
    "ot_month=ot_month[['OM_Name','TL_Name','MONTH','Cases']]\n",
    "ot_month= pl.from_pandas(ot_month)\n",
    "pivot_ot_month = ot_month.pivot(\n",
    "            values=[\"Cases\",],\n",
    "            index=[\"OM_Name\",\"TL_Name\",],\n",
    "            on=\"MONTH\",\n",
    "            aggregate_function=\"sum\" # WE can use 'first' n·∫øu ch·ªâ c√≥ 1 gi√° tr·ªã duy nh·∫•t cho m·ªói t·ªï h·ª£p index/columns\n",
    "        )\n",
    " \n",
    "pivot_ot_month = pivot_ot_month.to_pandas()\n",
    "pivot_ot_month=pivot_ot_month.sort_values(by=[\"OM_Name\",\"TL_Name\"],ascending=True)\n",
    "# Export to xlsx\n",
    "os.chdir(ot_report)\n",
    "writer = pd.ExcelWriter(\"BKN_OT_MONTH.xlsx\", engine=\"xlsxwriter\")\n",
    "pivot_ot_month.to_excel(writer, sheet_name=\"Sheet1\", startrow=1,header=False ,index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "(max_row, max_col) = pivot_ot_month.shape\n",
    "column_settings = [{\"header\": column} for column in pivot_ot_month.columns]\n",
    "worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "worksheet.set_column(0, 1, 19)\n",
    "worksheet.set_column(2, max_col - 1, 7)\n",
    "worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d7c674fa-38f9-48a7-8570-16960efd3ec2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#OT_WEEK (Aimee ask for report OT > 40H) group by weeks\n",
    "sql_query=\"\"\"\n",
    "with ot_raw as (\n",
    "select [OM_Name],[TL_Name],[Emp_Name] as [Agent_Name],[Week_num],[OT_Registered(s)],\n",
    "CASE WHEN FORMAT(DATEPART(ISO_WEEK, [Date]),'00') < 3 AND MONTH([Date]) > 10\n",
    "\tTHEN CONCAT(YEAR([Date])+1, FORMAT(DATEPART(ISO_WEEK,[Date]),'00'))\n",
    "\tELSE CONCAT(YEAR([Date]), FORMAT(DATEPART(ISO_WEEK,[Date] ),'00'))\n",
    "\tEND AS [Week],\n",
    "[Date]\n",
    "from BCOM.EEAAO\n",
    "where [Date]>=DATEADD(DAY, -100,CAST(GETDATE() As Date)) \n",
    "and [OT_Registered(s)]>0 \n",
    "and CASE WHEN FORMAT(DATEPART(ISO_WEEK, [Date]),'00') < 3 AND MONTH([Date]) > 10\n",
    "\tTHEN CONCAT(YEAR([Date])+1, FORMAT(DATEPART(ISO_WEEK,[Date]),'00'))\n",
    "\tELSE CONCAT(YEAR([Date]), FORMAT(DATEPART(ISO_WEEK,[Date] ),'00'))\n",
    "\tEND >=CASE WHEN FORMAT(DATEPART(ISO_WEEK, CAST(GETDATE() As Date)),'00') < 3 AND MONTH(CAST(GETDATE() As Date)) > 10\n",
    "\tTHEN CONCAT(YEAR(CAST(GETDATE() As Date))+1, FORMAT(DATEPART(ISO_WEEK,CAST(GETDATE() As Date)),'00'))\n",
    "\tELSE CONCAT(YEAR(CAST(GETDATE() As Date)), FORMAT(DATEPART(ISO_WEEK,CAST(GETDATE() As Date) ),'00'))\n",
    "\tEND-5),\n",
    "ot as (\n",
    "select [OM_Name],[TL_Name],[Agent_Name],[Week],sum(cast([OT_Registered(s)] as float)/3600) as [OT],\n",
    "case when sum(cast([OT_Registered(s)] as float)/3600)>20 then 1 else 0 end as [Cases]\n",
    "from ot_raw\n",
    "group by  [OM_Name],[TL_Name],[Agent_Name],[Week]),\n",
    "ot_month as (\n",
    "select [OM_Name],[TL_Name],[Week],sum([Cases]) as [Cases]\n",
    "from ot\n",
    "group by [OM_Name],[TL_Name],[Week])\n",
    "select * from ot_month where [Cases]>0\n",
    "\"\"\"\n",
    "ot_week = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "ot_week=ot_week.to_pandas()\n",
    "ot_week['Week']=ot_week['Week'].astype(\"int64\")\n",
    "ot_week=ot_week.sort_values(by='Week',ascending=True)\n",
    "ot_week=ot_week[['OM_Name','TL_Name','Week','Cases']]\n",
    "ot_week= pl.from_pandas(ot_week)\n",
    "pivot_ot_week = ot_week.pivot(\n",
    "            values=[\"Cases\",],\n",
    "            index=[\"OM_Name\",\"TL_Name\",],\n",
    "            on=\"Week\",\n",
    "            aggregate_function=\"sum\" # WE can use 'first' n·∫øu ch·ªâ c√≥ 1 gi√° tr·ªã duy nh·∫•t cho m·ªói t·ªï h·ª£p index/columns\n",
    "        )\n",
    " \n",
    "pivot_ot_week = pivot_ot_week.to_pandas()\n",
    "pivot_ot_week=pivot_ot_week.sort_values(by=[\"OM_Name\",\"TL_Name\"],ascending=True)\n",
    "# Export to xlsx\n",
    "os.chdir(ot_report)\n",
    "writer = pd.ExcelWriter(\"BKN_OT_WEEK.xlsx\", engine=\"xlsxwriter\")\n",
    "pivot_ot_week.to_excel(writer, sheet_name=\"Sheet1\", startrow=1,header=False ,index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "(max_row, max_col) = pivot_ot_week.shape\n",
    "column_settings = [{\"header\": column} for column in pivot_ot_week.columns]\n",
    "worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "worksheet.set_column(0, 1, 19)\n",
    "worksheet.set_column(2, max_col - 1, 7)\n",
    "worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
