{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2346d1-0842-4245-9bb9-1e6136aab7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library listðŸ¤–\n",
    "import glob, warnings, polars as pl, datetime, sqlite3, time, os, zipfile, xml.dom.minidom\n",
    "from datetime import datetime as dt, time as t, timedelta, date\n",
    "import pandas as pd, numpy as np, sqlalchemy as sa, xlsxwriter\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from sqlalchemy import create_engine, text\n",
    "import math\n",
    "# -----------------------------------------------------------------------------------------------#\n",
    "# Source collection\n",
    "# user_credential = os.path.join(os.environ['USERPROFILE'],r'Concentrix Corporation//CNXVN - WFM Team - Documents//')\n",
    "user_credential = os.path.join(os.environ['USERPROFILE'],r'Concentrix Corporation//CNXVN - WFM Team - Documents//')\n",
    "\n",
    "# INPUT-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾\n",
    "# [BKN]LOGOUT_COUNT 0ï¸âƒ£1ï¸âƒ£\n",
    "Link_LOGOUT_COUNT = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN//LOGOUT_COUNT//*.CSV')\n",
    "# [BKN]AGENTS 0ï¸âƒ£2ï¸âƒ£\n",
    "Link_AGENTS = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//AGENTS//*.xlsx')\n",
    "# [GLB]EmployeeMaster 0ï¸âƒ£3ï¸âƒ£\n",
    "Link_EmployeeMaster = os.path.join(user_credential,\n",
    "                                    r'DataBase//DataRaw//GLOBAL//WDD//*.xlsx')\n",
    "# [GLB]Ramco 0ï¸âƒ£4ï¸âƒ£\n",
    "Link_Ramco = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//GLOBAL//RAMCO//*.CSV')\n",
    "# [BKN]Schedule 0ï¸âƒ£5ï¸âƒ£\n",
    "Link_Schedule = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//ROSTER//*.xlsx')\n",
    "# [BKN]EPS 0ï¸âƒ£6ï¸âƒ£\n",
    "Link_EPS = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//EPS//*.CSV')\n",
    "# [BKN]AHT 0ï¸âƒ£7ï¸âƒ£\n",
    "Link_AHT = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//AHT//*.CSV')\n",
    "# [BKN]Holiday 0ï¸âƒ£8ï¸âƒ£\n",
    "Link_Holiday = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//HOLIDAY_MAPPING//*.CSV')\n",
    "# [BKN]IntervalReq 0ï¸âƒ£9ï¸âƒ£\n",
    "Link_IntervalReq = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN//INTERVAL_REQUIREMENT//*.xlsx')\n",
    "# [BKN]CapacityHC 1ï¸âƒ£0ï¸âƒ£\n",
    "Link_CapacityHC = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN//CAPACITY_HC//*.xlsx')\n",
    "# [BKN]RampHC 1ï¸âƒ£1ï¸âƒ£\n",
    "Link_RampHC = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//RAMPUP_HC//*.xlsx')\n",
    "# [BKN]CSAT_Tp 1ï¸âƒ£2ï¸âƒ£\n",
    "Link_CSAT_Tp = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//CSAT//*.CSV')\n",
    "# [BKN]CSAT_Rs 1ï¸âƒ£3ï¸âƒ£\n",
    "Link_CSAT_Rs = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//CSAT_RESO//*.CSV')\n",
    "# [BKN]CUIC 1ï¸âƒ£4ï¸âƒ£\n",
    "Link_CUIC = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//CUIC//*.xlsx')\n",
    "# [BKN]ExcepReq 1ï¸âƒ£5ï¸âƒ£\n",
    "Link_ExcepReq = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//EXCEPTION_REQ//*.xlsx')\n",
    "# [BKN]KPI_Tar 1ï¸âƒ£6ï¸âƒ£\n",
    "Link_KPI_Tar = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//KPI_TARGET//*.xlsx')\n",
    "# [BKN]OverTime 1ï¸âƒ£7ï¸âƒ£\n",
    "Link_OverTime = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//OVERTIME//*.xlsx')\n",
    "# [BKN]PSAT 1ï¸âƒ£8ï¸âƒ£\n",
    "Link_PSAT = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//PSAT//*.CSV')\n",
    "# [BKN]Quality 1ï¸âƒ£9ï¸âƒ£\n",
    "Link_Quality = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//QUALITY//*.xlsx')\n",
    "# [GLB]OTRamco 2ï¸âƒ£0ï¸âƒ£\n",
    "Link_OTRamco = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//GLOBAL//OT_RAMCO//*.xlsx')\n",
    "# [BKN]DailyReq 2ï¸âƒ£1ï¸âƒ£\n",
    "Link_DailyReq = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//REQUIREMENT_HOURS//*.xlsx')\n",
    "# [BKN]IEX 2ï¸âƒ£2ï¸âƒ£\n",
    "Link_IEX = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//IEX//*.xlsx')\n",
    "# [BKN]Workplan 2ï¸âƒ£3ï¸âƒ£\n",
    "Link_Workplan = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//WORKPLAN//WORKPLAN QUERY//*.xlsx')\n",
    "# [BKN]Ticket 2ï¸âƒ£4ï¸âƒ£\n",
    "Link_Ticket = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//TICKET//*.CSV')\n",
    "# [BKN]RONA 2ï¸âƒ£5ï¸âƒ£\n",
    "Link_RONA = os.path.join(user_credential,\n",
    "                        r'DataBase//DataRaw//BKN//RONA//*.xlsx')\n",
    "# [BKN]SC_Labels 2ï¸âƒ£6ï¸âƒ£\n",
    "Link_SC_Labels = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//SC_LABELS//*.CSV')\n",
    "# [BKN]ShrinkTar 2ï¸âƒ£7ï¸âƒ£\n",
    "Link_ShrinkTar = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//SHRINKAGE_TARGET//*.xlsx')\n",
    "# [GLB]WorkdayDump 2ï¸âƒ£8ï¸âƒ£\n",
    "Link_Attri_Ter = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//GLOBAL//WDD//*.xlsx')\n",
    "# [BKN]HC_Transfer 2ï¸âƒ£9ï¸âƒ£\n",
    "Link_HC_Transfer = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN//HC_TRANSFER//*.xlsx')\n",
    "# [BKN]Workplan_summary 3ï¸âƒ£0ï¸âƒ£\n",
    "Link_Workplan_summary = os.path.join(user_credential,\n",
    "                                    r'DataBase//DataRaw//BKN//WORKPLAN_SUMMARY//WORKPLAN_SUMMARY_QUERY//*.xlsx')\n",
    "# [BKN]CSAT_PEGA 3ï¸âƒ£1ï¸âƒ£\n",
    "Link_CSAT_PEGA = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//CSAT_PEGA//*.CSV')\n",
    "# [BKN]IPH_PEGA 3ï¸âƒ£2ï¸âƒ£\n",
    "Link_IPH_PEGA = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//IPH_PEGA//*.CSV')\n",
    "#[BKN]ContactTracker 3ï¸âƒ£3ï¸âƒ£\n",
    "Link_ContactTracker = os.path.join(os.environ['USERPROFILE'],\n",
    "                                   r'OneDrive - Concentrix Corporation//DataBase//DataRaw//BKN//ContactTracker//*.xlsx')\n",
    "# [BKN]OT_REQ 3ï¸âƒ£4ï¸âƒ£\n",
    "Link_OT_REQ = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//OT_REQ//*.xlsx')\n",
    "# [BKN]PROJECTED_HC 3ï¸âƒ£5ï¸âƒ£\n",
    "Link_PROJECTED_HC = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//PROJECTED_HEADCOUNT//*.xlsm')\n",
    "# [BKN]IEXHRS 3ï¸âƒ£6ï¸âƒ£\n",
    "Link_IEXHRS = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//IEXHOURS//Overview Interval Query//*.xlsx')\n",
    "# [BKN]REALTIME_CUIC 3ï¸âƒ£7ï¸âƒ£\n",
    "Link_REALTIME_CUIC = os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//REALTIME_VIEW//*.xlsx')\n",
    "\n",
    "# OUTPUT-----ðŸ“¥-----ðŸ“¥-----ðŸ“¥-----ðŸ“¥-----ðŸ“¥-----ðŸ“¥-----ðŸ“¥-----ðŸ“¥-----ðŸ“¥-----ðŸ“¥\n",
    "# [BKN]EEAAO ðŸ“‘\n",
    "DF_EEAAO = os.path.join(user_credential, \n",
    "                        r'DataBase//DataFrame//BKN//EEAAO_DF')\n",
    "# [BKN]REVENUE ðŸ“‘\n",
    "DF_REVENUE = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//REVENUE')\n",
    "# [BKN]CSAT_CMB ðŸ“‘\n",
    "DF_CSAT_CMB = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//CSAT_COMBINE')\n",
    "# [BKN]JEOPADY ðŸ“‘\n",
    "DF_JEOPADY = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//JEOPADY')\n",
    "\n",
    "# [GLB]NM_REPORT ðŸ“‘\n",
    "DF_NM_REPORT = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//GLOBAL//NM_REPORT')\n",
    "# [GLB]OT_REPORT ðŸ“‘\n",
    "DF_OT_REPORT = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//GLOBAL//OT_REPORT')\n",
    "# [BKN]AgentWorkPlan ðŸ“‘\n",
    "DF_AGENT_WORKPLAN = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//AGENT_WORKPLAN')\n",
    "# [BKN]INTERVAL_REQ ðŸ“‘\n",
    "DF_INTERVAL_REQ = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//INTERVAL_REQ')\n",
    "# [BKN]CONTACT_TRACKER ðŸ“‘\n",
    "DF_CONTACT_TRACKER = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//CONTACT_TRACKER')\n",
    "# [BKN]DATA_TRACKER ðŸ“‘\n",
    "DF_DATA_TRACKER = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//DATA_TRACKER')\n",
    "# [BKN]IEXHRS ðŸ“‘\n",
    "DF_IEXHRS = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//IEXHOURS')\n",
    "# [BKN]AHT_DETAIL ðŸ“‘\n",
    "DF_AHT_DETAIL = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//AHT_DETAIL')\n",
    "# [BKN]ATTRITION ðŸ“‘\n",
    "DF_ATTRITION = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//ATTRITION_DF')\n",
    "# [BKN]CHECKDUP ðŸ“‘\n",
    "DF_CHECKDUP = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//CHECKDUP')\n",
    "# [BKN]ATD_DF ðŸ“‘\n",
    "DF_ATD_DF = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//ATD_DF')\n",
    "# [BKN]ATD_DF ðŸ“‘\n",
    "DF_LOGIN_DF = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//LOGIN_DETAIL_DF//Booking - Agent Wise Login Detail.xlsx')\n",
    "Login_Logout_Folder= os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//Late_Soon_Insight')\n",
    "Stafftime_Folder= os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//Shortage of Stafftime')\n",
    "Logout_Count_Folder= os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//LOGOUT_COUNT_Insight')\n",
    "Low_CPH_Folder= os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//Low_CPH_Insight')\n",
    "OOH_Folder=os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN//Out_of_Hoop_insight')\n",
    "BKN_Folder= os.path.join(user_credential,\n",
    "                            r'DataBase//DataRaw//BKN')\n",
    "CPH_QUALITY_AHT_DF = os.path.join(user_credential, \n",
    "                            r'RTA_PersonalFile//Alice Nguyen')\n",
    "Seatmap = os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//SEAT_MAP')\n",
    "schedule=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//SCHEDULE')\n",
    "attrition=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//ATTRITION')\n",
    "delivery=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//DELIVERY')\n",
    "csat=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//CSAT')\n",
    "cph=os.path.join(user_credential, \n",
    "                            r'DataBase//TrainModel//CPH')\n",
    "\n",
    "data_tracker=os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//DATA_TRACKER')\n",
    "atd=os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//ATD_DF')\n",
    "ot_report=os.path.join(user_credential, \n",
    "                            r'DataBase//DataFrame//BKN//OT')\n",
    "# -----------------------------------------------------------------------------------------------#\n",
    "# Tracker_Folder\n",
    "folder_paths = [\n",
    "    os.path.dirname(Link) for Link in [\n",
    "        Link_LOGOUT_COUNT, Link_AGENTS, Link_EmployeeMaster, Link_Ramco, Link_Schedule, Link_EPS, Link_AHT, Link_Holiday, \n",
    "        Link_IntervalReq, Link_CapacityHC, Link_RampHC, Link_CSAT_Tp, Link_CSAT_Rs, Link_CUIC, Link_ExcepReq, Link_KPI_Tar, \n",
    "        Link_OverTime, Link_PSAT, Link_Quality, Link_OTRamco, Link_DailyReq, Link_IEX, Link_Workplan, Link_Ticket, Link_RONA, \n",
    "        Link_SC_Labels, Link_ShrinkTar, Link_Attri_Ter, Link_HC_Transfer, Link_Workplan_summary, Link_CSAT_PEGA, Link_IPH_PEGA, \n",
    "        Link_OT_REQ, Link_IEXHRS]] \n",
    "\n",
    "# -----------------------------------------------------------------------------------------------#\n",
    "# MyMiscellaneous\n",
    "\n",
    "# [DB]TonyMiscellaneous\n",
    "Link_DB = os.path.join(os.environ['USERPROFILE'], r'Desktop//Bcom_DB.db')\n",
    "link_PENDINGDETAIL = os.path.join(user_credential, r'DataBase//DataFrame//GLOBAL//PendingDetail//DetailPending.xlsx')\n",
    "conn = create_engine(f\"sqlite:///{Link_DB}\")\n",
    "server_name = \"PHMANVMDEV01V\"\n",
    "server_ip = \"10.5.11.60\"\n",
    "database = \"wfm_vn_dev\"\n",
    "user = \"usr_wfmvn_dev\"\n",
    "password = \"12guWU2OdEj5kEspl9Rlfoglf\"\n",
    "# SQL Server Authentication ðŸ”—\n",
    "connection_string = f\"mssql+pyodbc://{user}:{password}@{server_ip}/{database}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "# Windows Authentication ðŸ”—\n",
    "# connection_string = f\"mssql+pyodbc://{server_name}/{database}?driver=ODBC+Driver+17+for+SQL+Server&Trusted_Connection=yes\"\n",
    "engine = create_engine(connection_string, fast_executemany=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1012b368-4b36-4783-8dd6-7e05974bc484",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ATD MAIL Detail LINK ( Diliip xa ma)\n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[week_shift],[Original_Shift] as [Shift],\n",
    "cast([CUICLoggedTime(s)] as float)/3600 as [CUIC Hrs],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [ATD],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END AS [NormalShift],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk],\n",
    "CASE WHEN [Shift]='OFF' then 0 else 1 end as [Headcount],cast([OT_Registered(s)] as float)/3600 as [OT],[Ramco_Code] as [RAMCO],\n",
    "CASE WHEN [ScheduleHours(H)]>0 THEN 1 ELSE 0 END AS [Schedule Agents],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9 WHEN [ScheduleHours(H)]>0 THEN 4 ELSE 0 END AS [Schedule Hours],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9+cast([OT_Registered(s)] as float)/3600 \n",
    "WHEN [ScheduleHours(H)]>0 THEN 4+cast([OT_Registered(s)] as float)/3600 ELSE 0 END AS [Schedule+OT],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 9 WHEN [SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Unplanned Lost Hrs],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 9 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Planned Lost Hrs]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]>DATEADD(DAY, -60,CAST(GETDATE() As Date))\n",
    "order by [Date] desc\n",
    "\"\"\"\n",
    " \n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "atd_mail_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_mail_CSV = atd_mail_df.write_excel(workbook=\"BKN_ATD_Mail.xlsx\",worksheet=\"Sheet1\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1b786af-bf9f-42f0-a127-e730512f7c3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ATD Mail PIVOT 1 Overall (Dillip team)\n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    "with ATD as (\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[week_shift],[Original_Shift] as [Shift],\n",
    "cast([CUICLoggedTime(s)] as float)/3600 as [CUIC Hrs],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [ATD],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END AS [NormalShift],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk],\n",
    "CASE WHEN [Shift]='OFF' then 0 else 1 end as [Headcount],cast([OT_Registered(s)] as float)/3600 as [OT],[Ramco_Code] as [RAMCO],\n",
    "CASE WHEN [ScheduleHours(H)]>0 THEN 1 ELSE 0 END AS [Schedule Agents],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9 WHEN [ScheduleHours(H)]>0 THEN 4 ELSE 0 END AS [Schedule Hours],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9+cast([OT_Registered(s)] as float)/3600 \n",
    "WHEN [ScheduleHours(H)]>0 THEN 4+cast([OT_Registered(s)] as float)/3600 ELSE 0 END AS [Schedule+OT],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 9 WHEN [SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Unplanned Lost Hrs],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 9 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Planned Lost Hrs]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]>=DATEADD(DAY, -2,CAST(GETDATE() As Date)) and [Date]<=DATEADD(DAY, 0,CAST(GETDATE() As Date)))\n",
    "select [Date],sum([Schedule Agents]) as [Schedule Agents],sum([Schedule Hours]) as [Schedule Hours],\n",
    "sum([OT]) as [OT],sum([Schedule+OT]) as [Schedule+OT],sum([Unplanned Lost Hrs]) as [Unplanned Lost Hrs],\n",
    "sum([Planned Lost Hrs]) as [Planned Lost Hrs],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs])/sum([Schedule+OT]) end as [Unplanned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Planned Lost Hrs])/sum([Schedule+OT]) end as [Planned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Overall AR %],\n",
    "1-case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Attendance %]\n",
    "from ATD\n",
    "group by [Date]\n",
    "\"\"\"\n",
    " \n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "atd_pivot1_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "atd_pivot1_df=atd_pivot1_df.with_columns(pl.col(\"Date\").dt.to_string(\"%Y-%m-%d\"))\n",
    "atd_pivot1_df=atd_pivot1_df.to_pandas()\n",
    "atd_pivot1_df['Unplanned AR%'] = atd_pivot1_df['Unplanned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot1_df['Planned AR%'] = atd_pivot1_df['Planned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot1_df['Overall AR %'] = atd_pivot1_df['Overall AR %'].map('{:.2%}'.format)\n",
    "atd_pivot1_df['Attendance %'] = atd_pivot1_df['Attendance %'].map('{:.2%}'.format)\n",
    "atd_pivot1_df['OT'] = atd_pivot1_df['OT'].fillna(0)\n",
    "atd_pivot1_df['OT'] = atd_pivot1_df['OT'].astype(\"int64\")\n",
    "atd_pivot1_df['Schedule+OT'] = atd_pivot1_df['Schedule+OT'].fillna(0)\n",
    "atd_pivot1_df['Schedule+OT'] = atd_pivot1_df['Schedule+OT'].astype(\"int64\")\n",
    "\n",
    "atd_pivot1_df=pl.from_pandas(atd_pivot1_df)\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_pivot1_CSV = atd_pivot1_df.write_excel(workbook=\"BKN_ATD_pivot_1.xlsx\",worksheet=\"Sheet1\",\n",
    "                                           table_name='Table1', table_style='Table Style Medium 2',autofit=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "646dd65a-e60e-4152-baa3-bf9501c0c303",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ATD Mail PIVOT 2 By LOB (Dillip team)\n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    "with ATD as (\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[week_shift],[Original_Shift] as [Shift],\n",
    "cast([CUICLoggedTime(s)] as float)/3600 as [CUIC Hrs],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [ATD],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END AS [NormalShift],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk],\n",
    "CASE WHEN [Shift]='OFF' then 0 else 1 end as [Headcount],cast([OT_Registered(s)] as float)/3600 as [OT],[Ramco_Code] as [RAMCO],\n",
    "CASE WHEN [ScheduleHours(H)]>0 THEN 1 ELSE 0 END AS [Schedule Agents],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9 WHEN [ScheduleHours(H)]>0 THEN 4 ELSE 0 END AS [Schedule Hours],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9+cast([OT_Registered(s)] as float)/3600 \n",
    "WHEN [ScheduleHours(H)]>0 THEN 4+cast([OT_Registered(s)] as float)/3600 ELSE 0 END AS [Schedule+OT],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 9 WHEN [SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Unplanned Lost Hrs],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 9 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Planned Lost Hrs]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]=DATEADD(DAY, 0,CAST(GETDATE() As Date)))\n",
    "select [Date],[LOB],sum([Schedule Agents]) as [Schedule Agents],sum([Schedule Hours]) as [Schedule Hours],\n",
    "sum([OT]) as [OT],sum([Schedule+OT]) as [Schedule+OT],sum([Unplanned Lost Hrs]) as [Unplanned Lost Hrs],\n",
    "sum([Planned Lost Hrs]) as [Planned Lost Hrs],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs])/sum([Schedule+OT]) end as [Unplanned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Planned Lost Hrs])/sum([Schedule+OT]) end as [Planned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Overall AR %],\n",
    "1-case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Attendance %]\n",
    "from ATD\n",
    "group by [Date],[LOB]\n",
    "\"\"\"\n",
    " \n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "atd_pivot2_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "atd_pivot2_df=atd_pivot2_df.with_columns(pl.col(\"Date\").dt.to_string(\"%Y-%m-%d\"))\n",
    "atd_pivot2_df=atd_pivot2_df.to_pandas()\n",
    "atd_pivot2_df['Unplanned AR%'] = atd_pivot2_df['Unplanned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot2_df['Planned AR%'] = atd_pivot2_df['Planned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot2_df['Overall AR %'] = atd_pivot2_df['Overall AR %'].map('{:.2%}'.format)\n",
    "atd_pivot2_df['Attendance %'] = atd_pivot2_df['Attendance %'].map('{:.2%}'.format)\n",
    "atd_pivot2_df['OT'] = atd_pivot2_df['OT'].fillna(0)\n",
    "atd_pivot2_df['OT'] = atd_pivot2_df['OT'].astype(\"int64\")\n",
    "atd_pivot2_df['Schedule+OT'] = atd_pivot2_df['Schedule+OT'].fillna(0)\n",
    "atd_pivot2_df['Schedule+OT'] = atd_pivot2_df['Schedule+OT'].astype(\"int64\")\n",
    "\n",
    "atd_pivot2_df=pl.from_pandas(atd_pivot2_df)\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_pivot2_CSV = atd_pivot2_df.write_excel(workbook=\"BKN_ATD_pivot_2.xlsx\",worksheet=\"Sheet1\",\n",
    "                                           table_name='Table1', table_style='Table Style Medium 2',autofit=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aad78067-afb7-46fc-a7e6-27f10aa56989",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ATD Mail PIVOT 3 BY TL (Dillip team)\n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    "with ATD as (\n",
    "SELECT [Date],[LOB],[TL_Name],[Emp ID],[Emp_Name] AS [Name],[week_shift],[Original_Shift] as [Shift],\n",
    "cast([CUICLoggedTime(s)] as float)/3600 as [CUIC Hrs],\n",
    "CASE WHEN [ScheduleHours(H)]>4 and [CUICLoggedTime(s)]>0 then 1 \n",
    "when [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]>0 then 0.5 else 0 end as [ATD],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END AS [NormalShift],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 1 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [PlanLeave],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 1 WHEN [SchedUPL(H)]>0 THEN 0.5 ELSE 0 END AS [UnplanLeave],\n",
    "CASE WHEN [ScheduleHours(H)]>0 and [CUICLoggedTime(s)]<=0 then \n",
    "(CASE WHEN [ScheduleHours(H)]>4 THEN 1 WHEN [ScheduleHours(H)]>0 THEN 0.5 ELSE 0 END)\n",
    "else 0 end as [UPL-Not present at desk],\n",
    "CASE WHEN [Shift]='OFF' then 0 else 1 end as [Headcount],cast([OT_Registered(s)] as float)/3600 as [OT],[Ramco_Code] as [RAMCO],\n",
    "CASE WHEN [ScheduleHours(H)]>0 THEN 1 ELSE 0 END AS [Schedule Agents],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9 WHEN [ScheduleHours(H)]>0 THEN 4 ELSE 0 END AS [Schedule Hours],\n",
    "CASE WHEN [ScheduleHours(H)]>4 THEN 9+cast([OT_Registered(s)] as float)/3600 \n",
    "WHEN [ScheduleHours(H)]>0 THEN 4+cast([OT_Registered(s)] as float)/3600 ELSE 0 END AS [Schedule+OT],\n",
    "CASE WHEN [SchedUPL(H)]>4 THEN 9 WHEN [SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Unplanned Lost Hrs],\n",
    "CASE WHEN [SchedLeave(H)]-[SchedUPL(H)]>4 THEN 9 WHEN [SchedLeave(H)]-[SchedUPL(H)]>0 THEN 4 ELSE 0 END AS [Planned Lost Hrs]\n",
    "FROM BCOM.EEAAO\n",
    "where [Date]=DATEADD(DAY, 0,CAST(GETDATE() As Date)))\n",
    "select [Date],[TL_Name],sum([Schedule Agents]) as [Schedule Agents],sum([Schedule Hours]) as [Schedule Hours],\n",
    "sum([OT]) as [OT],sum([Schedule+OT]) as [Schedule+OT],sum([Unplanned Lost Hrs]) as [Unplanned Lost Hrs],\n",
    "sum([Planned Lost Hrs]) as [Planned Lost Hrs],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs])/sum([Schedule+OT]) end as [Unplanned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Planned Lost Hrs])/sum([Schedule+OT]) end as [Planned AR%],\n",
    "case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Overall AR %],\n",
    "1-case when sum([Schedule+OT])=0 then 0 else sum([Unplanned Lost Hrs]+[Planned Lost Hrs])/sum([Schedule+OT]) end as [Attendance %]\n",
    "from ATD\n",
    "group by [Date],[TL_Name]\n",
    "\"\"\"\n",
    " \n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "atd_pivot3_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "atd_pivot3_df=atd_pivot3_df.with_columns(pl.col(\"Date\").dt.to_string(\"%Y-%m-%d\"))\n",
    "atd_pivot3_df=atd_pivot3_df.to_pandas()\n",
    "atd_pivot3_df['Unplanned AR%'] = atd_pivot3_df['Unplanned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot3_df['Planned AR%'] = atd_pivot3_df['Planned AR%'].map('{:.2%}'.format)\n",
    "atd_pivot3_df['Overall AR %'] = atd_pivot3_df['Overall AR %'].map('{:.2%}'.format)\n",
    "atd_pivot3_df['Attendance %'] = atd_pivot3_df['Attendance %'].map('{:.2%}'.format)\n",
    "atd_pivot3_df['OT'] = atd_pivot3_df['OT'].fillna(0)\n",
    "atd_pivot3_df['OT'] = atd_pivot3_df['OT'].astype(\"int64\")\n",
    "atd_pivot3_df['Schedule+OT'] = atd_pivot3_df['Schedule+OT'].fillna(0)\n",
    "atd_pivot3_df['Schedule+OT'] = atd_pivot3_df['Schedule+OT'].astype(\"int64\")\n",
    "\n",
    "atd_pivot3_df=pl.from_pandas(atd_pivot3_df)\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atd_pivot3_CSV = atd_pivot3_df.write_excel(workbook=\"BKN_ATD_pivot_3.xlsx\",worksheet=\"Sheet1\",\n",
    "                                           table_name='Table1', table_style='Table Style Medium 2',autofit=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16050cfd-3c4e-45bf-8753-ccb82dd3b4ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ATTRITION\n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    "SET DATEFIRST 1;\n",
    "WITH\n",
    "ROSTER_RAW AS ( --IMPORT BCOM.ROSTER\n",
    "\n",
    "SELECT [Emp ID], [Attribute], [Value], [LOB], [team_leader], [week_shift], [week_off], [OM], [DPE] FROM BCOM.ROSTER \n",
    "\n",
    "),\n",
    "\n",
    "Staff_RAW AS ( --IMPORT BCOM.Staff\n",
    "\n",
    "SELECT [Employee_ID], [Wave #], [Role], [Booking Login ID], [Language Start Date], [TED Name], [CUIC Name], [EnterpriseName], [Hire_Date], [PST_Start_Date], [Production_Start_Date], [Designation], [cnx_email], [Booking Email], [Full name], [IEX], [serial_number], [BKN_ID], [Extension Number] FROM BCOM.Staff \n",
    "\n",
    "),\n",
    "\n",
    "RAMCO_RAW AS ( --IMPORT GLB.RAMCO\n",
    "\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code], \n",
    "\n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define] \n",
    "\n",
    "FROM GLB.RAMCO \n",
    "\n",
    "),\n",
    "\n",
    "ROSTER_RAW2 AS ( --IMPORT BCOM.ROSTER 2\n",
    "\n",
    "SELECT\n",
    "\n",
    "\tROSTER_RAW.[Emp ID], ROSTER_RAW.[Attribute] AS [Date], \n",
    "\n",
    "\tROSTER_RAW.[Value] AS [Original_Shift], ROSTER_RAW.[LOB], ROSTER_RAW.[team_leader], ROSTER_RAW.[week_shift], \n",
    "\n",
    "\tROSTER_RAW.[week_off], ROSTER_RAW.[OM], ROSTER_RAW.[DPE],\n",
    "\n",
    "\tCASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END AS [Shift],\n",
    "\n",
    "\tCASE \n",
    "\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('OFF', 'AL', 'CO', 'HO', 'UPL', 'VGH') THEN 'OFF'\n",
    "\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('Training', 'PEGA') THEN 'Training'\n",
    "\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\n",
    "\t\t\tELSE Null END AS [Shift_type]\n",
    "\n",
    "FROM ROSTER_RAW\n",
    "\n",
    "LEFT JOIN RAMCO_RAW ON ROSTER_RAW.[Emp ID] = RAMCO_RAW.[EID] AND ROSTER_RAW.[Attribute] = RAMCO_RAW.[Date] \n",
    "\n",
    "),\n",
    "\n",
    "TRANSFER_RAW AS ( --IMPORT BCOM.LTTransfers\n",
    "\n",
    "SELECT [EID], [LWD], [Remarks] \n",
    "\n",
    "FROM BCOM.LTTransfers\n",
    "\n",
    "),\n",
    "\n",
    "TERMINATION_RAW AS ( --IMPORT GLB.Termination\n",
    "\n",
    "SELECT [EMPLOYEE_ID], [LWD], [Termination Reason] \n",
    "\n",
    "FROM GLB.Termination \n",
    "\n",
    "WHERE [Client Name ( Process )] = 'Bookingcom' And [JOB_ROLE] = 'Agent' And [COUNTRY] = 'Vietnam'\n",
    "\n",
    "),\n",
    "\n",
    "RESIGNATION_RAW AS ( --IMPORT GLB.Resignation 1 (RAW)\n",
    "\n",
    "SELECT [Employee ID], [Proposed Termination Date], [Resignation Primary Reason] \n",
    "\n",
    "FROM GLB.Resignation \n",
    "\n",
    "WHERE [MSA Client] = 'Bookingcom' And [Job Family] = 'Contact Center' And [Country] = 'Vietnam'\n",
    "\n",
    "),\n",
    "\n",
    "--IMPORT TL,OM,DPE\n",
    "\n",
    "TL_RAW AS (SELECT [Employee_ID],[TED Name] AS [TL_Name] FROM BCOM.Staff),\n",
    "\n",
    "OM_RAW AS (SELECT [Employee_ID],[TED Name] AS [OM_Name] FROM BCOM.Staff),\n",
    "\n",
    "DPE_RAW AS (SELECT [Employee_ID],[TED Name] AS [DPE_Name] FROM BCOM.Staff),\n",
    "\n",
    "ROSTER_RAW3 AS ( --IMPORT BCOM.ROSTER 3\n",
    "\n",
    "SELECT\n",
    "\n",
    "ROSTER_RAW2.[Shift], ROSTER_RAW2.[Shift_type], ROSTER_RAW2.[Original_Shift], ROSTER_RAW2.[LOB], ROSTER_RAW2.[week_shift], ROSTER_RAW2.[week_off], \n",
    "\n",
    "ROSTER_RAW2.[team_leader] AS [TL_ID], TL_RAW.[TL_Name], ROSTER_RAW2.[OM] AS [OM_ID], OM_RAW.[OM_Name], ROSTER_RAW2.[DPE] AS [DPE_ID], DPE_RAW.[DPE_Name],\n",
    "\n",
    "COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) AS [Emp ID], Staff_RAW.[Full name] AS [Emp_Name], \n",
    "\n",
    "Staff_RAW.[Wave #] AS [Wave], Staff_RAW.[Booking Login ID], Staff_RAW.[TED Name], Staff_RAW.[cnx_email], Staff_RAW.[Booking Email], Staff_RAW.[CUIC Name], Staff_RAW.[PST_Start_Date],\n",
    "\n",
    "COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]) AS [Date],\n",
    "\n",
    "CASE \n",
    "\n",
    "    WHEN DATEDIFF(day, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) >= 90 THEN 'TN'\n",
    "\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined' \n",
    "\n",
    "    ELSE 'NH' END AS [Tenure],\n",
    "\n",
    "CASE \n",
    "\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 30 THEN '00-30'\n",
    "\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 60 THEN '31-60'\n",
    "\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 90 THEN '61-90'\n",
    "\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 120 THEN '91-120'\n",
    "\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 120 THEN '120+'\n",
    "\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined'\n",
    "\n",
    "    ELSE 'Undefined' END AS [Tenure days],\n",
    "\n",
    "CASE \n",
    "\n",
    "\tWHEN FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00') < 3 AND MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 10\n",
    "\n",
    "\tTHEN CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]))+1, FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\n",
    "\tELSE CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])), FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\n",
    "\tEND AS [Week_num],\n",
    "\n",
    "CASE\n",
    "\n",
    "WHEN ROSTER_RAW2.[Shift] IN (\n",
    "\n",
    "'0000-0900','0100-1000','0200-1100','0300-1200','0400-1300','0500-1400','0600-1500','0700-1600','0800-1700','0900-1800','1000-1900','1100-2000',\n",
    "\n",
    "'1200-2100','1300-2200','1400-2300','1500-0000','1600-0100','1700-0200','1800-0300','1900-0400','2000-0500','2100-0600','2200-0700','2300-0800'\n",
    "\n",
    ",'HAL','Training','DOWNTIME','PEGA','New Hire Training'\n",
    "\n",
    ") THEN 'WORK'\n",
    "\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('AL', 'CO', 'VGH','HO') THEN 'Planned leave'\n",
    "\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('UPL') THEN 'Unplanned leave' ELSE NULL END AS [Shift_definition],\n",
    "\n",
    "YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [YEAR],\n",
    "\n",
    "MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [MONTH],\n",
    "\n",
    "DATENAME(weekday, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [Week_day],\n",
    "\n",
    "COALESCE(TRANSFER_RAW.[Remarks], TERMINATION_RAW.[Termination Reason], RESIGNATION_RAW.[Resignation Primary Reason]) AS [Termination/Transfer],\n",
    "\n",
    "CASE \n",
    "\n",
    "    WHEN ROSTER_RAW2.[LOB] IN ('NL', 'ID4', 'HE4', 'XT4', 'EL', 'TR', 'KO', 'IT', 'CS', 'HU', 'FR', 'ZH', 'RU', 'PL', 'PT', 'NO', 'DA', 'DE', 'RO') THEN 'Unbabel'\n",
    "\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'EN' THEN 'English'\n",
    "\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSP' THEN 'Vietnamese CSP'\n",
    "\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSG' THEN 'Vietnamese CSG'\n",
    "\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'Senior VICSP' THEN 'Senior VICSP'\n",
    "\n",
    "    ELSE 'Undefined' END AS [LOB Group],\n",
    "\n",
    "-- Set up ScheduleSeconds(s)\n",
    "\n",
    "CASE\n",
    "\n",
    "    WHEN CHARINDEX('-', ROSTER_RAW2.[Original_Shift]) = 5 OR ROSTER_RAW2.[Original_Shift] IN ('UPL', 'PEGA') THEN 9 * 3600\n",
    "\n",
    "    WHEN ROSTER_RAW2.[Original_Shift] IN ('HAL', 'HSL') THEN 4 * 3600\n",
    "\n",
    "    ELSE 0\n",
    "\n",
    "END AS [ScheduleSeconds(s)]\n",
    "\n",
    "FROM ROSTER_RAW2\n",
    "\n",
    "FULL JOIN TRANSFER_RAW ON ROSTER_RAW2.[Emp ID] = TRANSFER_RAW.[EID] And ROSTER_RAW2.[Date] = TRANSFER_RAW.[LWD]\n",
    "\n",
    "FULL JOIN TERMINATION_RAW ON ROSTER_RAW2.[Emp ID] = TERMINATION_RAW.[EMPLOYEE_ID] And ROSTER_RAW2.[Date] = TERMINATION_RAW.[LWD]\n",
    "\n",
    "FULL JOIN RESIGNATION_RAW ON ROSTER_RAW2.[Emp ID] = RESIGNATION_RAW.[Employee ID] And ROSTER_RAW2.[Date] = RESIGNATION_RAW.[Proposed Termination Date]\n",
    "\n",
    "LEFT JOIN TL_RAW ON ROSTER_RAW2.[team_leader] = TL_RAW.[Employee_ID]\n",
    "\n",
    "LEFT JOIN OM_RAW ON ROSTER_RAW2.[OM] = OM_RAW.[Employee_ID]\n",
    "\n",
    "LEFT JOIN DPE_RAW ON ROSTER_RAW2.[DPE] = DPE_RAW.[Employee_ID]\n",
    "\n",
    "LEFT JOIN Staff_RAW ON COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) = Staff_RAW.[Employee_ID])\n",
    ",\n",
    "EEAAO as (\n",
    "select [Date],[Emp ID],[Termination/Transfer],[TL_ID],[OM_ID],[DPE_ID]\n",
    "from ROSTER_RAW3),\n",
    "\n",
    "RankedData as (\n",
    "\tSELECT \n",
    "        [Attribute] AS [Date],[Emp ID],[team_leader],[OM],[DPE],ROW_NUMBER() OVER (PARTITION BY [Emp ID] ORDER BY [Attribute] DESC) AS rn\n",
    "    FROM \n",
    "        BCOM.ROSTER),\n",
    "SCHE as (\n",
    "\tSELECT [Date],[Emp ID],[team_leader],[OM],[DPE]\n",
    "\tFROM RankedData\n",
    "\tWHERE \n",
    "\t\trn = 1),\n",
    "\n",
    "MiniTer as (\n",
    "select [EMPLOYEE_ID],[SUPERVISOR_ID]\n",
    "from GLB.Termination\n",
    "where [COUNTRY]='Vietnam' and [Client Name ( Process )]='Bookingcom' ),\n",
    "\n",
    "EmpMaster as (\n",
    "select [EMPLOYEE_NUMBER],[SUPERVISOR_ID],[MANAGER_02_ID],[SUPERVISOR_FULL_NAME],[MANAGER_02_FULL_NAME]\n",
    "from GLB.EmpMaster\n",
    "where [MSA Client]='Bookingcom' and [Country]='Vietnam'),\n",
    "\n",
    "TER as (\n",
    "select MiniTer.[EMPLOYEE_ID], max(COALESCE(MiniTer.[SUPERVISOR_ID], SCHE.[team_leader], EmpMaster.[SUPERVISOR_ID])) As [TeamLead],\n",
    "max(COALESCE(EmpMaster.[SUPERVISOR_ID],SCHE.[OM])) As [OM], max(SCHE.[DPE]) as [DPE] from MiniTer\n",
    "left join SCHE on MiniTer.[SUPERVISOR_ID]=SCHE.[team_leader]\n",
    "left join EmpMaster on MiniTer.[SUPERVISOR_ID]=EmpMaster.[EMPLOYEE_NUMBER]\n",
    "group by MiniTer.[EMPLOYEE_ID]),\n",
    "\n",
    "MiniRESIGN as (\n",
    "select [Employee ID],[Sup ID]\n",
    "from GLB.Resignation\n",
    "where [MSA Client]='Bookingcom' and Country='Vietnam'),\n",
    "RESIGN as (\n",
    "select MiniRESIGN.[Employee ID], max(COALESCE(MiniRESIGN.[Sup ID], SCHE.[team_leader], EmpMaster.[SUPERVISOR_ID])) As [TeamLead],\n",
    "max(COALESCE(EmpMaster.[SUPERVISOR_ID],SCHE.[OM])) As [OM],max(SCHE.[DPE]) as [DPE]\n",
    "from MiniRESIGN\n",
    "left join SCHE on MiniRESIGN.[Sup ID]=SCHE.[team_leader]\n",
    "left join EmpMaster on MiniRESIGN.[Sup ID]=EmpMaster.[EMPLOYEE_NUMBER]\n",
    "group by MiniRESIGN.[Employee ID]),\n",
    "TERMINATE as (\n",
    "select EEAAO.[Emp ID],EEAAO.[Date],EEAAO.[Termination/Transfer],\n",
    "COALESCE( TER.[TeamLead],RESIGN.[TeamLead],EEAAO.[TL_ID],SCHE.[team_leader]) as [TEAMLEADER],\n",
    "COALESCE( TER.[OM],RESIGN.[OM],EEAAO.[OM_ID],SCHE.[OM]) as [OM],\n",
    "COALESCE( TER.[DPE],RESIGN.[DPE],EEAAO.[DPE_ID],SCHE.[DPE]) as [DPE]\n",
    " from EEAAO\n",
    "left join SCHE on EEAAO.[Emp ID]=SCHE.[Emp ID]\n",
    "left join TER on EEAAO.[Emp ID]=TER.[EMPLOYEE_ID]\n",
    "left join RESIGN on EEAAO.[Emp ID]=RESIGN.[Employee ID]),\n",
    "MR_Emp as (\n",
    "select [Employee_ID],[TED Name] as [Agents Name] from BCOM.Staff\n",
    "),\n",
    "MR_TL as (\n",
    "select [Employee_ID],[TED Name] as [TL Name] from BCOM.Staff\n",
    "),\n",
    "MR_OM as (\n",
    "select [Employee_ID],[TED Name] as [OM Name] from BCOM.Staff\n",
    "),\n",
    "MR_DPE as (\n",
    "select [Employee_ID],[TED Name] as [DPE Name] from BCOM.Staff\n",
    ")\n",
    ",\n",
    "Attrition as (\n",
    "select TERMINATE.[Emp ID],TERMINATE.[Date],TERMINATE.[Termination/Transfer],MR_Emp.[Agents Name],TERMINATE.[TEAMLEADER],MR_TL.[TL Name],\n",
    "TERMINATE.[OM],MR_OM.[OM Name],TERMINATE.[DPE],MR_DPE.[DPE Name],\n",
    "DATEADD(day, 1 - DATEPART(weekday, TERMINATE.[Date]), TERMINATE.[Date]) AS [Week 2]\n",
    "from TERMINATE\n",
    "left join MR_Emp on TERMINATE.[Emp ID]=MR_Emp.[Employee_ID]\n",
    "left join MR_TL on TERMINATE.[TEAMLEADER]=MR_TL.[Employee_ID]\n",
    "left join MR_OM on TERMINATE.[OM]=MR_OM.[Employee_ID]\n",
    "left join MR_DPE on TERMINATE.[DPE]=MR_DPE.[Employee_ID]\n",
    "where TERMINATE.[Date]>=DATEADD(DAY, -730,CAST(GETDATE() As Date)) and (left(TERMINATE.[Termination/Transfer],7) <> 'Lateral' or TERMINATE.[Termination/Transfer] is null) )\n",
    "select * from Attrition\n",
    "\"\"\"\n",
    "\n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "\n",
    "attrition_df = pl.read_database(query=sql_query, connection=engine)\n",
    "\n",
    "engine.dispose()\n",
    "\n",
    "# Export to CSV\n",
    "\n",
    "os.chdir(DF_ATTRITION)\n",
    "\n",
    "attrition_df_CSV = attrition_df.write_csv(\"BKN_ATTRITION.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e471024-c556-4bbe-a56a-4c8d8c8420dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]ATD MM Detail linkðŸŽ¡\n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    "WITH\n",
    "-- Create GLB.OT_RAMCO 1 (RAW)\n",
    "OTRAMCO_RAW AS (  --Setup OTRamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [OT_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] in ('OT1.0X','OT1.5X','OT2.0X','OT2.1X','OT2.5X','OT2.7X') And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "PHRAMCO_RAW AS (  --Setup PHRamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [PH_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] in ('OT3.0X','OT3.9X','OT4.0X') And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "NSARAMCO_RAW AS (  --Setup NSARamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [NSA_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] = 'NSA' And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "-- Create GLB.RAMCO 1 (RAW)\n",
    "RAMCO_RAW AS ( \n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define] \n",
    "FROM GLB.RAMCO \n",
    "),\n",
    "-- Create RAMCO Pre1 (RAW)\n",
    "RAMCO_RAW_Pre1 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre1], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre1] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create BCOM.RegisteredOT (RAW)\n",
    "RegisteredOT_RAW AS (\n",
    "SELECT [Date], [Emp ID], [OT]*3600 AS [OT_Registered(s)], [Type] AS [OT_Registered_Type] FROM BCOM.RegisteredOT\n",
    "),\n",
    "-- Create RAMCO Pre2 (RAW)\n",
    "RAMCO_RAW_Pre2 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre2], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre2] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre3 (RAW)\n",
    "RAMCO_RAW_Pre3 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre3], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre3] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre4 (RAW)\n",
    "RAMCO_RAW_Pre4 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre4], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre4] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre5 (RAW)\n",
    "RAMCO_RAW_Pre5 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre5], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre5] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre6 (RAW)\n",
    "RAMCO_RAW_Pre6 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre6], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre6] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create GLB.PremHdays 1 (RAW)\n",
    "PremHday_RAW AS ( SELECT [Date],[Holiday] FROM GLB.PremHdays \n",
    "),\n",
    "-- Create BCOM.ROSTER 1 (RAW)\n",
    "ROSTER_RAW AS ( SELECT [Emp ID], [Attribute], [Value], [LOB], [team_leader], [week_shift], [week_off], [OM], [DPE] FROM BCOM.ROSTER \n",
    "),\n",
    "-- Create ROSTER(n-1) 1 (RAW)\n",
    "ROSTER_Pre1_RAW AS ( SELECT [Emp ID], [Attribute] AS [Date-1], [Value], [LOB], [team_leader], [week_shift], [week_off], [OM], [DPE] FROM BCOM.ROSTER \n",
    "),\n",
    "-- Create BCOM.LTTransfers 1 (RAW)\n",
    "TRANSFER_RAW AS (      \n",
    "SELECT [EID], [LWD], [Remarks] \n",
    "FROM BCOM.LTTransfers\n",
    "),\n",
    "-- Create BCOM.ExceptionReq 1 (RAW)\n",
    "ExceptionReq_RAW AS (\n",
    "SELECT [Date (MM/DD/YYYY)] AS [Date], [Emp ID], SUM([Exception request (Minute)]*60) AS [Req_Second] FROM BCOM.ExceptionReq\n",
    "WHERE [OM] = 'Approve' \n",
    "GROUP BY [Date (MM/DD/YYYY)],[Emp ID] \n",
    "),\n",
    "-- Create GLB.Termination 1 (RAW)\n",
    "TERMINATION_RAW AS (   \n",
    "SELECT [EMPLOYEE_ID], [LWD], [Termination Reason] \n",
    "FROM GLB.Termination \n",
    "WHERE [Client Name ( Process )] = 'Bookingcom' And [JOB_ROLE] = 'Agent' And [COUNTRY] = 'Vietnam'\n",
    "),\n",
    "-- Create GLB.Resignation 1 (RAW)\n",
    "RESIGNATION_RAW AS (   \n",
    "SELECT [Employee ID], [Proposed Termination Date], [Resignation Primary Reason] \n",
    "FROM GLB.Resignation \n",
    "WHERE [MSA Client] = 'Bookingcom' And [Job Family] = 'Contact Center' And [Country] = 'Vietnam'\n",
    "),\n",
    "-- Create BCOM.EPS 1 (RAW)\n",
    "EPS_RAW AS ( \n",
    "SELECT [Username], [Session Login], [Session Logout], [Session Time], [BPE Code], [Total Time], [SessionLogin_VN], CAST([SessionLogin_VN] AS DATE) AS [Date_Login_VN], DATEADD(DAY, -1, CAST([SessionLogin_VN] AS DATE)) AS [PreviousDate_Login_VN], CAST([SessionLogin_VN] AS TIME) AS [Time_Login_VN], [SessionLogout_VN], CAST([SessionLogout_VN] AS DATE) AS [Date_Logout_VN], CAST([SessionLogout_VN] AS TIME) AS [Time_Logout_VN], [NightTime], [DayTime], [Night_BPE], [Day_BPE] FROM BCOM.EPS \n",
    "),\n",
    "-- Create BCOM.Staff 1 (RAW)\n",
    "Staff_RAW AS ( \n",
    "SELECT [Employee_ID], [Wave #], [Role], [Booking Login ID], [Language Start Date], [TED Name], [CUIC Name], [EnterpriseName], [Hire_Date], [PST_Start_Date], [Production_Start_Date], [Designation], [cnx_email], [Booking Email], [Full name], [IEX], [serial_number], [BKN_ID], [Extension Number] FROM BCOM.Staff \n",
    "),\n",
    "-- Create TL,OM,DPE 1 (RAW)\n",
    "TL_RAW AS (SELECT [Employee_ID],[TED Name] AS [TL_Name] FROM BCOM.Staff),\n",
    "OM_RAW AS (SELECT [Employee_ID],[TED Name] AS [OM_Name] FROM BCOM.Staff),\n",
    "DPE_RAW AS (SELECT [Employee_ID],[TED Name] AS [DPE_Name] FROM BCOM.Staff),\n",
    "-- Create BCOM.CPI_PEGA 1 (RAW)\n",
    "CPI_PEGA_RAW AS ( \n",
    "SELECT \n",
    "[Staff Name], [Operator Def], [Service Case Type New], [Channel Def], [Lang Def], [Reason For No Service Case], \n",
    "[Topic Def New], [Subtopics], [Case Id], [Reservation Id Def], [Day of Date] AS [Date], [# Swivels], [Count of ServiceCase or Interaction],\n",
    "CASE \n",
    "WHEN [# Swivels] > 0 THEN 'PEGA Swiveled to TED'\n",
    "ELSE 'PEGA' END AS [CRM]\n",
    "FROM BCOM.CPI_PEGA \n",
    "WHERE [Count of ServiceCase or Interaction] > 0\n",
    "),\n",
    "-- Create BCOM.CPI 1 (RAW)\n",
    "CPI_RAW AS ( \n",
    "SELECT \n",
    "BCOM.CPI.[Date], BCOM.CPI.[Staff Name], BCOM.CPI.[Hour Interval Selected], \n",
    "BCOM.CPI.[Channel], BCOM.CPI.[Item Label], BCOM.CPI.[Item ID], BCOM.CPI.['Item ID'], BCOM.CPI.[Time Alert], \n",
    "BCOM.CPI.[Nr. Contacts], 'TED' AS [CRM]\n",
    "FROM BCOM.CPI \n",
    "LEFT JOIN CPI_PEGA_RAW ON CPI_PEGA_RAW.[Staff Name] = BCOM.CPI.[Staff Name] AND CPI_PEGA_RAW.[Date] = BCOM.CPI.[Date] AND CPI_PEGA_RAW.[Reservation Id Def] = BCOM.CPI.[Item ID]\n",
    "WHERE CPI_PEGA_RAW.[Reservation Id Def] IS NULL\n",
    "),\n",
    "-- Create BCOM.LogoutCount 1 (RAW)\n",
    "LogoutCount_RAW AS (\n",
    "SELECT [Aggregation] AS [TED_Name], [TimeDimension] AS [Date], SUM([KPI Value Formatted]) AS [Logout_Count] FROM BCOM.LogoutCount GROUP BY [Aggregation], [TimeDimension]\n",
    "),\n",
    "-- Create BCOM.PSAT 1 (RAW)\n",
    "PSAT_RAW AS (\n",
    "SELECT \n",
    "[Sorted By Dimension] AS [Date], Staff_RAW.[Employee_ID], [Staff Name] AS [Staff], '' AS [Team], [Survey Id], [Hotel Id] AS [Reservation], [Channel], \n",
    "[Agent understood my question], [Agent did everything possible to help me], [Final Topics] AS [Topic of the first Ticket], [Language], 'PSAT' AS [CSAT/PSAT]\n",
    "From BCOM.PSAT\n",
    "LEFT JOIN Staff_RAW ON [Staff Name] = Staff_RAW.[TED Name]\n",
    "),\n",
    "-- Create BCOM.ROSTER 2 (Add: Shift)\n",
    "ROSTER_RAW2 AS (\n",
    "SELECT\n",
    "\tROSTER_RAW.[Emp ID], ROSTER_RAW.[Attribute] AS [Date], \n",
    "\tROSTER_RAW.[Value] AS [Original_Shift], ROSTER_RAW.[LOB], ROSTER_RAW.[team_leader], ROSTER_RAW.[week_shift], \n",
    "\tROSTER_RAW.[week_off], ROSTER_RAW.[OM], ROSTER_RAW.[DPE],\n",
    "\tCASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END AS [Shift],\n",
    "\tCASE \n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('OFF', 'AL', 'CO', 'HO', 'UPL', 'VGH') THEN 'OFF'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('Training', 'PEGA') THEN 'Training'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tELSE Null END AS [Shift_type]\n",
    "FROM ROSTER_RAW\n",
    "LEFT JOIN RAMCO_RAW ON ROSTER_RAW.[Emp ID] = RAMCO_RAW.[EID] AND ROSTER_RAW.[Attribute] = RAMCO_RAW.[Date] \n",
    "),\n",
    "-- Create ROSTER_Pre1_RAW 2 (Add: Shift_type)\n",
    "ROSTER_Pre1_RAW2 AS (\n",
    "SELECT\n",
    "\tROSTER_Pre1_RAW.[Emp ID], ROSTER_Pre1_RAW.[Date-1], \n",
    "\tROSTER_Pre1_RAW.[Value] AS [Original_Shift], ROSTER_Pre1_RAW.[LOB], ROSTER_Pre1_RAW.[team_leader], ROSTER_Pre1_RAW.[week_shift], \n",
    "\tROSTER_Pre1_RAW.[week_off], ROSTER_Pre1_RAW.[OM], ROSTER_Pre1_RAW.[DPE],\n",
    "\tCASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END AS [Shift],\n",
    "\tCASE \n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('OFF', 'AL', 'CO', 'HO', 'UPL', 'VGH') THEN 'OFF'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('Training', 'PEGA') THEN 'Training'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tWHEN ROSTER_Pre1_RAW.[week_shift] IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN ROSTER_Pre1_RAW.[week_shift] IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tELSE Null END AS [Shift_type]\n",
    "FROM ROSTER_Pre1_RAW\n",
    "LEFT JOIN RAMCO_RAW ON ROSTER_Pre1_RAW.[Emp ID] = RAMCO_RAW.[EID] AND ROSTER_Pre1_RAW.[Date-1] = RAMCO_RAW.[Date] \n",
    "),\n",
    "-- Create BCOM.ROSTER 3 (Add: [Termination/Transfer])\n",
    "ROSTER_RAW3 AS (\n",
    "SELECT\n",
    "ROSTER_RAW2.[Shift], ROSTER_RAW2.[Shift_type], ROSTER_RAW2.[Original_Shift], ROSTER_RAW2.[LOB], ROSTER_RAW2.[week_shift], ROSTER_RAW2.[week_off], \n",
    "ROSTER_RAW2.[team_leader] AS [TL_ID], TL_RAW.[TL_Name], ROSTER_RAW2.[OM] AS [OM_ID], OM_RAW.[OM_Name], ROSTER_RAW2.[DPE] AS [DPE_ID], DPE_RAW.[DPE_Name],\n",
    "COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) AS [Emp ID], Staff_RAW.[Full name] AS [Emp_Name], \n",
    "Staff_RAW.[Wave #] AS [Wave], Staff_RAW.[Booking Login ID], Staff_RAW.[TED Name], Staff_RAW.[cnx_email], Staff_RAW.[Booking Email], Staff_RAW.[CUIC Name], Staff_RAW.[PST_Start_Date],\n",
    "COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]) AS [Date],\n",
    "CASE \n",
    "    WHEN DATEDIFF(day, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) >= 90 THEN 'TN'\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined' \n",
    "    ELSE 'NH' END AS [Tenure],\n",
    "CASE \n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 30 THEN '00-30'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 60 THEN '31-60'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 90 THEN '61-90'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 120 THEN '91-120'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 120 THEN '120+'\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined'\n",
    "    ELSE 'Undefined' END AS [Tenure days],\n",
    "CASE \n",
    "\tWHEN FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00') < 3 AND MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 10\n",
    "\tTHEN CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]))+1, FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\tELSE CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])), FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\tEND AS [Week_num],\n",
    "CASE\n",
    "WHEN ROSTER_RAW2.[Shift] IN (\n",
    "'0000-0900','0100-1000','0200-1100','0300-1200','0400-1300','0500-1400','0600-1500','0700-1600','0800-1700','0900-1800','1000-1900','1100-2000',\n",
    "'1200-2100','1300-2200','1400-2300','1500-0000','1600-0100','1700-0200','1800-0300','1900-0400','2000-0500','2100-0600','2200-0700','2300-0800'\n",
    ",'HAL','Training','DOWNTIME','PEGA','New Hire Training'\n",
    ") THEN 'WORK'\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('AL', 'CO', 'VGH','HO') THEN 'Planned leave'\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('UPL') THEN 'Unplanned leave' \n",
    "WHEN ROSTER_RAW2.[Shift] IN ('OFF') THEN 'OFF' ELSE NULL END AS [Shift_definition],\n",
    "YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [YEAR],\n",
    "MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [MONTH],\n",
    "DATENAME(weekday, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [Week_day],\n",
    "COALESCE(TRANSFER_RAW.[Remarks], TERMINATION_RAW.[Termination Reason], RESIGNATION_RAW.[Resignation Primary Reason]) AS [Termination/Transfer],\n",
    "CASE \n",
    "    WHEN ROSTER_RAW2.[LOB] IN ('NL', 'ID4', 'HE4', 'XT4', 'EL', 'TR', 'KO', 'IT', 'CS', 'HU', 'FR', 'ZH', 'RU', 'PL', 'PT', 'NO', 'DA', 'DE', 'RO') THEN 'Unbabel'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'EN' THEN 'English'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSP' THEN 'Vietnamese CSP'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSG' THEN 'Vietnamese CSG'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'Senior VICSP' THEN 'Senior VICSP'\n",
    "    ELSE 'Undefined' END AS [LOB Group],\n",
    "-- Set up ScheduleSeconds(s)\n",
    "CASE\n",
    "    WHEN CHARINDEX('-', ROSTER_RAW2.[Original_Shift]) = 5 OR ROSTER_RAW2.[Original_Shift] IN ('UPL', 'PEGA') THEN 9 * 3600\n",
    "    WHEN ROSTER_RAW2.[Original_Shift] IN ('HAL', 'HSL') THEN 4 * 3600\n",
    "    ELSE 0\n",
    "END AS [ScheduleSeconds(s)]\n",
    "FROM ROSTER_RAW2\n",
    "FULL JOIN TRANSFER_RAW ON ROSTER_RAW2.[Emp ID] = TRANSFER_RAW.[EID] And ROSTER_RAW2.[Date] = TRANSFER_RAW.[LWD]\n",
    "FULL JOIN TERMINATION_RAW ON ROSTER_RAW2.[Emp ID] = TERMINATION_RAW.[EMPLOYEE_ID] And ROSTER_RAW2.[Date] = TERMINATION_RAW.[LWD]\n",
    "FULL JOIN RESIGNATION_RAW ON ROSTER_RAW2.[Emp ID] = RESIGNATION_RAW.[Employee ID] And ROSTER_RAW2.[Date] = RESIGNATION_RAW.[Proposed Termination Date]\n",
    "LEFT JOIN TL_RAW ON ROSTER_RAW2.[team_leader] = TL_RAW.[Employee_ID]\n",
    "LEFT JOIN OM_RAW ON ROSTER_RAW2.[OM] = OM_RAW.[Employee_ID]\n",
    "LEFT JOIN DPE_RAW ON ROSTER_RAW2.[DPE] = DPE_RAW.[Employee_ID]\n",
    "LEFT JOIN Staff_RAW ON COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) = Staff_RAW.[Employee_ID]\n",
    "),\n",
    "-- Create BCOM.EPS 2 (Add: Shift)\n",
    "EPS_RAW2 AS ( \n",
    "SELECT \n",
    "ROSTER_RAW2.[Shift], ROSTER_RAW2.[Shift_type], Staff_RAW.[Employee_ID], EPS_RAW.[Username], EPS_RAW.[Session Login], EPS_RAW.[Session Logout], EPS_RAW.[Session Time], EPS_RAW.[BPE Code], EPS_RAW.[Total Time], EPS_RAW.[SessionLogin_VN], EPS_RAW.[Date_Login_VN], \n",
    "EPS_RAW.[PreviousDate_Login_VN], EPS_RAW.[Time_Login_VN], EPS_RAW.[SessionLogout_VN], EPS_RAW.[Date_Logout_VN], EPS_RAW.[Time_Logout_VN], EPS_RAW.[NightTime], EPS_RAW.[DayTime], EPS_RAW.[Night_BPE], EPS_RAW.[Day_BPE] \n",
    "FROM EPS_RAW\n",
    "LEFT JOIN Staff_RAW ON EPS_RAW.[Username] = Staff_RAW.[Booking Login ID] \n",
    "LEFT JOIN ROSTER_RAW2 ON Staff_RAW.[Employee_ID] = ROSTER_RAW2.[Emp ID] And EPS_RAW.[Date_Login_VN] = ROSTER_RAW2.[Date] ),\n",
    "-- Create BCOM.EPS 3 (Add: Final Date)\n",
    "EPS_RAW3 AS (\n",
    "SELECT\n",
    "EPS_RAW2.[Shift], EPS_RAW2.[Shift_type], ROSTER_RAW2.[Shift] AS [Shift-1], ROSTER_RAW2.[Shift_type] AS [Shifttype-1], \n",
    "CASE \n",
    "WHEN (EPS_RAW2.[Shift_type] IS NULL OR EPS_RAW2.[Shift_type] <> 'DS')\n",
    "AND ROSTER_RAW2.[Shift_type] = 'NS'\n",
    "AND EPS_RAW2.[Time_Login_VN] < '12:00:00'\n",
    "THEN EPS_RAW2.[PreviousDate_Login_VN] \n",
    "ELSE EPS_RAW2.[Date_Login_VN] END AS [Date],\n",
    "EPS_RAW2.[Employee_ID], EPS_RAW2.[Username], EPS_RAW2.[Session Login], EPS_RAW2.[Session Logout], EPS_RAW2.[Session Time], EPS_RAW2.[BPE Code], \n",
    "EPS_RAW2.[Total Time], EPS_RAW2.[SessionLogin_VN], EPS_RAW2.[Date_Login_VN], EPS_RAW2.[PreviousDate_Login_VN], EPS_RAW2.[Time_Login_VN], EPS_RAW2.[SessionLogout_VN], \n",
    "EPS_RAW2.[Date_Logout_VN], EPS_RAW2.[Time_Logout_VN], EPS_RAW2.[NightTime], EPS_RAW2.[DayTime], EPS_RAW2.[Night_BPE], EPS_RAW2.[Day_BPE] \n",
    "FROM EPS_RAW2\n",
    "LEFT JOIN ROSTER_RAW2 ON EPS_RAW2.[Employee_ID] = ROSTER_RAW2.[Emp ID] And EPS_RAW2.[PreviousDate_Login_VN] = ROSTER_RAW2.[Date]\n",
    "),\n",
    "-- Create BCOM.EPS 4 (Add: Data's Pivoted)\n",
    "EPS_RAW4 AS (\n",
    "SELECT \n",
    "EPS_RAW3.[Date], EPS_RAW3.[Employee_ID], \n",
    "/*Set up Login Logout*/\n",
    "MIN(EPS_RAW3.[SessionLogin_VN]) AS [Login], MAX(EPS_RAW3.[SessionLogout_VN]) AS [Logout],\n",
    "/*Set up StaffTime*/\n",
    "SUM(EPS_RAW3.[Total Time]) AS [StaffTime(s)], SUM(EPS_RAW3.[Night_BPE]) AS [Night_StaffTime(s)], SUM(EPS_RAW3.[Day_BPE]) AS [Day_StaffTime(s)],  \n",
    "/*Set up Break*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Total Time] else Null end) as [Break(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Break(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Break(s)],\n",
    "/*Set up Global Support*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Total Time] else Null end) as [Global_Support(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Global_Support(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Global_Support(s)],\n",
    "/*Set up Loaner*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Total Time] else Null end) as [Loaner(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Loaner(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Loaner(s)],\n",
    "/*Set up Lunch*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Total Time] else Null end) as [Lunch(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Lunch(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Lunch(s)],\n",
    "/*Set up Mass Issue*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Total Time] else Null end) as [Mass_Issue(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Mass_Issue(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Mass_Issue(s)],\n",
    "/*Set up Meeting*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Total Time] else Null end) as [Meeting(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Meeting(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Meeting(s)],\n",
    "/*Set up Moderation*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Total Time] else Null end) as [Moderation(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Moderation(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Moderation(s)],\n",
    "/*Set up New Hire Training*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Total Time] else Null end) as [New_Hire_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Night_BPE] else Null end) as [Night_New_Hire_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Day_BPE] else Null end) as [Day_New_Hire_Training(s)],\n",
    "/*Set up Not Working Yet*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Total Time] else Null end) as [Not_Working_Yet(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Not_Working_Yet(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Not_Working_Yet(s)],\n",
    "/*Set up Payment Processing*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Total Time] else Null end) as [Payment_Processing(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Payment_Processing(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Payment_Processing(s)],\n",
    "/*Set up Personal Time*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Total Time] else Null end) as [Personal_Time(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Personal_Time(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Personal_Time(s)],\n",
    "/*Set up Picklist - off Phone*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Total Time] else Null end) as [Picklist_off_Phone(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Picklist_off_Phone(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Picklist_off_Phone(s)],\n",
    "/*Set up Project*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Total Time] else Null end) as [Project(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Project(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Project(s)],\n",
    "/*Set up RONA*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Total Time] else Null end) as [RONA(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Night_BPE] else Null end) as [Night_RONA(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Day_BPE] else Null end) as [Day_RONA(s)],\n",
    "/*Set up Ready or Talking*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Total Time] else Null end) as [Ready_Talking(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Ready_Talking(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Ready_Talking(s)],\n",
    "/*Set up Special Task*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Total Time] else Null end) as [Special_Task(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Special_Task(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Special_Task(s)],\n",
    "/*Set up Technical Problems*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Total Time] else Null end) as [Technical_Problems(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Technical_Problems(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Technical_Problems(s)],\n",
    "/*Set up Training*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Total Time] else Null end) as [Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Training(s)],\n",
    "/*Set up Unscheduled Picklist*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Total Time] else Null end) as [Unscheduled_Picklist(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Unscheduled_Picklist(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Unscheduled_Picklist(s)],\n",
    "/*Set up Work Council*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Total Time] else Null end) as [Work_Council(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Work_Council(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Work_Council(s)]\n",
    "FROM EPS_RAW3 GROUP BY EPS_RAW3.[Date], EPS_RAW3.[Employee_ID]\n",
    ")\n",
    "select ROSTER_RAW3.[Emp ID],ROSTER_RAW3.[TED Name],ROSTER_RAW3.[TL_Name],ROSTER_RAW3.[OM_Name],ROSTER_RAW3.[Wave],\n",
    "ROSTER_RAW3.[Date],ROSTER_RAW3.[Shift],RAMCO_RAW.[Ramco_Code] as [RAMCO],\n",
    "Case\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'PO' AND ROSTER_RAW3.[Shift] = 'OFF' THEN 'Valid'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'PR' AND ROSTER_RAW3.[Shift] = 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HAL' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HLWP' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] IS NOT Null THEN Null  \n",
    "    When RAMCO_RAW.[Ramco_Code] IS NOT Null AND ROSTER_RAW3.[Shift] is Null THEN Null\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] is Null THEN 'Valid'\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'AB' AND ROSTER_RAW3.[Shift_definition] = 'WORK' THEN 'Valid'\n",
    "    When (Case When Roster_Raw3.[Shift_definition] = 'WORK' Then 'WORK'\n",
    "               When Roster_Raw3.[Shift_definition] is Null then Null Else 'OFF' End) = RAMCO_RAW.[Ramco_Define] THEN 'Valid'\n",
    "Else 'ATD MM' End As [ATD_Mismatch]\n",
    "from ROSTER_RAW3\n",
    "left join RAMCO_RAW on RAMCO_RAW.[EID]=ROSTER_RAW3.[Emp ID] and RAMCO_RAW.[Date]=ROSTER_RAW3.[Date]\n",
    "where ROSTER_RAW3.[Date]>=DATEADD(DAY, -30,CAST(GETDATE() As Date)) and ROSTER_RAW3.[Date]<=DATEADD(DAY, 0,CAST(GETDATE() As Date))\n",
    "\"\"\"\n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "atdmm_df = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(atd)\n",
    "atdmm_CSV = atdmm_df.write_excel(workbook=\"BKN_ATD_MM.xlsx\",worksheet=\"Sheet1\",table_name='Table1', autofit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "408fdba6-0283-4441-9919-6383b4352464",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#[BKN]ATD MM PIVOT to powwer automate captureðŸŽ¡\n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    "WITH\n",
    "-- Create GLB.OT_RAMCO 1 (RAW)\n",
    "OTRAMCO_RAW AS (  --Setup OTRamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [OT_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] in ('OT1.0X','OT1.5X','OT2.0X','OT2.1X','OT2.5X','OT2.7X') And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "PHRAMCO_RAW AS (  --Setup PHRamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [PH_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] in ('OT3.0X','OT3.9X','OT4.0X') And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "NSARAMCO_RAW AS (  --Setup NSARamco\n",
    "SELECT [Date], [employee_code] AS [EID], SUM([Hours]*3600) AS [NSA_Ramco(s)] \n",
    "FROM GLB.OT_RAMCO\n",
    "WHERE [OT Type] = 'NSA' And [Hours] > 0 And [Status] In ('Pending','Authorized')\n",
    "GROUP BY [Date], [employee_code]\n",
    "),\n",
    "-- Create GLB.RAMCO 1 (RAW)\n",
    "RAMCO_RAW AS ( \n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define] \n",
    "FROM GLB.RAMCO \n",
    "),\n",
    "-- Create RAMCO Pre1 (RAW)\n",
    "RAMCO_RAW_Pre1 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre1], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre1] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create BCOM.RegisteredOT (RAW)\n",
    "RegisteredOT_RAW AS (\n",
    "SELECT [Date], [Emp ID], [OT]*3600 AS [OT_Registered(s)], [Type] AS [OT_Registered_Type] FROM BCOM.RegisteredOT\n",
    "),\n",
    "-- Create RAMCO Pre2 (RAW)\n",
    "RAMCO_RAW_Pre2 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre2], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre2] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre3 (RAW)\n",
    "RAMCO_RAW_Pre3 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre3], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre3] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre4 (RAW)\n",
    "RAMCO_RAW_Pre4 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre4], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre4] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre5 (RAW)\n",
    "RAMCO_RAW_Pre5 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre5], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre5] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create RAMCO Pre6 (RAW)\n",
    "RAMCO_RAW_Pre6 As (\n",
    "SELECT [EID], [Date], [Code] AS [Ramco_Code_Pre6], \n",
    "CASE WHEN [Code] in ('PH','PO','PR','PI','POWH','HAL','HLWP','HSL') THEN 'WORK' WHEN [Code] IS NULL THEN NULL ELSE 'OFF' END AS [Ramco_Define_Pre6] \n",
    "FROM GLB.RAMCO\n",
    "),\n",
    "-- Create GLB.PremHdays 1 (RAW)\n",
    "PremHday_RAW AS ( SELECT [Date],[Holiday] FROM GLB.PremHdays \n",
    "),\n",
    "-- Create BCOM.ROSTER 1 (RAW)\n",
    "ROSTER_RAW AS ( SELECT [Emp ID], [Attribute], [Value], [LOB], [team_leader], [week_shift], [week_off], [OM], [DPE] FROM BCOM.ROSTER \n",
    "),\n",
    "-- Create ROSTER(n-1) 1 (RAW)\n",
    "ROSTER_Pre1_RAW AS ( SELECT [Emp ID], [Attribute] AS [Date-1], [Value], [LOB], [team_leader], [week_shift], [week_off], [OM], [DPE] FROM BCOM.ROSTER \n",
    "),\n",
    "-- Create BCOM.LTTransfers 1 (RAW)\n",
    "TRANSFER_RAW AS (      \n",
    "SELECT [EID], [LWD], [Remarks] \n",
    "FROM BCOM.LTTransfers\n",
    "),\n",
    "-- Create BCOM.ExceptionReq 1 (RAW)\n",
    "ExceptionReq_RAW AS (\n",
    "SELECT [Date (MM/DD/YYYY)] AS [Date], [Emp ID], SUM([Exception request (Minute)]*60) AS [Req_Second] FROM BCOM.ExceptionReq\n",
    "WHERE [OM] = 'Approve' \n",
    "GROUP BY [Date (MM/DD/YYYY)],[Emp ID] \n",
    "),\n",
    "-- Create GLB.Termination 1 (RAW)\n",
    "TERMINATION_RAW AS (   \n",
    "SELECT [EMPLOYEE_ID], [LWD], [Termination Reason] \n",
    "FROM GLB.Termination \n",
    "WHERE [Client Name ( Process )] = 'Bookingcom' And [JOB_ROLE] = 'Agent' And [COUNTRY] = 'Vietnam'\n",
    "),\n",
    "-- Create GLB.Resignation 1 (RAW)\n",
    "RESIGNATION_RAW AS (   \n",
    "SELECT [Employee ID], [Proposed Termination Date], [Resignation Primary Reason] \n",
    "FROM GLB.Resignation \n",
    "WHERE [MSA Client] = 'Bookingcom' And [Job Family] = 'Contact Center' And [Country] = 'Vietnam'\n",
    "),\n",
    "-- Create BCOM.EPS 1 (RAW)\n",
    "EPS_RAW AS ( \n",
    "SELECT [Username], [Session Login], [Session Logout], [Session Time], [BPE Code], [Total Time], [SessionLogin_VN], CAST([SessionLogin_VN] AS DATE) AS [Date_Login_VN], DATEADD(DAY, -1, CAST([SessionLogin_VN] AS DATE)) AS [PreviousDate_Login_VN], CAST([SessionLogin_VN] AS TIME) AS [Time_Login_VN], [SessionLogout_VN], CAST([SessionLogout_VN] AS DATE) AS [Date_Logout_VN], CAST([SessionLogout_VN] AS TIME) AS [Time_Logout_VN], [NightTime], [DayTime], [Night_BPE], [Day_BPE] FROM BCOM.EPS \n",
    "),\n",
    "-- Create BCOM.Staff 1 (RAW)\n",
    "Staff_RAW AS ( \n",
    "SELECT [Employee_ID], [Wave #], [Role], [Booking Login ID], [Language Start Date], [TED Name], [CUIC Name], [EnterpriseName], [Hire_Date], [PST_Start_Date], [Production_Start_Date], [Designation], [cnx_email], [Booking Email], [Full name], [IEX], [serial_number], [BKN_ID], [Extension Number] FROM BCOM.Staff \n",
    "),\n",
    "-- Create TL,OM,DPE 1 (RAW)\n",
    "TL_RAW AS (SELECT [Employee_ID],[TED Name] AS [TL_Name] FROM BCOM.Staff),\n",
    "OM_RAW AS (SELECT [Employee_ID],[TED Name] AS [OM_Name] FROM BCOM.Staff),\n",
    "DPE_RAW AS (SELECT [Employee_ID],[TED Name] AS [DPE_Name] FROM BCOM.Staff),\n",
    "-- Create BCOM.CPI_PEGA 1 (RAW)\n",
    "CPI_PEGA_RAW AS ( \n",
    "SELECT \n",
    "[Staff Name], [Operator Def], [Service Case Type New], [Channel Def], [Lang Def], [Reason For No Service Case], \n",
    "[Topic Def New], [Subtopics], [Case Id], [Reservation Id Def], [Day of Date] AS [Date], [# Swivels], [Count of ServiceCase or Interaction],\n",
    "CASE \n",
    "WHEN [# Swivels] > 0 THEN 'PEGA Swiveled to TED'\n",
    "ELSE 'PEGA' END AS [CRM]\n",
    "FROM BCOM.CPI_PEGA \n",
    "WHERE [Count of ServiceCase or Interaction] > 0\n",
    "),\n",
    "-- Create BCOM.CPI 1 (RAW)\n",
    "CPI_RAW AS ( \n",
    "SELECT \n",
    "BCOM.CPI.[Date], BCOM.CPI.[Staff Name], BCOM.CPI.[Hour Interval Selected], \n",
    "BCOM.CPI.[Channel], BCOM.CPI.[Item Label], BCOM.CPI.[Item ID], BCOM.CPI.['Item ID'], BCOM.CPI.[Time Alert], \n",
    "BCOM.CPI.[Nr. Contacts], 'TED' AS [CRM]\n",
    "FROM BCOM.CPI \n",
    "LEFT JOIN CPI_PEGA_RAW ON CPI_PEGA_RAW.[Staff Name] = BCOM.CPI.[Staff Name] AND CPI_PEGA_RAW.[Date] = BCOM.CPI.[Date] AND CPI_PEGA_RAW.[Reservation Id Def] = BCOM.CPI.[Item ID]\n",
    "WHERE CPI_PEGA_RAW.[Reservation Id Def] IS NULL\n",
    "),\n",
    "-- Create BCOM.LogoutCount 1 (RAW)\n",
    "LogoutCount_RAW AS (\n",
    "SELECT [Aggregation] AS [TED_Name], [TimeDimension] AS [Date], SUM([KPI Value Formatted]) AS [Logout_Count] FROM BCOM.LogoutCount GROUP BY [Aggregation], [TimeDimension]\n",
    "),\n",
    "-- Create BCOM.PSAT 1 (RAW)\n",
    "PSAT_RAW AS (\n",
    "SELECT \n",
    "[Sorted By Dimension] AS [Date], Staff_RAW.[Employee_ID], [Staff Name] AS [Staff], '' AS [Team], [Survey Id], [Hotel Id] AS [Reservation], [Channel], \n",
    "[Agent understood my question], [Agent did everything possible to help me], [Final Topics] AS [Topic of the first Ticket], [Language], 'PSAT' AS [CSAT/PSAT]\n",
    "From BCOM.PSAT\n",
    "LEFT JOIN Staff_RAW ON [Staff Name] = Staff_RAW.[TED Name]\n",
    "),\n",
    "-- Create BCOM.ROSTER 2 (Add: Shift)\n",
    "ROSTER_RAW2 AS (\n",
    "SELECT\n",
    "\tROSTER_RAW.[Emp ID], ROSTER_RAW.[Attribute] AS [Date], \n",
    "\tROSTER_RAW.[Value] AS [Original_Shift], ROSTER_RAW.[LOB], ROSTER_RAW.[team_leader], ROSTER_RAW.[week_shift], \n",
    "\tROSTER_RAW.[week_off], ROSTER_RAW.[OM], ROSTER_RAW.[DPE],\n",
    "\tCASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END AS [Shift],\n",
    "\tCASE \n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('OFF', 'AL', 'CO', 'HO', 'UPL', 'VGH') THEN 'OFF'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('Training', 'PEGA') THEN 'Training'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_RAW.[week_shift] ELSE ROSTER_RAW.[Value] END) IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN ROSTER_RAW.[week_shift] IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tELSE Null END AS [Shift_type]\n",
    "FROM ROSTER_RAW\n",
    "LEFT JOIN RAMCO_RAW ON ROSTER_RAW.[Emp ID] = RAMCO_RAW.[EID] AND ROSTER_RAW.[Attribute] = RAMCO_RAW.[Date] \n",
    "),\n",
    "-- Create ROSTER_Pre1_RAW 2 (Add: Shift_type)\n",
    "ROSTER_Pre1_RAW2 AS (\n",
    "SELECT\n",
    "\tROSTER_Pre1_RAW.[Emp ID], ROSTER_Pre1_RAW.[Date-1], \n",
    "\tROSTER_Pre1_RAW.[Value] AS [Original_Shift], ROSTER_Pre1_RAW.[LOB], ROSTER_Pre1_RAW.[team_leader], ROSTER_Pre1_RAW.[week_shift], \n",
    "\tROSTER_Pre1_RAW.[week_off], ROSTER_Pre1_RAW.[OM], ROSTER_Pre1_RAW.[DPE],\n",
    "\tCASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END AS [Shift],\n",
    "\tCASE \n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('OFF', 'AL', 'CO', 'HO', 'UPL', 'VGH') THEN 'OFF'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('Training', 'PEGA') THEN 'Training'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN (CASE WHEN RAMCO_RAW.[Ramco_Code] IN ('PH', 'PO') THEN ROSTER_Pre1_RAW.[week_shift] ELSE ROSTER_Pre1_RAW.[Value] END) IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tWHEN ROSTER_Pre1_RAW.[week_shift] IN ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300') THEN 'DS'\n",
    "\t\t\tWHEN ROSTER_Pre1_RAW.[week_shift] IN ('1500-0000', '1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800') THEN 'NS'\n",
    "\t\t\tELSE Null END AS [Shift_type]\n",
    "FROM ROSTER_Pre1_RAW\n",
    "LEFT JOIN RAMCO_RAW ON ROSTER_Pre1_RAW.[Emp ID] = RAMCO_RAW.[EID] AND ROSTER_Pre1_RAW.[Date-1] = RAMCO_RAW.[Date] \n",
    "),\n",
    "-- Create BCOM.ROSTER 3 (Add: [Termination/Transfer])\n",
    "ROSTER_RAW3 AS (\n",
    "SELECT\n",
    "ROSTER_RAW2.[Shift], ROSTER_RAW2.[Shift_type], ROSTER_RAW2.[Original_Shift], ROSTER_RAW2.[LOB], ROSTER_RAW2.[week_shift], ROSTER_RAW2.[week_off], \n",
    "ROSTER_RAW2.[team_leader] AS [TL_ID], TL_RAW.[TL_Name], ROSTER_RAW2.[OM] AS [OM_ID], OM_RAW.[OM_Name], ROSTER_RAW2.[DPE] AS [DPE_ID], DPE_RAW.[DPE_Name],\n",
    "COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) AS [Emp ID], Staff_RAW.[Full name] AS [Emp_Name], \n",
    "Staff_RAW.[Wave #] AS [Wave], Staff_RAW.[Booking Login ID], Staff_RAW.[TED Name], Staff_RAW.[cnx_email], Staff_RAW.[Booking Email], Staff_RAW.[CUIC Name], Staff_RAW.[PST_Start_Date],\n",
    "COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]) AS [Date],\n",
    "CASE \n",
    "    WHEN DATEDIFF(day, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) >= 90 THEN 'TN'\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined' \n",
    "    ELSE 'NH' END AS [Tenure],\n",
    "CASE \n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 30 THEN '00-30'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 60 THEN '31-60'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 90 THEN '61-90'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) <= 120 THEN '91-120'\n",
    "    WHEN DATEDIFF(DAY, Staff_RAW.[PST_Start_Date], COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 120 THEN '120+'\n",
    "    WHEN Staff_RAW.[PST_Start_Date] IS NULL THEN 'Undefined'\n",
    "    ELSE 'Undefined' END AS [Tenure days],\n",
    "CASE \n",
    "\tWHEN FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00') < 3 AND MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) > 10\n",
    "\tTHEN CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date]))+1, FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\tELSE CONCAT(YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])), FORMAT(DATEPART(ISO_WEEK, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])),'00'))\n",
    "\tEND AS [Week_num],\n",
    "CASE\n",
    "WHEN ROSTER_RAW2.[Shift] IN (\n",
    "'0000-0900','0100-1000','0200-1100','0300-1200','0400-1300','0500-1400','0600-1500','0700-1600','0800-1700','0900-1800','1000-1900','1100-2000',\n",
    "'1200-2100','1300-2200','1400-2300','1500-0000','1600-0100','1700-0200','1800-0300','1900-0400','2000-0500','2100-0600','2200-0700','2300-0800'\n",
    ",'HAL','Training','DOWNTIME','PEGA','New Hire Training'\n",
    ") THEN 'WORK'\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('AL', 'CO', 'VGH','HO') THEN 'Planned leave'\n",
    "WHEN ROSTER_RAW2.[Shift] IN ('UPL') THEN 'Unplanned leave' \n",
    "WHEN ROSTER_RAW2.[Shift] IN ('OFF') THEN 'OFF' ELSE NULL END AS [Shift_definition],\n",
    "YEAR(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [YEAR],\n",
    "MONTH(COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [MONTH],\n",
    "DATENAME(weekday, COALESCE(ROSTER_RAW2.[Date], TRANSFER_RAW.[LWD], TERMINATION_RAW.[LWD], RESIGNATION_RAW.[Proposed Termination Date])) AS [Week_day],\n",
    "COALESCE(TRANSFER_RAW.[Remarks], TERMINATION_RAW.[Termination Reason], RESIGNATION_RAW.[Resignation Primary Reason]) AS [Termination/Transfer],\n",
    "CASE \n",
    "    WHEN ROSTER_RAW2.[LOB] IN ('NL', 'ID4', 'HE4', 'XT4', 'EL', 'TR', 'KO', 'IT', 'CS', 'HU', 'FR', 'ZH', 'RU', 'PL', 'PT', 'NO', 'DA', 'DE', 'RO') THEN 'Unbabel'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'EN' THEN 'English'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSP' THEN 'Vietnamese CSP'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'VICSG' THEN 'Vietnamese CSG'\n",
    "    WHEN ROSTER_RAW2.[LOB] = 'Senior VICSP' THEN 'Senior VICSP'\n",
    "    ELSE 'Undefined' END AS [LOB Group],\n",
    "-- Set up ScheduleSeconds(s)\n",
    "CASE\n",
    "    WHEN CHARINDEX('-', ROSTER_RAW2.[Original_Shift]) = 5 OR ROSTER_RAW2.[Original_Shift] IN ('UPL', 'PEGA') THEN 9 * 3600\n",
    "    WHEN ROSTER_RAW2.[Original_Shift] IN ('HAL', 'HSL') THEN 4 * 3600\n",
    "    ELSE 0\n",
    "END AS [ScheduleSeconds(s)]\n",
    "FROM ROSTER_RAW2\n",
    "FULL JOIN TRANSFER_RAW ON ROSTER_RAW2.[Emp ID] = TRANSFER_RAW.[EID] And ROSTER_RAW2.[Date] = TRANSFER_RAW.[LWD]\n",
    "FULL JOIN TERMINATION_RAW ON ROSTER_RAW2.[Emp ID] = TERMINATION_RAW.[EMPLOYEE_ID] And ROSTER_RAW2.[Date] = TERMINATION_RAW.[LWD]\n",
    "FULL JOIN RESIGNATION_RAW ON ROSTER_RAW2.[Emp ID] = RESIGNATION_RAW.[Employee ID] And ROSTER_RAW2.[Date] = RESIGNATION_RAW.[Proposed Termination Date]\n",
    "LEFT JOIN TL_RAW ON ROSTER_RAW2.[team_leader] = TL_RAW.[Employee_ID]\n",
    "LEFT JOIN OM_RAW ON ROSTER_RAW2.[OM] = OM_RAW.[Employee_ID]\n",
    "LEFT JOIN DPE_RAW ON ROSTER_RAW2.[DPE] = DPE_RAW.[Employee_ID]\n",
    "LEFT JOIN Staff_RAW ON COALESCE(ROSTER_RAW2.[Emp ID], TRANSFER_RAW.[EID], TERMINATION_RAW.[EMPLOYEE_ID], RESIGNATION_RAW.[Employee ID]) = Staff_RAW.[Employee_ID]\n",
    "),\n",
    "-- Create BCOM.EPS 2 (Add: Shift)\n",
    "EPS_RAW2 AS ( \n",
    "SELECT \n",
    "ROSTER_RAW2.[Shift], ROSTER_RAW2.[Shift_type], Staff_RAW.[Employee_ID], EPS_RAW.[Username], EPS_RAW.[Session Login], EPS_RAW.[Session Logout], EPS_RAW.[Session Time], EPS_RAW.[BPE Code], EPS_RAW.[Total Time], EPS_RAW.[SessionLogin_VN], EPS_RAW.[Date_Login_VN], \n",
    "EPS_RAW.[PreviousDate_Login_VN], EPS_RAW.[Time_Login_VN], EPS_RAW.[SessionLogout_VN], EPS_RAW.[Date_Logout_VN], EPS_RAW.[Time_Logout_VN], EPS_RAW.[NightTime], EPS_RAW.[DayTime], EPS_RAW.[Night_BPE], EPS_RAW.[Day_BPE] \n",
    "FROM EPS_RAW\n",
    "LEFT JOIN Staff_RAW ON EPS_RAW.[Username] = Staff_RAW.[Booking Login ID] \n",
    "LEFT JOIN ROSTER_RAW2 ON Staff_RAW.[Employee_ID] = ROSTER_RAW2.[Emp ID] And EPS_RAW.[Date_Login_VN] = ROSTER_RAW2.[Date] ),\n",
    "-- Create BCOM.EPS 3 (Add: Final Date)\n",
    "EPS_RAW3 AS (\n",
    "SELECT\n",
    "EPS_RAW2.[Shift], EPS_RAW2.[Shift_type], ROSTER_RAW2.[Shift] AS [Shift-1], ROSTER_RAW2.[Shift_type] AS [Shifttype-1], \n",
    "CASE \n",
    "WHEN (EPS_RAW2.[Shift_type] IS NULL OR EPS_RAW2.[Shift_type] <> 'DS')\n",
    "AND ROSTER_RAW2.[Shift_type] = 'NS'\n",
    "AND EPS_RAW2.[Time_Login_VN] < '12:00:00'\n",
    "THEN EPS_RAW2.[PreviousDate_Login_VN] \n",
    "ELSE EPS_RAW2.[Date_Login_VN] END AS [Date],\n",
    "EPS_RAW2.[Employee_ID], EPS_RAW2.[Username], EPS_RAW2.[Session Login], EPS_RAW2.[Session Logout], EPS_RAW2.[Session Time], EPS_RAW2.[BPE Code], \n",
    "EPS_RAW2.[Total Time], EPS_RAW2.[SessionLogin_VN], EPS_RAW2.[Date_Login_VN], EPS_RAW2.[PreviousDate_Login_VN], EPS_RAW2.[Time_Login_VN], EPS_RAW2.[SessionLogout_VN], \n",
    "EPS_RAW2.[Date_Logout_VN], EPS_RAW2.[Time_Logout_VN], EPS_RAW2.[NightTime], EPS_RAW2.[DayTime], EPS_RAW2.[Night_BPE], EPS_RAW2.[Day_BPE] \n",
    "FROM EPS_RAW2\n",
    "LEFT JOIN ROSTER_RAW2 ON EPS_RAW2.[Employee_ID] = ROSTER_RAW2.[Emp ID] And EPS_RAW2.[PreviousDate_Login_VN] = ROSTER_RAW2.[Date]\n",
    "),\n",
    "-- Create BCOM.EPS 4 (Add: Data's Pivoted)\n",
    "EPS_RAW4 AS (\n",
    "SELECT \n",
    "EPS_RAW3.[Date], EPS_RAW3.[Employee_ID], \n",
    "/*Set up Login Logout*/\n",
    "MIN(EPS_RAW3.[SessionLogin_VN]) AS [Login], MAX(EPS_RAW3.[SessionLogout_VN]) AS [Logout],\n",
    "/*Set up StaffTime*/\n",
    "SUM(EPS_RAW3.[Total Time]) AS [StaffTime(s)], SUM(EPS_RAW3.[Night_BPE]) AS [Night_StaffTime(s)], SUM(EPS_RAW3.[Day_BPE]) AS [Day_StaffTime(s)],  \n",
    "/*Set up Break*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Total Time] else Null end) as [Break(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Break(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Break' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Break(s)],\n",
    "/*Set up Global Support*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Total Time] else Null end) as [Global_Support(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Global_Support(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Global Support' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Global_Support(s)],\n",
    "/*Set up Loaner*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Total Time] else Null end) as [Loaner(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Loaner(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Loaner' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Loaner(s)],\n",
    "/*Set up Lunch*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Total Time] else Null end) as [Lunch(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Lunch(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Lunch' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Lunch(s)],\n",
    "/*Set up Mass Issue*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Total Time] else Null end) as [Mass_Issue(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Mass_Issue(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Mass Issue' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Mass_Issue(s)],\n",
    "/*Set up Meeting*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Total Time] else Null end) as [Meeting(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Meeting(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Meeting' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Meeting(s)],\n",
    "/*Set up Moderation*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Total Time] else Null end) as [Moderation(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Moderation(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Moderation' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Moderation(s)],\n",
    "/*Set up New Hire Training*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Total Time] else Null end) as [New_Hire_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Night_BPE] else Null end) as [Night_New_Hire_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'New Hire Training' then EPS_RAW3.[Day_BPE] else Null end) as [Day_New_Hire_Training(s)],\n",
    "/*Set up Not Working Yet*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Total Time] else Null end) as [Not_Working_Yet(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Not_Working_Yet(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Not Working Yet' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Not_Working_Yet(s)],\n",
    "/*Set up Payment Processing*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Total Time] else Null end) as [Payment_Processing(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Payment_Processing(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Payment Processing' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Payment_Processing(s)],\n",
    "/*Set up Personal Time*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Total Time] else Null end) as [Personal_Time(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Personal_Time(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Personal Time' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Personal_Time(s)],\n",
    "/*Set up Picklist - off Phone*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Total Time] else Null end) as [Picklist_off_Phone(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Picklist_off_Phone(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Picklist - off Phone' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Picklist_off_Phone(s)],\n",
    "/*Set up Project*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Total Time] else Null end) as [Project(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Project(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Project' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Project(s)],\n",
    "/*Set up RONA*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Total Time] else Null end) as [RONA(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Night_BPE] else Null end) as [Night_RONA(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'RONA' then EPS_RAW3.[Day_BPE] else Null end) as [Day_RONA(s)],\n",
    "/*Set up Ready or Talking*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Total Time] else Null end) as [Ready_Talking(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Ready_Talking(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Ready or Talking' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Ready_Talking(s)],\n",
    "/*Set up Special Task*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Total Time] else Null end) as [Special_Task(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Special_Task(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Special Task' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Special_Task(s)],\n",
    "/*Set up Technical Problems*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Total Time] else Null end) as [Technical_Problems(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Technical_Problems(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Technical Problems' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Technical_Problems(s)],\n",
    "/*Set up Training*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Total Time] else Null end) as [Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Training(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Training' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Training(s)],\n",
    "/*Set up Unscheduled Picklist*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Total Time] else Null end) as [Unscheduled_Picklist(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Unscheduled_Picklist(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Unscheduled Picklist' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Unscheduled_Picklist(s)],\n",
    "/*Set up Work Council*/\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Total Time] else Null end) as [Work_Council(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Night_BPE] else Null end) as [Night_Work_Council(s)],\n",
    "SUM(Case When EPS_RAW3.[BPE Code] = 'Work Council' then EPS_RAW3.[Day_BPE] else Null end) as [Day_Work_Council(s)]\n",
    "FROM EPS_RAW3 GROUP BY EPS_RAW3.[Date], EPS_RAW3.[Employee_ID]\n",
    ")\n",
    "select ROSTER_RAW3.[OM_Name],ROSTER_RAW3.[TL_Name],\n",
    "count(Case\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'PO' AND ROSTER_RAW3.[Shift] = 'OFF' THEN 'Valid'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'PR' AND ROSTER_RAW3.[Shift] = 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HAL' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HLWP' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] IS NOT Null THEN Null  \n",
    "    When RAMCO_RAW.[Ramco_Code] IS NOT Null AND ROSTER_RAW3.[Shift] is Null THEN Null\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] is Null THEN 'Valid'\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'AB' AND ROSTER_RAW3.[Shift_definition] = 'WORK' THEN 'Valid'\n",
    "\twhen RAMCO_RAW.[Ramco_Code] ='WO' AND ROSTER_RAW3.[Shift_definition] = 'OFF' THEN 'Valid'\n",
    "    When (Case When Roster_Raw3.[Shift_definition] = 'WORK' Then 'WORK'\n",
    "               When Roster_Raw3.[Shift_definition] is Null then Null Else 'OFF' End) = RAMCO_RAW.[Ramco_Define] THEN 'Valid'\n",
    "Else 'ATD MM' End) As [MM Cases]\n",
    "from ROSTER_RAW3\n",
    "left join RAMCO_RAW on RAMCO_RAW.[EID]=ROSTER_RAW3.[Emp ID] and RAMCO_RAW.[Date]=ROSTER_RAW3.[Date]\n",
    "where ROSTER_RAW3.[Date]>=DATEADD(DAY, -30,CAST(GETDATE() As Date)) and ROSTER_RAW3.[Date]<=DATEADD(DAY, 0,CAST(GETDATE() As Date))\n",
    "and \n",
    "Case\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'PO' AND ROSTER_RAW3.[Shift] = 'OFF' THEN 'Valid'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'PR' AND ROSTER_RAW3.[Shift] = 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HAL' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HLWP' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] IS NOT Null THEN Null  \n",
    "    When RAMCO_RAW.[Ramco_Code] IS NOT Null AND ROSTER_RAW3.[Shift] is Null THEN Null\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] is Null THEN 'Valid'\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'AB' AND ROSTER_RAW3.[Shift_definition] = 'WORK' THEN 'Valid'\n",
    "\twhen RAMCO_RAW.[Ramco_Code] ='WO' AND ROSTER_RAW3.[Shift_definition] = 'OFF' THEN 'Valid'\n",
    "    When (Case When Roster_Raw3.[Shift_definition] = 'WORK' Then 'WORK'\n",
    "               When Roster_Raw3.[Shift_definition] is Null then Null Else 'OFF' End) = RAMCO_RAW.[Ramco_Define] THEN 'Valid'\n",
    "Else 'ATD MM' End = 'ATD MM'\n",
    "group by ROSTER_RAW3.[OM_Name],ROSTER_RAW3.[TL_Name]\n",
    "order by \n",
    "count(Case\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'PO' AND ROSTER_RAW3.[Shift] = 'OFF' THEN 'Valid'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'PR' AND ROSTER_RAW3.[Shift] = 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HAL' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "\tWhen RAMCO_RAW.[Ramco_Code] = 'HLWP' AND ROSTER_RAW3.[Shift] <> 'HAL' THEN 'ATD MM'\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] IS NOT Null THEN Null  \n",
    "    When RAMCO_RAW.[Ramco_Code] IS NOT Null AND ROSTER_RAW3.[Shift] is Null THEN Null\n",
    "    When RAMCO_RAW.[Ramco_Code] is Null AND ROSTER_RAW3.[Shift] is Null THEN 'Valid'\n",
    "    When RAMCO_RAW.[Ramco_Code] = 'AB' AND ROSTER_RAW3.[Shift_definition] = 'WORK' THEN 'Valid'\n",
    "    When (Case When Roster_Raw3.[Shift_definition] = 'WORK' Then 'WORK'\n",
    "               When Roster_Raw3.[Shift_definition] is Null then Null Else 'OFF' End) = RAMCO_RAW.[Ramco_Define] THEN 'Valid'\n",
    "Else 'ATD MM' End) desc\n",
    "\n",
    "\"\"\"\n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "ATD_MM_pivot = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "ATD_MM_pivot=ATD_MM_pivot.to_pandas()\n",
    "# Export to CSV\n",
    "os.chdir(DF_ATD_DF)\n",
    "# Export to xlsx\n",
    "writer = pd.ExcelWriter(\"BKN_ATD_MM_pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "ATD_MM_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "(max_row, max_col) = ATD_MM_pivot.shape\n",
    "column_settings = [{\"header\": column} for column in ATD_MM_pivot.columns]\n",
    "worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings,\"style\": \"Table Style Light 9\"})\n",
    "worksheet.set_column(0, max_col - 1, 12)\n",
    "worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2434e5ec-9d7c-48f3-8aa5-8ad530402070",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]NM REPORT Link detailðŸŽ¡\n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    "WITH\n",
    "MASTER_EMP AS (\n",
    "SELECT [EMPLOYEE_NUMBER] AS [EID], [FULL_NAME], [Employee Status], [PERSON_TYPE], [WORKER_CATEGORY], [Job Title] as [Job_Title], [MSA Client],\n",
    "[Compensation Grade] As [Grade], [JOB_FUNCTION_DESCRIPTION] As [Function],\n",
    "REPLACE([SUPERVISOR_EMAIL_ID],'@concentrix.com','') As [Supervisor], REPLACE([MANAGER_02_EMAIL_ID],'@concentrix.com','') As [Upline_Sup]\n",
    "FROM GLB.EmpMaster WHERE [Country] = 'Vietnam')\n",
    "SELECT GLB.RAMCO.[Date],\n",
    "CASE WHEN DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date)) >=0 AND DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date))<=2 THEN '00-02 Days'\n",
    "WHEN DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date)) >2 AND DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date))<=5 THEN '03-05 Days'\n",
    "WHEN DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date)) >5 AND DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date))<=10 THEN '06-10 Days'\n",
    "WHEN DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date)) >10 THEN '10 Days +'\n",
    "ELSE NULL END AS [Date_Type],\n",
    "GLB.RAMCO.[EID],MASTER_EMP.[FULL_NAME],GLB.RAMCO.[Code] AS [Ramco],\n",
    "CASE WHEN GLB.RAMCO.[Code]='NM' THEN 1 ELSE 0 END AS [NM_Count],\n",
    "MASTER_EMP.[Employee Status],MASTER_EMP.[PERSON_TYPE],MASTER_EMP.[WORKER_CATEGORY],MASTER_EMP.[Job_Title],\n",
    "MASTER_EMP.[MSA Client],MASTER_EMP.[Grade],MASTER_EMP.[Function],MASTER_EMP.[Supervisor],MASTER_EMP.[Upline_Sup]\n",
    "from GLB.RAMCO\n",
    "LEFT JOIN MASTER_EMP ON MASTER_EMP.[EID]=GLB.RAMCO.[EID]\n",
    "WHERE DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date))<=62 AND DATEDIFF(day, GLB.RAMCO.[Date],cast(getdate() as date))>=0 and GLB.RAMCO.[Code]='NM'\n",
    "\"\"\"\n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "NM_REPORT = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(DF_NM_REPORT)\n",
    "NM_REPORT_CSV = NM_REPORT.write_excel(\"GLB_NM_REPORT.xlsx\", worksheet=\"Sheet1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82ad59ef-cc63-432a-8e5b-c7b9d75f0964",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Function</th><th>00-02 Days</th><th>03-05 Days</th><th>06-10 Days</th><th>10 Days +</th><th>Total</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Operations Group&quot;</td><td>2021</td><td>391</td><td>40</td><td>20</td><td>2472</td></tr><tr><td>&quot;Training &amp; Quality Group&quot;</td><td>116</td><td>13</td><td>0</td><td>1</td><td>130</td></tr><tr><td>&quot;WFM Group&quot;</td><td>24</td><td>0</td><td>0</td><td>0</td><td>24</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 6)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ Function                 â”† 00-02 Days â”† 03-05 Days â”† 06-10 Days â”† 10 Days + â”† Total â”‚\n",
       "â”‚ ---                      â”† ---        â”† ---        â”† ---        â”† ---       â”† ---   â”‚\n",
       "â”‚ str                      â”† i64        â”† i64        â”† i64        â”† i64       â”† i64   â”‚\n",
       "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
       "â”‚ Operations Group         â”† 2021       â”† 391        â”† 40         â”† 20        â”† 2472  â”‚\n",
       "â”‚ Training & Quality Group â”† 116        â”† 13         â”† 0          â”† 1         â”† 130   â”‚\n",
       "â”‚ WFM Group                â”† 24         â”† 0          â”† 0          â”† 0         â”† 24    â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[BKN]NM PIVOT to teamðŸŽ¡\n",
    "filtered_NM_REPORT = NM_REPORT.filter(\n",
    "    (pl.col(\"MSA Client\") == \"Bookingcom\") & \n",
    "    (pl.col(\"Ramco\") == \"NM\") &\n",
    "    (pl.col(\"Employee Status\") == \"Active\")\n",
    ")\n",
    "pivot_NM_REPORT = filtered_NM_REPORT.pivot(\n",
    "    values=[\"NM_Count\",],\n",
    "    index=[\"MSA Client\",\"Function\",],\n",
    "    on=\"Date_Type\",\n",
    "    aggregate_function=\"sum\" # WE can use 'first' náº¿u chá»‰ cÃ³ 1 giÃ¡ trá»‹ duy nháº¥t cho má»—i tá»• há»£p index/columns\n",
    ")\n",
    " \n",
    "#Edit Column\n",
    "unique_date_types = filtered_NM_REPORT[\"Date_Type\"].unique().to_list()\n",
    "pivot_NM_REPORT = pivot_NM_REPORT.with_columns([pl.col(unique_date_types).fill_null(0)])\n",
    "pivot_NM_REPORT = pivot_NM_REPORT.with_columns(pl.fold(0, lambda acc, s: acc + s, pl.exclude(\"MSA Client\",\"Function\",)).alias(\"Total\"))\n",
    "columns_to_select = [\"Function\",\"00-02 Days\", \"03-05 Days\", \"06-10 Days\", \"10 Days +\",\"Total\"]\n",
    "try:\n",
    "    pivot_NM_REPORT = pivot_NM_REPORT.select(columns_to_select)\n",
    "except:\n",
    "    for col in columns_to_select:\n",
    "        try:\n",
    "            pivot_NM_REPORT.select(col)\n",
    "        except:\n",
    "            pivot_NM_REPORT = pivot_NM_REPORT.with_columns(pl.lit(0).cast(pl.Int64).alias(col))\n",
    "    pivot_NM_REPORT = pivot_NM_REPORT.select(columns_to_select)\n",
    " \n",
    "# Export to CSV\n",
    "os.chdir(DF_NM_REPORT)\n",
    "pivot_NM_REPORT_CSV = pivot_NM_REPORT.write_excel(\"GLB_pivot_NM_REPORT.xlsx\", worksheet=\"Sheet1\")\n",
    " \n",
    "#RUN\n",
    "pivot_NM_REPORT_CSV\n",
    "pivot_NM_REPORT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a797e635-8071-4aaf-acc3-b2feda2d859e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]OT_NSA link detailðŸŽ¡\n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    "WITH\n",
    "MASTER_EMP AS (\n",
    "SELECT [EMPLOYEE_NUMBER] AS [EID], [FULL_NAME], [Employee Status], [PERSON_TYPE], [WORKER_CATEGORY], [Job Title] as [Job_Title], [MSA Client],\n",
    "[Compensation Grade] As [Grade], [JOB_FUNCTION_DESCRIPTION] As [Function],\n",
    "REPLACE([SUPERVISOR_EMAIL_ID],'@concentrix.com','') As [Supervisor], REPLACE([MANAGER_02_EMAIL_ID],'@concentrix.com','') As [Upline_Sup]\n",
    "FROM GLB.EmpMaster WHERE [Country] = 'Vietnam')\n",
    "\n",
    "SELECT GLB.OT_RAMCO.[Date],\n",
    "CASE WHEN DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date)) >=0 AND DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date))<=2 THEN '00-02 Days'\n",
    "WHEN DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date)) >2 AND DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date))<=5 THEN '03-05 Days'\n",
    "WHEN DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date)) >5 AND DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date))<=10 THEN '06-10 Days'\n",
    "WHEN DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date)) >10 THEN '10 Days +'\n",
    "ELSE NULL END AS [Date_Type],\n",
    "GLB.OT_RAMCO.[employee_code] as [EID],MASTER_EMP.[FULL_NAME],GLB.OT_RAMCO.[OT Type] AS [OT_Type],GLB.OT_RAMCO.[Status],GLB.OT_RAMCO.[Hours] AS [OT_Hours],\n",
    "MASTER_EMP.[Employee Status],MASTER_EMP.[PERSON_TYPE],MASTER_EMP.[WORKER_CATEGORY],MASTER_EMP.[Job_Title],\n",
    "MASTER_EMP.[MSA Client],MASTER_EMP.[Grade],MASTER_EMP.[Function],MASTER_EMP.[Supervisor],MASTER_EMP.[Upline_Sup]\n",
    "from GLB.OT_RAMCO\n",
    "LEFT JOIN MASTER_EMP ON MASTER_EMP.[EID]=GLB.OT_RAMCO.[employee_code]\n",
    "WHERE DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date))<=62 AND DATEDIFF(day, GLB.OT_RAMCO.[Date],cast(getdate() as date))>=0\n",
    "and GLB.OT_RAMCO.[Status]='Pending'\n",
    "\"\"\"\n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "OT_REPORT = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(DF_OT_REPORT)\n",
    "OT_REPORT_CSV = OT_REPORT.write_excel(\"GLB_OT_REPORT.xlsx\", worksheet=\"Sheet1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc7a6eca-a5c5-44e1-abab-cc923f65c6cf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]NSA PIVOT to teamðŸŽ¡\n",
    "filtered_NSA_REPORT = OT_REPORT.filter(\n",
    "    (pl.col(\"MSA Client\") == \"Bookingcom\") & \n",
    "    (pl.col(\"Employee Status\") == \"Active\") & \n",
    "    (pl.col(\"OT_Type\") == \"NSA\") & \n",
    "    (pl.col(\"Status\") == \"Pending\")\n",
    ")\n",
    "pivot_NSA_REPORT = filtered_NSA_REPORT.pivot(\n",
    "    values=[\"Upline_Sup\",],\n",
    "    index=[\"MSA Client\",\"Function\",],\n",
    "    on=\"Date_Type\",\n",
    "    aggregate_function=\"len\" # WE can use 'first' náº¿u chá»‰ cÃ³ 1 giÃ¡ trá»‹ duy nháº¥t cho má»—i tá»• há»£p index/columns\n",
    ")\n",
    " \n",
    "#Edit Column\n",
    "unique_date_types = filtered_NSA_REPORT[\"Date_Type\"].unique().to_list()\n",
    "pivot_NSA_REPORT = pivot_NSA_REPORT.with_columns([pl.col(unique_date_types).fill_null(0)])\n",
    "pivot_NSA_REPORT = pivot_NSA_REPORT.with_columns(pl.fold(0, lambda acc, s: acc + s, pl.exclude(\"MSA Client\", \"Function\",)).alias(\"Total\"))\n",
    "\n",
    "columns_to_select = [\"Function\",\"00-02 Days\", \"03-05 Days\", \"06-10 Days\", \"10 Days +\",\"Total\"]\n",
    "try:\n",
    "    pivot_NSA_REPORT = pivot_NSA_REPORT.select(columns_to_select)\n",
    "except:\n",
    "    for col in columns_to_select:\n",
    "        try:\n",
    "            pivot_NSA_REPORT.select(col)\n",
    "        except:\n",
    "            pivot_NSA_REPORT = pivot_NSA_REPORT.with_columns(pl.lit(0).cast(pl.Int64).alias(col))\n",
    "    pivot_NSA_REPORT = pivot_NSA_REPORT.select(columns_to_select)\n",
    " \n",
    "# Export to CSV\n",
    "os.chdir(DF_OT_REPORT)\n",
    "pivot_NSA_REPORT_CSV = pivot_NSA_REPORT.write_excel(\"GLB_pivot_NSA_REPORT.xlsx\", worksheet=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb114422-1c4d-4a63-88d1-0912a036f4cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[BKN]OT PIVOT to teamðŸŽ¡\n",
    "filtered_OT_REPORT = OT_REPORT.filter(\n",
    "    (pl.col(\"MSA Client\") == \"Bookingcom\") & \n",
    "    (pl.col(\"Employee Status\") == \"Active\") & \n",
    "    (pl.col(\"Status\") == \"Pending\") &\n",
    "    (pl.col(\"OT_Type\").is_in([\"OT1.5X\", \"OT2.0X\", \"OT2.1X\", \"OT2.7X\", \"OT3.0X\", \"OT3.9X\"]))\n",
    ")\n",
    "pivot_OT_REPORT = filtered_OT_REPORT.pivot(\n",
    "    values=[\"Upline_Sup\",],\n",
    "    index=[\"MSA Client\",\"Function\",],\n",
    "    on=\"Date_Type\",\n",
    "    aggregate_function=\"len\" # WE can use 'first' náº¿u chá»‰ cÃ³ 1 giÃ¡ trá»‹ duy nháº¥t cho má»—i tá»• há»£p index/columns\n",
    ")\n",
    " \n",
    "#Edit Column\n",
    "unique_date_types = filtered_OT_REPORT[\"Date_Type\"].unique().to_list()\n",
    "pivot_OT_REPORT = pivot_OT_REPORT.with_columns([pl.col(unique_date_types).fill_null(0)])\n",
    "pivot_OT_REPORT = pivot_OT_REPORT.with_columns(pl.fold(0, lambda acc, s: acc + s, pl.exclude(\"MSA Client\", \"Function\",)).alias(\"Total\"))\n",
    "columns_to_select = [\"Function\",\"00-02 Days\", \"03-05 Days\", \"06-10 Days\", \"10 Days +\",\"Total\"]\n",
    "try:\n",
    "    pivot_OT_REPORT = pivot_OT_REPORT.select(columns_to_select)\n",
    "except:\n",
    "    for col in columns_to_select:\n",
    "        try:\n",
    "            pivot_OT_REPORT.select(col)\n",
    "        except:\n",
    "            pivot_OT_REPORT = pivot_OT_REPORT.with_columns(pl.lit(0).cast(pl.Int64).alias(col))\n",
    "    pivot_OT_REPORT = pivot_OT_REPORT.select(columns_to_select)\n",
    " \n",
    "# Export to CSV\n",
    "os.chdir(DF_OT_REPORT)\n",
    "pivot_OT_REPORT_CSV = pivot_OT_REPORT.write_excel(\"GLB_pivot_OT_REPORT.xlsx\", worksheet=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c2d0b4f-84bb-4477-a7d0-dcb9f4f1e2e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[GLB]Pending Detail FileðŸŽ¡ Combine link detail\n",
    "with xlsxwriter.Workbook(link_PENDINGDETAIL) as workbook:\n",
    "    worksheet = workbook.add_worksheet('NM Pending Detail') # Create a new worksheet.\n",
    "    filtered_NM_REPORT.write_excel(workbook=workbook, worksheet=\"NM Pending Detail\", position=\"A1\") # Do something with the worksheet.\n",
    " \n",
    "    worksheet = workbook.add_worksheet('OT Pending Detail') # Create a new worksheet.\n",
    "    filtered_OT_REPORT.write_excel(workbook=workbook, worksheet=\"OT Pending Detail\", position=\"A1\") # Do something with the worksheet.\n",
    " \n",
    "    worksheet = workbook.add_worksheet('NSA Pending Detail') # Create a new worksheet.\n",
    "    filtered_NSA_REPORT.write_excel(workbook=workbook, worksheet=\"NSA Pending Detail\", position=\"A1\") # Do something with the worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c2eae5-36df-4468-917f-0b4fc6dc1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[BKN]Login report link DetailðŸŽ¡ (Dillip team)\n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    "select [Date],[Week_day] as [Weekday],[Emp ID],[Emp_Name] as [Name],[Booking login ID] as [Username], [Wave],[TL_Name] as [Sup],[LOB] as [LOBs],[Shift],\n",
    " \n",
    "[Productive(s)]/3600.0 as [THT (In hours)],\n",
    "CAST([Stafftime(s)]+[ExceptionReq(s)] as float)/3600.0 as [Staffed hours],\n",
    " \n",
    "CAST((([Stafftime(s)]-[Delivery(s)]-IIF([Lunch(s)] IS NULL,0,[Lunch(s)])-IIF([Break(s)] IS NULL,0,[Break(s)]))+[ExceptionReq(s)]) as float)/3600.0 as [Non Productive Aux(In Hours)],\n",
    "\n",
    "[Delivery(s)]/3600.0 as [Delivered hours],\n",
    " \n",
    "[Phone_#TED]+[Phone_#PEGA] as [Total Phone Tickets], \n",
    "[NonPhone_#TED]+[NonPhone_#PEGA] as [Total Non-phone Tickets],\n",
    "[AgentAvailTime(s)]/3600.0 as [Avail Time(In Hours)],\n",
    " \n",
    "[Downtime(s)]/3600.0 as [Other Productive Aux(In Hours)],\n",
    "(CAST(IIF([Lunch(s)] IS NULL,0,[Lunch(s)])as float)+CAST(IIF([Break(s)] IS NULL,0,[Break(s)]) as float))/3600.0 as [Total break (In hours)]\n",
    " \n",
    "FROM BCOM.EEAAO\n",
    " \n",
    "where Date < DATEADD(DAY, -1,CAST(GETDATE() As Date)) and Date> DATEADD(DAY, -30,CAST(GETDATE() As Date)) and [Stafftime(s)]>0\n",
    "\n",
    "\"\"\"\n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "Login_detail_raw = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "Login_detail = Login_detail_raw.to_pandas()\n",
    "Login_detail['Date']=pd.to_datetime(Login_detail['Date']).dt.date\n",
    "Login_detail=Login_detail[['Date','Weekday','Emp ID','Name','Username','Wave','Sup','LOBs','Shift','Delivered hours',\n",
    "                           'Staffed hours','Total Phone Tickets','Total Non-phone Tickets']]\n",
    "Login_detail = pl.from_pandas(Login_detail)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7ec00f8-acf9-4c53-8934-9ebc84e42a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[BKN]Login Summary Pivot (Dillip team)ðŸŽ¡\n",
    "Login_summary = Login_detail_raw.to_pandas()\n",
    "Login_summary['Date']=pd.to_datetime(Login_summary['Date']).dt.date\n",
    "Login_summary=Login_summary[['Date','Staffed hours','Total break (In hours)','THT (In hours)','Avail Time(In Hours)',\n",
    "                             'Other Productive Aux(In Hours)','Non Productive Aux(In Hours)']]\n",
    "Login_summary['Location'] = 'HCM'\n",
    "Login_summary['Country'] = 'Vietnam'\n",
    "Login_summary['Account'] = 'Booking.com'\n",
    "Login_summary['Work Status'] = 'WFO'\n",
    "Login_summary['Present for calculation'] = 1\n",
    "Login_summary=Login_summary.groupby(['Date','Location','Country','Account','Work Status'],as_index=False).sum()\n",
    "Login_summary=Login_summary.sort_values(by='Date',ascending=True)\n",
    "Login_summary = pl.from_pandas(Login_summary)\n",
    "\n",
    "\n",
    "# Export to xlsx\n",
    "# os.chdir(DF_LOGIN_DF)\n",
    "# writer = pd.ExcelWriter(\"Booking - Agent Wise Login Detail.xlsx\", engine=\"xlsxwriter\")\n",
    "# Login_summary.to_excel(writer, sheet_name=\"Overall Login\", startrow=1, header=False, index=False)\n",
    "# workbook = writer.book\n",
    "# worksheet = writer.sheets[\"Overall Login\"]\n",
    "# (max_row, max_col) = Login_summary.shape\n",
    "# column_settings = [{\"header\": column} for column in Login_summary.columns]\n",
    "# worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings})\n",
    "# worksheet.set_column(0, max_col - 1, 12)\n",
    "# writer.close()\n",
    "\n",
    "with xlsxwriter.Workbook(DF_LOGIN_DF) as workbook:\n",
    "    worksheet = workbook.add_worksheet('Overall Login') # Create a new worksheet.\n",
    "    Login_summary.write_excel(workbook=workbook, worksheet=\"Overall Login\", position=\"A1\") # Do something with the worksheet.\n",
    "\n",
    "    worksheet = workbook.add_worksheet('Agent wise Login') # Create a new worksheet.\n",
    "    Login_detail.write_excel(workbook=workbook, worksheet=\"Agent wise Login\", position=\"A1\") # Do something with the worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "254da566-1a8a-4f06-b0bc-34141ae1999f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call out Login-Logout\n",
    "today = datetime.date.today()\n",
    "weekday=today.weekday()\n",
    "last_week = today - datetime.timedelta(days=4) \n",
    "weeknum_last_week = last_week.isocalendar().week \n",
    "year_last_week = last_week.year\n",
    "# Táº¡o chuá»—i káº¿t há»£p nÄƒm vÃ  weeknum, Ä‘áº£m báº£o weeknum cÃ³ 2 chá»¯ sá»‘\n",
    "result =f\"{year_last_week}{weeknum_last_week:02d}\"\n",
    "text=\"Call out Login_Logout W\"\n",
    "path=\".xlsx\"\n",
    "filename= text+result+path\n",
    "\n",
    "def find_excel_files(folder_path):  \n",
    "  excel_files = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.xls', '.xlsx')):\n",
    "      excel_files.append(os.path.basename(filename))  # Chá»‰ láº¥y tÃªn file\n",
    "  return excel_files\n",
    "folder_path = Login_Logout_Folder  # Thay tháº¿ báº±ng Ä‘Æ°á»ng dáº«n thÆ° má»¥c cá»§a báº¡n\n",
    "excel_files = find_excel_files(folder_path)\n",
    "\n",
    "if weekday==2:\n",
    "    def check_file_in_list(filename, list_filenames):\n",
    "        return filename in list_filenames\n",
    "    result = check_file_in_list(filename, excel_files)  # result sáº½ lÃ  True\n",
    "    if result==False:\n",
    "        sql_query = \"\"\"\n",
    "\n",
    "\t\tSELECT [Emp ID],[Week_num],[Date],[LOB],[Tenure days],[OM_Name],[TL_Name],[TED Name],[shift],[Login],[Logout],[Late-Soon] \n",
    "\t\tFROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "\t\tand [Late-Soon] <>'' and [Shift]<>'New Hire Training'\n",
    "\t\torder by [Date] asc\n",
    "\n",
    "        \"\"\"\n",
    "        # Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "        login_logout = pl.read_database(query=sql_query, connection=engine)\n",
    "        engine.dispose()\n",
    "\n",
    "        # Export to Pivot\n",
    "        login_logout_pivot = login_logout.pivot(\n",
    "            values=[\"Emp ID\",],\n",
    "            index=[\"OM_Name\",\"TL_Name\",],\n",
    "            on=\"Late-Soon\",\n",
    "            aggregate_function=\"len\" # WE can use 'first' náº¿u chá»‰ cÃ³ 1 giÃ¡ trá»‹ duy nháº¥t cho má»—i tá»• há»£p index/columns\n",
    "        )\n",
    "        login_logout_pivot = login_logout_pivot.fill_null(0).select([pl.all().sort_by(\"OM_Name\")]) \n",
    "        login_logout_pivot = login_logout_pivot.to_pandas()\n",
    "\n",
    "        # Export to xlsx\n",
    "        os.chdir(BKN_Folder)\n",
    "        # login_logout_pivot = login_logout_pivot.write_excel(\"Login_Logout_Pivot.xlsx\", worksheet=\"Pivot\", autofit=True)        \n",
    "        writer = pd.ExcelWriter(\"Login_Logout_Pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "        login_logout_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "        (max_row, max_col) = login_logout_pivot.shape\n",
    "        column_settings = [{\"header\": column} for column in login_logout_pivot.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "        worksheet.set_column(0, max_col - 1, 13)\n",
    "        worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "        writer.close()          \n",
    "        \n",
    "        # Export to Detail\n",
    "        login_logout = login_logout.to_pandas()\n",
    "        writer = pd.ExcelWriter(Login_Logout_Folder+\"//\"+filename, engine='xlsxwriter') \n",
    "        login_logout.to_excel(writer, sheet_name=\"Detail\", startrow=0, index=False)\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Detail']        \n",
    "        worksheet.set_column('A:N', 11)\n",
    "        \n",
    "        #Adding the header and Datavalidation list\n",
    "        worksheet.write('M1', 'Reason')\n",
    "        worksheet.data_validation('M2:M1000', {'validate': 'list',\n",
    "                                          'source': ['Seat Issue','Technical Issue','Non-adherence shift'\n",
    "                                                    ,'Traffic Issue','Personal Issue'\n",
    "                                                     ,'Parking Issue','Badge Issue'\n",
    "                                                    ,'Weather Issue','No insight given','Yubikey + Prepare for shift']})\n",
    "        worksheet.write('N1', 'Please provide insight here')\n",
    "        workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a66849e-bfe8-42d2-9656-8d17f1ee9553",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Call out Stafftime\n",
    "today = datetime.date.today()\n",
    "weekday=today.weekday()\n",
    "last_week = today - datetime.timedelta(days=4) \n",
    "weeknum_last_week = last_week.isocalendar().week \n",
    "year_last_week = last_week.year\n",
    "# Táº¡o chuá»—i káº¿t há»£p nÄƒm vÃ  weeknum, Ä‘áº£m báº£o weeknum cÃ³ 2 chá»¯ sá»‘\n",
    "result =f\"{year_last_week}{weeknum_last_week:02d}\"\n",
    "text=\"Call out Shortage of Stafftime W\"\n",
    "path=\".xlsx\"\n",
    "filename= text+result+path\n",
    "\n",
    "def find_excel_files(folder_path):  \n",
    "  excel_files = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.xls', '.xlsx')):\n",
    "      excel_files.append(os.path.basename(filename))  # Chá»‰ láº¥y tÃªn file\n",
    "  return excel_files\n",
    "folder_path = Stafftime_Folder  # Thay tháº¿ báº±ng Ä‘Æ°á»ng dáº«n thÆ° má»¥c cá»§a báº¡n\n",
    "excel_files = find_excel_files(folder_path)\n",
    "\n",
    "if weekday==2:\n",
    "    def check_file_in_list(filename, list_filenames):\n",
    "        return filename in list_filenames\n",
    "    result = check_file_in_list(filename, excel_files)  # result sáº½ lÃ  True\n",
    "    if result==False:\n",
    "        sql_query = \"\"\"   \n",
    "        SELECT [Week_num],[Date],[LOB],[OM_Name],[TL_Name],[shift],[Emp ID],[Emp_Name],[Ramco_Code] as [RAMCO],[Login],[Logout],\n",
    "        CAST([Stafftime(s)] as float)/3600 as [Stafftime(H)],CAST([ExceptionReq(s)] as float)/3600 as [ExceptionReq(H)],CAST([Stafftime(s)] +[ExceptionReq(s)] as float)/3600 as [Total Present time]\n",
    "        FROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "\t\tand CAST([Stafftime(s)] +[ExceptionReq(s)] as float)/3600 <7.5 and [Ramco_Code]='PR' and [Shift]<>'New Hire Training' and [Work Type]<>'Part time'\n",
    "\t\torder by [Date] asc\n",
    "        \"\"\"\n",
    "        stafftime = pl.read_database(query=sql_query, connection=engine)\n",
    "        engine.dispose()\n",
    "        # Export to Pivot\n",
    "        stafftime_pivot = (\n",
    "            stafftime.group_by([\"OM_Name\", \"TL_Name\"])\n",
    "            .agg(\n",
    "                [\n",
    "                    pl.col(\"Emp ID\").count().alias(\"Cases\")\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        stafftime_pivot = stafftime_pivot.fill_null(0).select([pl.all().sort_by(\"OM_Name\")]) \n",
    "        stafftime_pivot = stafftime_pivot.to_pandas()\n",
    "        stafftime_pivot = stafftime_pivot.sort_values(by='Cases',ascending=False)\n",
    "        # Export to xlsx\n",
    "        os.chdir(BKN_Folder)\n",
    "        writer = pd.ExcelWriter(\"Stafftime_Pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "        stafftime_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "        (max_row, max_col) = stafftime_pivot.shape\n",
    "        column_settings = [{\"header\": column} for column in stafftime_pivot.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "        worksheet.set_column(0, max_col - 1, 13)\n",
    "        worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "        writer.close()          \n",
    "        \n",
    "        # Export to Detail\n",
    "        stafftime = stafftime.to_pandas()\n",
    "        writer = pd.ExcelWriter(Stafftime_Folder+\"//\"+filename, engine='xlsxwriter') \n",
    "        stafftime.to_excel(writer, sheet_name=\"Detail\", startrow=0, index=False)\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Detail']        \n",
    "        worksheet.set_column('A:P', 11)\n",
    "        \n",
    "        #Adding the header and Datavalidation list\n",
    "        worksheet.write('O1', 'Reason')\n",
    "        worksheet.data_validation('O2:O1000', {'validate': 'list',\n",
    "                                          'source': ['HAL','Non-adherence shift','Personal Issue'\n",
    "                                                    ,'Ramco mismatch','Technical issue','No insight given','Mismatch RAMCO']})\n",
    "        worksheet.write('P1', 'Please provide insight here')\n",
    "        workbook.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c80c173-a5b1-40a3-80e1-63cdeefff6d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Call out LOW_CPH\n",
    "today = datetime.date.today()\n",
    "weekday=today.weekday()\n",
    "last_week = today - datetime.timedelta(days=4) \n",
    "weeknum_last_week = last_week.isocalendar().week \n",
    "year_last_week = last_week.year\n",
    "# Táº¡o chuá»—i káº¿t há»£p nÄƒm vÃ  weeknum, Ä‘áº£m báº£o weeknum cÃ³ 2 chá»¯ sá»‘\n",
    "result =f\"{year_last_week}{weeknum_last_week:02d}\"\n",
    "text=\"Low_CPH_Insight_W\"\n",
    "path=\".xlsx\"\n",
    "filename= text+result+path\n",
    "\n",
    "def find_excel_files(folder_path):  \n",
    "  excel_files = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.xls', '.xlsx')):\n",
    "      excel_files.append(os.path.basename(filename))  # Chá»‰ láº¥y tÃªn file\n",
    "  return excel_files\n",
    "folder_path = Low_CPH_Folder  # Thay tháº¿ báº±ng Ä‘Æ°á»ng dáº«n thÆ° má»¥c cá»§a báº¡n\n",
    "excel_files = find_excel_files(folder_path)\n",
    "\n",
    "if weekday==2:\n",
    "    def check_file_in_list(filename, list_filenames):\n",
    "        return filename in list_filenames\n",
    "    result = check_file_in_list(filename, excel_files)  # result sáº½ lÃ  True\n",
    "    if result==False:\n",
    "        sql_query = \"\"\"  \n",
    "        SELECT [Week_num],[OM_Name],[TL_Name],[Emp ID],[Emp_Name],\n",
    "        CASE WHEN SUM([Productive(s)])=0 THEN 0 ELSE Sum([Total_Cases])/(Sum(CAST([Productive(s)] as float))/3600) END as [CPH],\n",
    "        sum(CAST([Productive(s)] as float))/3600 as [Productive (H)],\n",
    "\t\tsum([Total_Cases]) as [Case],\n",
    "        CASE WHEN SUM([Csat Survey])=0 THEN 0 ELSE CAST(sum(CAST([Csat Score] AS FLOAT))/sum(CAST([Csat Survey] AS FLOAT)) AS FLOAT) END as [CSAT],\n",
    "        sum([Csat Survey]) as [Survey]\n",
    "               \n",
    "        FROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "        and LOB <> 'Senior VICSP' and [Shift]<>'New Hire Training'\n",
    "        group by [Week_num],[OM_Name],[TL_Name],[Emp ID],[Emp_Name] \n",
    "                \"\"\"\n",
    "        Low_CPH = pl.read_database(query=sql_query, connection=engine)\n",
    "        engine.dispose()\n",
    "        Low_CPH =Low_CPH.filter((pl.col(\"CPH\")<1.5)&(pl.col(\"Productive (H)\")>0))\n",
    "        # Export to Pivot\n",
    "        Low_CPH_pivot = (\n",
    "            Low_CPH.group_by([\"OM_Name\", \"TL_Name\"])\n",
    "            .agg(\n",
    "                [\n",
    "                    pl.col(\"Emp ID\").count().alias(\"Cases\")\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        Low_CPH_pivot = Low_CPH_pivot.fill_null(0).select([pl.all().sort_by(\"OM_Name\")]) \n",
    "        Low_CPH_pivot = Low_CPH_pivot.to_pandas()\n",
    "        Low_CPH_pivot = Low_CPH_pivot.sort_values(by='Cases',ascending=False)\n",
    "        # Export to xlsx\n",
    "        os.chdir(BKN_Folder)\n",
    "        writer = pd.ExcelWriter(\"Low_CPH_Pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "        Low_CPH_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "        (max_row, max_col) = Low_CPH_pivot.shape\n",
    "        column_settings = [{\"header\": column} for column in Low_CPH_pivot.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                         ,\"style\": \"Table Style Light 9\"})\n",
    "        worksheet.set_column(0, max_col - 1, 13)\n",
    "        worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "        writer.close()          \n",
    "        \n",
    "        # Export to Detail\n",
    "        Low_CPH = Low_CPH.to_pandas()\n",
    "        writer = pd.ExcelWriter(Low_CPH_Folder+\"//\"+filename, engine='xlsxwriter') \n",
    "        Low_CPH.to_excel(writer, sheet_name=\"Detail\", startrow=0, index=False)\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Detail']        \n",
    "        worksheet.set_column('A:L', 11)\n",
    "        \n",
    "        #Adding the header and Datavalidation list\n",
    "        worksheet.write('K1', 'Reason')\n",
    "        worksheet.data_validation('K2:K1000', {'validate': 'list',\n",
    "                                          'source': ['Bad Quality','Behavior Issue','Cases not counted to CPH'\n",
    "                                                     ,'Complicated cases','Control CSAT','Health Issue'\n",
    "                                                     ,'Long leave','Newbie','Newly Transferred'\n",
    "                                                    ,'Promoted','Resigned','No insight given'\n",
    "                                                    ,'Skill Issue','Support Newbie','Technical Issue'\n",
    "                                                     ]})\n",
    "        worksheet.write('L1', 'Please provide insight here')\n",
    "        workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f19a248a-a87f-48f9-88a4-628c02d644ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Call out OOH\n",
    "today = datetime.date.today()\n",
    "weekday=today.weekday()\n",
    "last_week = today - datetime.timedelta(days=4) \n",
    "weeknum_last_week = last_week.isocalendar().week \n",
    "year_last_week = last_week.year\n",
    "# Táº¡o chuá»—i káº¿t há»£p nÄƒm vÃ  weeknum, Ä‘áº£m báº£o weeknum cÃ³ 2 chá»¯ sá»‘\n",
    "result =f\"{year_last_week}{weeknum_last_week:02d}\"\n",
    "text=\"Call out Out of Hoop_W\"\n",
    "path=\".xlsx\"\n",
    "filename= text+result+path\n",
    "\n",
    "def find_excel_files(folder_path):  \n",
    "  excel_files = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.xls', '.xlsx')):\n",
    "      excel_files.append(os.path.basename(filename))  # Chá»‰ láº¥y tÃªn file\n",
    "  return excel_files\n",
    "folder_path = Low_CPH_Folder  # Thay tháº¿ báº±ng Ä‘Æ°á»ng dáº«n thÆ° má»¥c cá»§a báº¡n\n",
    "excel_files = find_excel_files(folder_path)\n",
    "\n",
    "if weekday==2:\n",
    "    def check_file_in_list(filename, list_filenames):\n",
    "        return filename in list_filenames\n",
    "    result = check_file_in_list(filename, excel_files)  # result sáº½ lÃ  True\n",
    "    if result==False:\n",
    "        sql_query = \"\"\"  \t\t\n",
    "        with LI as (\n",
    "\t\tSELECT [Date],[Week_num],[OM_Name],[TL_Name],[Emp ID],[Emp_Name],[Shift],[LOB],[Login],[Logout],\n",
    "        case when [LoggedInBeforeShift]='1' then 'Logged in soon' else '' end as [WFM_Note]               \n",
    "        FROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "        and [LoggedInBeforeShift]='1' \n",
    "        and [LOB]<>'EN'),\n",
    "\t\tLO as (\n",
    "\t\tSELECT [Date],[Week_num],[OM_Name],[TL_Name],[Emp ID],[Emp_Name],[Shift],[LOB],[Login],[Logout],\n",
    "        case when [NotLoggedOutAfterShift]='1' then 'Logged out late' else '' end as [WFM_Note]          \n",
    "        FROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "        and [NotLoggedOutAfterShift]='1' \n",
    "        and [LOB]<>'EN')\n",
    "\t\tselect * from LI\n",
    "\t\tunion all\n",
    "        SELECT * FROM LO\n",
    "        \"\"\"\n",
    "        OOH = pl.read_database(query=sql_query, connection=engine)\n",
    "        engine.dispose()\n",
    "\n",
    "        # Export to Pivot\n",
    "        OOH_pivot =(\n",
    "            OOH.group_by([\"OM_Name\", \"TL_Name\"])\n",
    "            .agg(\n",
    "                [\n",
    "                    pl.col(\"Emp ID\").count().alias(\"Cases\")\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        OOH_pivot = OOH_pivot.fill_null(0).select([pl.all().sort_by(\"OM_Name\")]) \n",
    "        OOH_pivot = OOH_pivot.to_pandas()\n",
    "        OOH_pivot = OOH_pivot.sort_values(by='Cases',ascending=False)\n",
    "        # Export to xlsx\n",
    "        os.chdir(BKN_Folder)\n",
    "        writer = pd.ExcelWriter(\"OOH_Pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "        OOH_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "        (max_row, max_col) = OOH_pivot.shape\n",
    "        column_settings = [{\"header\": column} for column in OOH_pivot.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                         ,\"style\": \"Table Style Light 9\"})\n",
    "        worksheet.set_column(0, max_col - 1, 13)\n",
    "        worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "        writer.close()          \n",
    "        \n",
    "        # Export to Detail\n",
    "        OOH = OOH.to_pandas()\n",
    "        writer = pd.ExcelWriter(OOH_Folder+\"//\"+filename, engine='xlsxwriter') \n",
    "        OOH.to_excel(writer, sheet_name=\"Detail\", startrow=0, index=False)\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Detail']        \n",
    "        worksheet.set_column('A:L', 11)\n",
    "        \n",
    "        #Adding the header and Datavalidation list\n",
    "        worksheet.write('L1', 'Reason')\n",
    "        worksheet.data_validation('L2:L1000', {'validate': 'list',\n",
    "                                          'source': ['Scheduling misinformation'\n",
    "                                                     ,'Missing logout time','Technical issue'\n",
    "                                                     ,'Handling case over logout time','Prepare for the shift'\n",
    "                                                    ,'No insight given','Non-adherence shift time'\n",
    "                                                     ]})\n",
    "        worksheet.write('M1', 'Please provide insight here')\n",
    "        workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ea3bf91-1e35-4123-ad11-373bee9e63f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Call out LOGOUTCOUNT\n",
    "today = datetime.date.today()\n",
    "weekday=today.weekday()\n",
    "last_week = today - datetime.timedelta(days=4) \n",
    "weeknum_last_week = last_week.isocalendar().week \n",
    "year_last_week = last_week.year\n",
    "# Táº¡o chuá»—i káº¿t há»£p nÄƒm vÃ  weeknum, Ä‘áº£m báº£o weeknum cÃ³ 2 chá»¯ sá»‘\n",
    "result =f\"{year_last_week}{weeknum_last_week:02d}\"\n",
    "text=\"Call out LOGOUT_COUNT W\"\n",
    "path=\".xlsx\"\n",
    "filename= text+result+path\n",
    "\n",
    "def find_excel_files(folder_path):  \n",
    "  excel_files = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.xls', '.xlsx')):\n",
    "      excel_files.append(os.path.basename(filename))  # Chá»‰ láº¥y tÃªn file\n",
    "  return excel_files\n",
    "folder_path = Logout_Count_Folder  # Thay tháº¿ báº±ng Ä‘Æ°á»ng dáº«n thÆ° má»¥c cá»§a báº¡n\n",
    "excel_files = find_excel_files(folder_path)\n",
    "\n",
    "if weekday==2:\n",
    "    def check_file_in_list(filename, list_filenames):\n",
    "        return filename in list_filenames\n",
    "    result = check_file_in_list(filename, excel_files)  # result sáº½ lÃ  True\n",
    "    if result==False:\n",
    "        sql_query = \"\"\" \t\t\n",
    "        select [Week_num],[Date],[Emp ID],[Emp_Name],[TED Name],[shift],[OM_Name],[TL_Name],[Login],[Logout],[Logout_Count]       \n",
    "        FROM BCOM.EEAAO\n",
    "\t\twhere [Date] >= DATEADD(DAY, -9,CAST(GETDATE() As Date)) and [Date] <= DATEADD(DAY, -3,CAST(GETDATE() As Date))\n",
    "        and [Logout_Count]>=50\n",
    "                  \"\"\"\n",
    "        Logout_Count = pl.read_database(query=sql_query, connection=engine)\n",
    "        engine.dispose()\n",
    "        # Export to Pivot\n",
    "        Logout_Count_pivot = (\n",
    "            Logout_Count.group_by([\"OM_Name\", \"TL_Name\"])\n",
    "            .agg(\n",
    "                [\n",
    "                    pl.col(\"Emp ID\").count().alias(\"Cases\")\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        Logout_Count_pivot = Logout_Count_pivot.to_pandas()\n",
    "        Logout_Count_pivot = Logout_Count_pivot.sort_values(by='Cases',ascending=False)\n",
    "\n",
    "        # Export to xlsx\n",
    "        os.chdir(BKN_Folder)\n",
    "        writer = pd.ExcelWriter(\"Logout_Count_Pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "        Logout_Count_pivot.to_excel(writer, sheet_name=\"Sheet1\", startrow=1, header=False, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "        (max_row, max_col) = Logout_Count_pivot.shape\n",
    "        column_settings = [{\"header\": column} for column in Logout_Count_pivot.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "        worksheet.set_column(0, max_col - 1, 13)\n",
    "        worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "        writer.close()          \n",
    "        \n",
    "        # Export to Detail\n",
    "        Logout_Count = Logout_Count.to_pandas()\n",
    "        writer = pd.ExcelWriter(Logout_Count_Folder+\"//\"+filename, engine='xlsxwriter') \n",
    "        Logout_Count.to_excel(writer, sheet_name=\"Count>=50\", startrow=0, index=False)\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Count>=50']        \n",
    "        worksheet.set_column('A:M', 11)\n",
    "        \n",
    "        #Adding the header and Datavalidation list\n",
    "        worksheet.write('L1', 'Reason')\n",
    "        worksheet.data_validation('L2:L1000', {'validate': 'list',\n",
    "                                          'source': ['Behavior','Low Volume','Personal Issue'\n",
    "                                                    ,'Ramco mismatch','Technical issue','No insight given']})\n",
    "        worksheet.write('M1', 'Please provide insight here')\n",
    "        workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7678ebe5-d9b6-423e-9647-e0320aeb7293",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Stability Report\n",
    "import os, glob, re\n",
    "from datetime import timedelta, datetime as dt, time as t, date as d\n",
    "import polars as pl\n",
    "from sqlalchemy import create_engine, text\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Source collection\n",
    "\n",
    "user_credential = os.path.join(os.environ['USERPROFILE'],r'Concentrix Corporation//CNXVN - WFM Team - Documents//')\n",
    "\n",
    "# INPUT-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾-----ðŸ’¾\n",
    "# [BKN]Error Log\n",
    "LOG_LINK = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN//MODIFIED_LOG//*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "184fe5a7-d4dc-48e4-af8b-9fde26218255",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Data code 1\n",
    " \n",
    "# CÃ¢u lá»‡nh SQL\n",
    "sql_query = \"\"\"\n",
    " \n",
    " \n",
    "WITH CombinedData AS (\n",
    "-- 01/ BCOM.AHT \n",
    "    SELECT 'BKN' AS [SCHEMA], 'AHT' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.AHT2\n",
    "    UNION ALL\n",
    "-- 02/ BCOM.CapHC \n",
    "    SELECT 'BKN' AS [SCHEMA], 'CapHC' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CapHC\n",
    "    UNION ALL\n",
    "-- 03/ BCOM.Contrack\n",
    "    SELECT 'BKN' AS [SCHEMA], 'Contrack' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.Contrack\n",
    "    UNION ALL\n",
    "-- 04/ BCOM.CPI\n",
    "    SELECT 'BKN' AS [SCHEMA], 'CPI' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CPI\n",
    "    UNION ALL\n",
    "-- 05/ BCOM.CPI_PEGA\n",
    "    SELECT 'BKN' AS [SCHEMA], 'CPI_PEGA' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CPI_PEGA\n",
    "    UNION ALL\n",
    "-- 06/ BCOM.CSAT_RS\n",
    "    SELECT 'BKN' AS [SCHEMA], 'CSAT_RS' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CSAT_RS\n",
    "    UNION ALL\n",
    "-- 07/ BCOM.CSAT_TP\n",
    "    SELECT 'BKN' AS [SCHEMA], 'CSAT_TP' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CSAT_TP\n",
    "    UNION ALL\n",
    "-- 08/ BCOM.CUIC\n",
    "    SELECT 'BKN' AS [SCHEMA], 'CUIC' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.CUIC\n",
    "    UNION ALL\n",
    "-- 10/ BCOM.DailyReq\n",
    "    SELECT 'BKN' AS [SCHEMA], 'DailyReq' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.DailyReq\n",
    "    UNION ALL\n",
    "-- 11/ BCOM.EPS\n",
    "    SELECT 'BKN' AS [SCHEMA], 'EPS' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.EPS\n",
    "    UNION ALL\n",
    "-- 12/ BCOM.ExceptionReq\n",
    "    SELECT 'BKN' AS [SCHEMA], 'ExceptionReq' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.ExceptionReq\n",
    "    UNION ALL\n",
    "-- 13/ BCOM.IEX_Hrs\n",
    "    SELECT 'BKN' AS [SCHEMA], 'IEX_Hrs' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.IEX_Hrs\n",
    "    UNION ALL\n",
    "-- 14/ BCOM.IntervalReq\n",
    "    SELECT 'BKN' AS [SCHEMA], 'IntervalReq' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.IntervalReq\n",
    "    UNION ALL\n",
    "-- 15/ BCOM.KPI_Target\n",
    "    SELECT 'BKN' AS [SCHEMA], 'KPI_Target' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.KPI_Target\n",
    "    UNION ALL\n",
    "-- 16/ BCOM.LogoutCount\n",
    "    SELECT 'BKN' AS [SCHEMA], 'LogoutCount' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.LogoutCount\n",
    "    UNION ALL\n",
    "-- 17/ BCOM.LTTransfers\n",
    "    SELECT 'BKN' AS [SCHEMA], 'LTTransfers' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.LTTransfers\n",
    "    UNION ALL\n",
    "-- 18/ BCOM.OTReq\n",
    "    SELECT 'BKN' AS [SCHEMA], 'OTReq' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.OTReq\n",
    "    UNION ALL\n",
    "-- 19/ BCOM.ProjectedHC\n",
    "    SELECT 'BKN' AS [SCHEMA], 'ProjectedHC' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.ProjectedHC\n",
    "    UNION ALL\n",
    "-- 20/ BCOM.ProjectedShrink\n",
    "    SELECT 'BKN' AS [SCHEMA], 'ProjectedShrink' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.ProjectedShrink\n",
    "    UNION ALL\n",
    "-- 21/ BCOM.PSAT\n",
    "    SELECT 'BKN' AS [SCHEMA], 'PSAT' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.PSAT\n",
    "    UNION ALL\n",
    "-- 22/ BCOM.Quality\n",
    "    SELECT 'BKN' AS [SCHEMA], 'Quality' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.Quality\n",
    "    UNION ALL\n",
    "-- 23/ BCOM.RegisteredOT\n",
    "    SELECT 'BKN' AS [SCHEMA], 'RegisteredOT' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.RegisteredOT\n",
    "    UNION ALL\n",
    "-- 24/ BCOM.RONA\n",
    "    SELECT 'BKN' AS [SCHEMA], 'RONA' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.RONA\n",
    "    UNION ALL\n",
    "-- 25/ BCOM.ROSTER\n",
    "    SELECT 'BKN' AS [SCHEMA], 'ROSTER' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.ROSTER\n",
    "    UNION ALL\n",
    "-- 26/ BCOM.Staff\n",
    "    SELECT 'BKN' AS [SCHEMA], 'Staff' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.Staff\n",
    "    UNION ALL\n",
    "-- 27/ BCOM.WpDetail\n",
    "    SELECT 'BKN' AS [SCHEMA], 'WpDetail' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.WpDetail\n",
    "    UNION ALL\n",
    "-- 28/ BCOM.WpSummary\n",
    "    SELECT 'BKN' AS [SCHEMA], 'WpSummary' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM BCOM.WpSummary\n",
    "    UNION ALL\n",
    "-- 29/ GLB.EmpMaster\n",
    "    SELECT 'GLB' AS [SCHEMA], 'EmpMaster' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.EmpMaster\n",
    "    UNION ALL\n",
    "-- 30/ GLB.NormHdays\n",
    "    SELECT 'GLB' AS [SCHEMA], 'NormHdays' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.NormHdays\n",
    "    UNION ALL\n",
    "-- 31/ GLB.OT_RAMCO\n",
    "    SELECT 'GLB' AS [SCHEMA], 'OT_RAMCO' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.OT_RAMCO\n",
    "    UNION ALL\n",
    "-- 32/ GLB.PremHdays\n",
    "    SELECT 'GLB' AS [SCHEMA], 'PremHdays' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.PremHdays\n",
    "    UNION ALL\n",
    "-- 33/ GLB.RAMCO\n",
    "    SELECT 'GLB' AS [SCHEMA], 'RAMCO' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.RAMCO\n",
    "    UNION ALL\n",
    "-- 34/ GLB.Resignation\n",
    "    SELECT 'GLB' AS [SCHEMA], 'Resignation' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.Resignation\n",
    "    UNION ALL\n",
    "-- 35/ GLB.Termination\n",
    "    SELECT 'GLB' AS [SCHEMA], 'Termination' AS [FOLDER NAME], [FileName], [ModifiedDate] FROM GLB.Termination\n",
    "),\n",
    "FileNameCheck AS (\n",
    "    SELECT [SCHEMA],[FOLDER NAME],[FileName] + ' - ' + CONVERT(VARCHAR, [ModifiedDate], 120) AS [FileName - ModifiedDate],COUNT(*) \n",
    "\tAS [ROW_NUMBER]\n",
    "    FROM CombinedData\n",
    "    GROUP BY [SCHEMA], [FOLDER NAME], [FileName] + ' - ' + CONVERT(VARCHAR, [ModifiedDate], 120)\n",
    "    HAVING COUNT(*) > 1\n",
    ")\n",
    "SELECT * FROM FileNameCheck\n",
    "ORDER BY [SCHEMA] ASC, [FOLDER NAME] DESC, [FileName - ModifiedDate] ASC\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "Code1_Result = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b793adc6-f6ba-4e4a-b3b8-a3d4ae32a4ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Data code 2\n",
    "engine = create_engine(connection_string)\n",
    " \n",
    "# CÃ¢u lá»‡nh SQL\n",
    "\n",
    "sql_query2 = \"\"\"\n",
    "with\n",
    "-- 1. Agent Raw\n",
    "Agents_Raw1 as\n",
    "(Select Employee_ID, COUNT(*) as [Count]\n",
    "From BCOM.Staff\n",
    "Group by Employee_ID Having COUNT(*)>1),\n",
    "-- 2. AHT Raw ðŸ“\n",
    "AHT_Raw1 as\n",
    "(Select  [Agent Name Display]+cast([Date] AS varchar)+[Answered Language Name]+[Measure Names] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.AHT2\n",
    "Where    [Agent Name Display]+cast([Date] AS varchar)+[Answered Language Name]+[Measure Names] Is not Null\n",
    "Group by [Agent Name Display]+cast([Date] AS varchar)+[Answered Language Name]+[Measure Names] Having COUNT(*)>1),\n",
    "-- 3. Capacity HC ðŸ“\n",
    "CapacityHC_Raw1 as\n",
    "(Select  [LOB]+cast([Date] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CapHC\n",
    "Where    [LOB]+cast([Date] as varchar) is not Null\n",
    "Group by [LOB]+cast([Date] as varchar) Having COUNT(*)>1),\n",
    "-- 4. CSAT Raw ðŸ“\n",
    "CSAT_Raw1 as\n",
    "(Select  cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CSAT_TP\n",
    "Where    cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] is not Null\n",
    "Group by cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] Having COUNT(*)>1),\n",
    "-- 5. CSAT Reso Raw ðŸ“\n",
    "CSAT_Reso_Raw as\n",
    "(Select  cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CSAT_RS\n",
    "Where    cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] is not Null\n",
    "Group by cast([Sort by Dimension] as varchar)+[Staff]+[Type]+[Team]+[Survey Id]+[Reservation]+[Channel]+[Topic of the first Ticket]+[Language]+[Csat 2.0 Score] Having COUNT(*)>1),\n",
    "-- 6. CUIC Raw ðŸ“\n",
    "CUIC_Raw1 as\n",
    "(Select [FullName]+[LoginName]+cast([Interval] as varchar)+cast([AgentLoggedOnTime] as varchar)+cast([AgentAvailTime] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CUIC\n",
    "Where    [FullName]+[LoginName]+cast([Interval] as varchar)+cast([AgentLoggedOnTime] as varchar)+cast([AgentAvailTime] as varchar) is not Null\n",
    "Group by [FullName]+[LoginName]+cast([Interval] as varchar)+cast([AgentLoggedOnTime] as varchar)+cast([AgentAvailTime] as varchar) Having COUNT(*)>1),\n",
    "-- 7. EEAAO ðŸ“\n",
    "\n",
    "-- 8. EPS Raw ðŸ“\n",
    "EPS_Raw1 as\n",
    "(Select  [Username]+cast([Session Login] as varchar)+cast([Session Logout] as varchar)+[BPE Code]+[Session Time]+cast([Total Time] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.EPS\n",
    "Where    [Username]+cast([Session Login] as varchar)+cast([Session Logout] as varchar)+[BPE Code]+[Session Time]+cast([Total Time] as varchar) is not Null\n",
    "Group by [Username]+cast([Session Login] as varchar)+cast([Session Logout] as varchar)+[BPE Code]+[Session Time]+cast([Total Time] as varchar) Having COUNT(*)>1),\n",
    "-- 9. Exception Req ðŸ“\n",
    "Exception_Req as\n",
    "(Select [Emp ID]+cast([Date (MM/DD/YYYY)] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From BCOM.ExceptionReq\n",
    "Where [Emp ID]+cast([Date (MM/DD/YYYY)] as varchar) is not null\n",
    "Group by [Emp ID]+cast([Date (MM/DD/YYYY)] as varchar) Having COUNT(*)>1),\n",
    "-- 10. HC Transfer ðŸ“\n",
    "HC_Transfer as\n",
    "(Select  [EID]+cast([LWD] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.LTTransfers\n",
    "Where    [EID]+cast([LWD] as varchar) is not Null\n",
    "Group by [EID]+cast([LWD] as varchar) Having COUNT(*)>1),\n",
    "-- 11. Holiday Raw ðŸ“\n",
    "Holiday_Raw1 as\n",
    "(Select cast([Date] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From GLB.PremHdays\n",
    "Group by cast([Date] as varchar) Having COUNT(*)>1),\n",
    "-- 12. IEX Raw ðŸ“\n",
    "\n",
    "-- 13. IntervalReq_Raw1 ðŸ“\n",
    "IntervalReq_Raw1 as\n",
    "(Select  [LOB]+cast([Datetime_VN] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.IntervalReq\n",
    "Where    [LOB]+cast([Datetime_VN] as varchar) is not Null\n",
    "Group by [LOB]+cast([Datetime_VN] as varchar) Having COUNT(*)>1),\n",
    "-- 14. KPI Targer (LOB) ðŸ“\n",
    "LOB_Tar as\n",
    "(Select  cast([Week] as varchar)+[LOB]+[Tenure days] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.KPI_Target\n",
    "Where    cast([Week] as varchar)+[LOB]+[Tenure days] is not Null\n",
    "Group by cast([Week] as varchar)+[LOB]+[Tenure days] Having COUNT(*)>1),\n",
    "-- 15. KPI Targer (LOB Group) ðŸ“\n",
    "LOBGR_Tar as\n",
    "(Select  cast([Week] as varchar)+[LOB Group]+[Tenure days] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.KPI_Target\n",
    "where    cast([Week] as varchar)+[LOB Group]+[Tenure days] is not Null And [LOB] is Null\n",
    "Group by cast([Week] as varchar)+[LOB Group]+[Tenure days] Having COUNT(*)>1),\n",
    "-- 16. Logout Count ðŸ“\n",
    "LOGOUT_COUNT as\n",
    "(Select  [Aggregation]+cast([TimeDimension] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.LogoutCount\n",
    "Where    [Aggregation]+cast([TimeDimension] as varchar) is not Null\n",
    "Group by [Aggregation]+cast([TimeDimension] as varchar) Having COUNT(*)>1),\n",
    "-- 17. OT Ramco ðŸ“\n",
    "OT_Ramco as\n",
    "(Select  cast([Date] as varchar)+[employee_code]+[OT Type] as [Concat], COUNT(*) as [Count]\n",
    "From     GLB.OT_RAMCO\n",
    "Where    cast([Date] as varchar)+[employee_code]+[OT Type] is not Null\n",
    "Group by cast([Date] as varchar)+[employee_code]+[OT Type] Having COUNT(*)>1),\n",
    "-- 18. OverTime Raw ðŸ“\n",
    "OverTime_Raw1 as\n",
    "(Select  cast([Date] as varchar)+[Emp ID] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.RegisteredOT\n",
    "WHere    cast([Date] as varchar)+[Emp ID] is not Null\n",
    "Group by cast([Date] as varchar)+[Emp ID] Having COUNT(*)>1),\n",
    "-- 19. PSAT ðŸ“\n",
    "PSAT_Raw1 as\n",
    "(Select  cast([Date] as varchar)+[Survey Id]+[Has Comment]+[Channel]+[Final Topics] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.PSAT\n",
    "Where    cast([Date] as varchar)+[Survey Id]+[Has Comment]+[Channel]+[Final Topics] Is not Null\n",
    "Group by cast([Date] as varchar)+[Survey Id]+[Has Comment]+[Channel]+[Final Topics] Having COUNT(*)>1),\n",
    "-- 20. Quality_Raw1 ðŸ“\n",
    "Quality_Raw1 as\n",
    "(Select  cast([eval_date] as varchar)+[eval_id]+[agent_username]+[final_question_grouping]+[sections]+[template_group]+[csat_satisfied]+[tix_final_subtopic]+cast([score_n] as varchar)+cast([score_question_weight] as varchar)+[eval_language]+[eval_reference]+[csat_language_code]+[tix_final_topic] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.Quality\n",
    "Where    cast([eval_date] as varchar)+[eval_id]+[agent_username]+[final_question_grouping]+[sections]+[template_group]+[csat_satisfied]+[tix_final_subtopic]+cast([score_n] as varchar)+cast([score_question_weight] as varchar)+[eval_language]+[eval_reference]+[csat_language_code]+[tix_final_topic] Is not Null\n",
    "Group by cast([eval_date] as varchar)+[eval_id]+[agent_username]+[final_question_grouping]+[sections]+[template_group]+[csat_satisfied]+[tix_final_subtopic]+cast([score_n] as varchar)+cast([score_question_weight] as varchar)+[eval_language]+[eval_reference]+[csat_language_code]+[tix_final_topic] Having COUNT(*)>1),\n",
    "-- 21. Ramco Raw ðŸ“\n",
    "Ramco_Raw1 as\n",
    "(Select  cast([Date] as varchar)+[EID] as [Concat], COUNT(*) as [Count]\n",
    "From     GLB.RAMCO\n",
    "Where    cast([Date] as varchar)+[EID] is not Null\n",
    "Group by cast([Date] as varchar)+[EID] Having COUNT(*)>1),\n",
    "-- 22. RamUp HC ðŸ“\n",
    "\n",
    "-- 23. Requirement Hours ðŸ“\n",
    "Requirement_Hours as\n",
    "(Select  [LOB]+cast([Date] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.DailyReq\n",
    "Where    [LOB]+cast([Date] as varchar) is not Null\n",
    "Group by [LOB]+cast([Date] as varchar) Having COUNT(*)>1),\n",
    "-- 24. Resignation Dump ðŸ“\n",
    "Resignation_Dump as\n",
    "(Select [Employee ID], COUNT(*) as [Count]\n",
    "From GLB.Resignation\n",
    "Group by [Employee ID] Having COUNT(*)>1),\n",
    "-- 25. RONA ðŸ“\n",
    "RONA_Raw1 as\n",
    "(Select  [Agent]+cast([RONA] as varchar)+cast([DateTime] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.RONA\n",
    "where    [Agent]+cast([RONA] as varchar)+cast([DateTime] as varchar) is not null\n",
    "Group by [Agent]+cast([RONA] as varchar)+cast([DateTime] as varchar) Having COUNT(*)>1),\n",
    "-- 26. Roster Raw ðŸ“\n",
    "Roster_Raw as\n",
    "(Select [Emp ID]+cast([Attribute] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From BCOM.ROSTER\n",
    "Where [Emp ID]+cast([Attribute] as varchar) is not Null\n",
    "Group by [Emp ID]+cast([Attribute] as varchar) Having COUNT(*)>1),\n",
    "-- 27. SC Labels ðŸ“\n",
    "\n",
    "-- 28. Shrinkage Target ðŸ“\n",
    "Shrinkage_Target as\n",
    "(Select  [LOB]+cast([Week] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.ProjectedShrink\n",
    "Where    [LOB]+cast([Week] as varchar) is not Null\n",
    "Group by [LOB]+cast([Week] as varchar) Having COUNT(*)>1),\n",
    "-- 29. Termination Dump ðŸ“\n",
    "Termination_Dump as\n",
    "(Select [EMPLOYEE_ID]+cast([Termination Date] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From GLB.Termination\n",
    "Where [EMPLOYEE_ID]+cast([Termination Date] as varchar) is not Null\n",
    "Group by [EMPLOYEE_ID]+cast([Termination Date] as varchar) Having COUNT(*)>1),\n",
    "-- 30. Ticket Raw ðŸ“\n",
    "Ticket_Raw1 as\n",
    "(Select  cast([Date] as varchar)+[Staff Name]+cast([Hour Interval Selected] as varchar)+[Channel]+[Item Label]+[Item ID]+['Item ID']+[Time Alert]+cast([Nr. Contacts] as varchar)+[Item Link]+[Time] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CPI\n",
    "Where    cast([Date] as varchar)+[Staff Name]+cast([Hour Interval Selected] as varchar)+[Channel]+[Item Label]+[Item ID]+['Item ID']+[Time Alert]+cast([Nr. Contacts] as varchar)+[Item Link]+[Time] is not Null\n",
    "Group by cast([Date] as varchar)+[Staff Name]+cast([Hour Interval Selected] as varchar)+[Channel]+[Item Label]+[Item ID]+['Item ID']+[Time Alert]+cast([Nr. Contacts] as varchar)+[Item Link]+[Time] Having COUNT(*)>1),\n",
    "-- 31. Workplan Raw ðŸ“\n",
    "Workplan_Raw1 as\n",
    "(Select  [LOB]+[ID]+cast([DateTime_Act_Start] as varchar)+cast([DateTime_Act_End] as varchar)+cast([Act_Dur] as varchar)+[Action] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.WpDetail\n",
    "Where    [LOB]+[ID]+cast([DateTime_Act_Start] as varchar)+cast([DateTime_Act_End] as varchar)+cast([Act_Dur] as varchar)+[Action] is not Null\n",
    "Group by [LOB]+[ID]+cast([DateTime_Act_Start] as varchar)+cast([DateTime_Act_End] as varchar)+cast([Act_Dur] as varchar)+[Action] Having COUNT(*)>1),\n",
    "-- 32. Workplan Summary Raw ðŸ“\n",
    "Workplan_Summary as\n",
    "(Select  cast([Date] as varchar)+[LOB]+[Agent ID]+[Agent Name]+[Scheduled Activity]+cast([Length] as varchar)+cast([Percent] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.WpSummary\n",
    "Where    cast([Date] as varchar)+[LOB]+[Agent ID]+[Agent Name]+[Scheduled Activity]+cast([Length] as varchar)+cast([Percent] as varchar) is not Null\n",
    "Group by cast([Date] as varchar)+[LOB]+[Agent ID]+[Agent Name]+[Scheduled Activity]+cast([Length] as varchar)+cast([Percent] as varchar) Having COUNT(*)>1),\n",
    "-- 33. CSAT PEGA ðŸ“\n",
    "\n",
    "-- 34. IPH PEGA ðŸ“\n",
    "IPH_PEGA as\n",
    "(Select  cast([Day of Date] as varchar)+[Staff Name]+[Operator Def]+[Service Case Type New]+[Channel Def]+[Reason For No Service Case]+[Topic Def New]+[Subtopics]+[Case Id]+[Reservation Id Def]+cast([# Swivels] as varchar)+cast([Count of ServiceCase or Interaction] as varchar) as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.CPI_PEGA\n",
    "Where    cast([Day of Date] as varchar)+[Staff Name]+[Operator Def]+[Service Case Type New]+[Channel Def]+[Reason For No Service Case]+[Topic Def New]+[Subtopics]+[Case Id]+[Reservation Id Def]+cast([# Swivels] as varchar)+cast([Count of ServiceCase or Interaction] as varchar)  is not Null\n",
    "Group by cast([Day of Date] as varchar)+[Staff Name]+[Operator Def]+[Service Case Type New]+[Channel Def]+[Reason For No Service Case]+[Topic Def New]+[Subtopics]+[Case Id]+[Reservation Id Def]+cast([# Swivels] as varchar)+cast([Count of ServiceCase or Interaction] as varchar)  Having COUNT(*)>1),\n",
    "-- 35. Agents Raw(TEDNAME) ðŸ“\n",
    "TEDNAME as\n",
    "(Select [TED Name], COUNT(*) as [Count]\n",
    "From BCOM.Staff where [TED Name] IS NOT NULL\n",
    "Group by [TED Name] Having COUNT(*)>1),\n",
    "-- 36. OTREQ ðŸ“\n",
    "OTREQ as\n",
    "(Select  cast([Date] as varchar)+[LOB]+[Type] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.OTReq\n",
    "Where    cast([Date] as varchar)+[LOB]+[Type] is not Null\n",
    "Group by cast([Date] as varchar)+[LOB]+[Type] Having COUNT(*)>1),\n",
    "-- 37. PROHC ðŸ“\n",
    "PROHC as\n",
    "(Select  cast([Date] as varchar)+[LOB] as [Concat], COUNT(*) as [Count]\n",
    "From     BCOM.ProjectedHC\n",
    "Where    cast([Date] as varchar)+[LOB] is not Null\n",
    "Group by cast([Date] as varchar)+[LOB] Having COUNT(*)>1)\n",
    "--\n",
    "--------------------------------------------------------[Nvidia]Prcess---------------------------------------------------------------\n",
    "--\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Agents_Raw1\n",
    "Select    '01' as [No.],    Count(*) as [CheckDup],    'Agents Raw' as [Table]            ,    'IMPORTANT' as [Note]\n",
    "From       Agents_Raw1                    UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   AHT_Raw1\n",
    "Select    '02' as [No.],    Count(*) as [CheckDup],    'AHT Raw' as [Table]               ,    '' as [Note]\n",
    "From       AHT_Raw1                       UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   CapacityHC_Raw1\n",
    "Select    '03' as [No.],    Count(*) as [CheckDup],    'Capacity HC' as [Table]           ,    '' as [Note]\n",
    "From       CapacityHC_Raw1                UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   CSAT_Raw1\n",
    "Select    '04' as [No.],    Count(*) as [CheckDup],    'CSAT Raw' as [Table]              ,    '' as [Note]\n",
    "From       CSAT_Raw1                      UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   CSAT_Reso_Raw\n",
    "Select    '05' as [No.],    Count(*) as [CheckDup],    'CSAT Reso Raw' as [Table]         ,    '' as [Note]\n",
    "From       CSAT_Reso_Raw                 UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   CUIC_Raw1\n",
    "Select    '06' as [No.],    Count(*) as [CheckDup],    'CUIC Raw' as [Table]              ,    '' as [Note]\n",
    "From       CUIC_Raw1                      UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   EPS_Raw1\n",
    "Select    '08' as [No.],    Count(*) as [CheckDup],    'EPS Raw' as [Table]               ,    '' as [Note]\n",
    "From       EPS_Raw1                       UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Exception_Req\n",
    "Select    '09' as [No.],    Count(*) as [CheckDup],    'Exception Req' as [Table]         ,    '' as [Note]\n",
    "From       Exception_Req                 UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   HC_Transfer\n",
    "Select    '10' as [No.],    Count(*) as [CheckDup],    'HC Transfer' as [Table]           ,    '' as [Note]\n",
    "From       HC_Transfer                   UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Holiday_Raw1\n",
    "Select    '11' as [No.],    Count(*) as [CheckDup],    'Holiday Raw' as [Table]           ,    '' as [Note]\n",
    "From       Holiday_Raw1                   UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   IntervalReq_Raw1\n",
    "Select    '13' as [No.],    Count(*) as [CheckDup],    'IntervalReq' as [Table]       ,    'IMPORTANT' as [Note]\n",
    "From       IntervalReq_Raw1               UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   LOB_Tar\n",
    "Select    '14' as [No.],    Count(*) as [CheckDup],    'KPI Targer (LOB)' as [Table]      ,    'IMPORTANT' as [Note]\n",
    "From       LOB_Tar                       UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   LOBGR_Tar\n",
    "Select    '15' as [No.],    Count(*) as [CheckDup],    'KPI Targer (LOB Group)' as [Table],    'IMPORTANT' as [Note]\n",
    "From       LOBGR_Tar                     UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   LOGOUT_COUNT\n",
    "Select    '16' as [No.],    Count(*) as [CheckDup],    'Logout Count' as [Table]          ,    'IMPORTANT' as [Note]\n",
    "From       LOGOUT_COUNT                  UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   OT_Ramco\n",
    "Select    '17' as [No.],    Count(*) as [CheckDup],    'OT Ramco' as [Table]              ,    'IMPORTANT' as [Note]\n",
    "From       OT_Ramco                      UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   OverTime_Raw1\n",
    "Select    '18' as [No.],    Count(*) as [CheckDup],    'OverTime Raw' as [Table]          ,    'IMPORTANT' as [Note]\n",
    "From       OverTime_Raw1                  UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   PSAT_Raw1\n",
    "Select    '19' as [No.],    Count(*) as [CheckDup],    'PSAT' as [Table]                  ,    '' as [Note]\n",
    "From       PSAT_Raw1                      UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Quality_Raw1\n",
    "Select    '20' as [No.],    Count(*) as [CheckDup],    'Quality_Raw' as [Table]           ,    '' as [Note]\n",
    "From       Quality_Raw1                   UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Ramco_Raw1\n",
    "Select    '21' as [No.],    Count(*) as [CheckDup],    'Ramco Raw' as [Table]             ,    'IMPORTANT' as [Note]\n",
    "From       Ramco_Raw1                     UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Requirement_Hours\n",
    "Select    '23' as [No.],    Count(*) as [CheckDup],    'Daily Requirement' as [Table]     ,    'IMPORTANT' as [Note]\n",
    "From       Requirement_Hours             UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Resignation_Dump\n",
    "Select    '24' as [No.],    Count(*) as [CheckDup],    'Resignation Dump' as [Table]      ,    '' as [Note]\n",
    "From       Resignation_Dump              UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   RONA_Raw1\n",
    "Select    '25' as [No.],    Count(*) as [CheckDup],    'RONA' as [Table]                  ,    '' as [Note]\n",
    "From       RONA_Raw1                      UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Roster_Raw\n",
    "Select    '26' as [No.],    Count(*) as [CheckDup],    'Roster Raw' as [Table]            ,    'IMPORTANT' as [Note]\n",
    "From       Roster_Raw                    UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Shrinkage_Target\n",
    "Select    '28' as [No.],    Count(*) as [CheckDup],    'Shrinkage Target' as [Table]      ,    '' as [Note]\n",
    "From       Shrinkage_Target              UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Termination_Dump\n",
    "Select    '29' as [No.],    Count(*) as [CheckDup],    'Termination Dump' as [Table]      ,    '' as [Note]\n",
    "From       Termination_Dump              UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Ticket_Raw1\n",
    "Select    '30' as [No.],    Count(*) as [CheckDup],    'Ticket Raw' as [Table]            ,    '' as [Note]\n",
    "From       Ticket_Raw1                    UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Workplan_Raw1\n",
    "Select    '31' as [No.],    Count(*) as [CheckDup],    'Workplan Raw' as [Table]          ,    '' as [Note]\n",
    "From       Workplan_Raw1                  UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   Workplan_Summary\n",
    "Select    '32' as [No.],    Count(*) as [CheckDup],    'Workplan Summary Raw' as [Table]  ,    '' as [Note]\n",
    "From       Workplan_Summary              UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   IPH_PEGA\n",
    "Select    '34' as [No.],    Count(*) as [CheckDup],    'IPH_PEGA' as [Table]              ,    '' as [Note]\n",
    "From       IPH_PEGA                     UNION ALL     \n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   TED Name\n",
    "Select    '35' as [No.],    Count(*) as [CheckDup],    'TEDNAME' as [Table]              ,    'IMPORTANT' as [Note]\n",
    "From       TEDNAME                      UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   TED Name\n",
    "Select    '36' as [No.],    Count(*) as [CheckDup],    'OTREQ' as [Table]              ,      'IMPORTANT' as [Note]\n",
    "From       OTREQ                        UNION ALL\n",
    "------[ðŸ“¥]--(ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰                   TED Name\n",
    "Select    '37' as [No.],    Count(*) as [CheckDup],    'PROHC' as [Table]              ,      'IMPORTANT' as [Note]\n",
    "From       PROHC\n",
    "--          \n",
    "\"\"\"\n",
    "# Äá»c dá»¯ liá»‡u vÃ o DataFrame\n",
    "Code2_Result = pl.read_database(query=sql_query2, connection=engine)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1671ae9a-9f1f-4c69-baf6-6dd256add201",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#DEFINITION ðŸŒðŸŒðŸŒ\n",
    "#Name Pattern definition\n",
    "def Namepattern(folder_name):\n",
    "    match folder_name:\n",
    "        case \"Staff\":\n",
    "            pattern = r\"CNX Global Master Roster.xlsx\"\n",
    "        case \"ProjectedShrink\":\n",
    "            pattern = r\"IO Shrinkage.xlsx\"\n",
    "        case \"LTTransfers\":\n",
    "            pattern = r\"transfer.xlsx\"\n",
    "        case \"KPI_Target\":\n",
    "            pattern = r\"kpi_target.xlsx\"\n",
    "        case \"EPS\":\n",
    "            pattern = r\"EPS Tableau - (\\d{8})\\.csv\"\n",
    "        case \"DailyReq\":\n",
    "            pattern = r\"(\\d{6})(_(\\d{6}))?\\..{4}\"\n",
    "        case \"IntervalReq\":\n",
    "            pattern = r\"(\\d{6,8})(_(\\d{6,8}))?\\..{4}\"   \n",
    "        case \"Contrack\":\n",
    "        \n",
    "            pattern = r\"(\\[WFM\\] Contact Tracker|WFM_Contact Tracker|WFM Contact Tracker|(\\d{8})(_(\\d{8}))?|W(\\d{2})-(\\d{4}))\\..{4}\"  \n",
    "        case \"CapHC\":\n",
    "            pattern = r\"(\\d{4})(_(\\d{4}))?\\..{4}\"  \n",
    "        case \"AHT\":\n",
    "            pattern = r\"(\\d{8})_(\\d{8})_(...)?phone\\..{3}\"  \n",
    "        case \"Termination\":\n",
    "            pattern = r\"WDD.xlsx\" \n",
    "        case \"Resignation\":\n",
    "            pattern = r\"WDD.xlsx\" \n",
    "        case \"PremHdays\":\n",
    "            pattern = r\"Holiday Mapping.csv\" \n",
    "        case \"NormHdays\":\n",
    "            pattern = r\"Holiday Nonbillable.csv\"\n",
    "        case \"EmpMaster\":\n",
    "            pattern = r\"WDD.xlsx\"\n",
    "        case \"CUIC_RTMonitor\":\n",
    "            pattern = r\"00_RTA_View-Agent Team Real Time.xlsx\"\n",
    "        case \"CUIC\":\n",
    "            pattern = r\"(\\d{4,8})_(\\d{2,8})(_(\\d{2}))?(_\\d)?\\..{4}\"\n",
    "        case \"WpSummary\":\n",
    "            pattern = r\"(\\d{4})-(\\d{2})\"\n",
    "        case \"WpDetail\":\n",
    "            pattern = r\"(\\d{4})-(\\d{2})\"\n",
    "        case \"IEX_Hrs\":\n",
    "            pattern = r\"(\\d{4})-(\\d{2})\"\n",
    "        case _:\n",
    "            pattern = r\"(\\d{8})(_(\\d{8}))?\\..{3,4}\"\n",
    "    return pattern\n",
    "\n",
    "#table1 from code 1\n",
    "Folder_column_name = 'FOLDER NAME'\n",
    "Name_Coumn_name = 'FileName - ModifiedDate'\n",
    "Row_column_name = 'ROW_NUMBER'\n",
    "#table2 from code 2\n",
    "important_column= 'Note'\n",
    "Check_dup_column = 'CheckDup'\n",
    "Table_column = 'Table'\n",
    "#log file that we read\n",
    "Error_log_column ='Error'\n",
    "Log_name_column='FileName'\n",
    "\n",
    "\n",
    "#Color code\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    FAILVIOLET = '\\033[35m'\n",
    "\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28bd9dcc-642a-47dc-a570-e74eb48831e9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ðŸ“Exception list, use it to ignore a file that has been confirmed OKðŸ“\n",
    "\n",
    "#Exception for inconsistent row\n",
    "Expection_list_checkrow=[\n",
    "    \"EPS Tableau - 20240831\",\n",
    "    \"20231001_20231231\",\n",
    "    \"20250330\",\"20250421\",\n",
    "    \"20220919_20230930\",\n",
    "    \"20250331_20250406\",\n",
    "    \"20250515\",\"20250516\",\"20250517\",\n",
    "    \"EPS Tableau - 20241229\",\n",
    "    \"20240101_20250223\",    \n",
    "    \"20220919_20231231\",\n",
    "    \"20230101_20231231\",\n",
    "    \"W29-2025\",\n",
    "    \"20250803\"\n",
    "    ]\n",
    "Expection_list_checkupdate=[\n",
    "    \"20240101_20250223\",\n",
    "    \"20250224_20250302\"\n",
    "]\n",
    "\n",
    "Expection_list_checkmissing=[\n",
    "    \"[WFM] Contact Tracker\",\n",
    "    \"20220919_20230930\",\n",
    "    \"20231001_20231231\",\n",
    "    \"20240101_20240630\",\n",
    "    \"20240701_20241229\",\n",
    "    \"20221231\",\n",
    "    \"20230630\",\n",
    "    \"20230930\",\n",
    "    \"20231231\",\n",
    "    \"20240430\",\n",
    "    \"20240831\",\n",
    "    \"20241229\",\n",
    "    \"20240101_20241231_nonphone\", \n",
    "    \"20240101_20241231_phone\",\n",
    "    \"20250101_20250629\",\n",
    "    \"20220919_20231231\",\n",
    "    \"20240101_20241231\",\n",
    "    \"20250101_20250622\"\n",
    "]\n",
    "\n",
    "ROSTER_FIRST_FILE = \"20250623_20250629\"\n",
    "WP_FIRST_FILE=\"2025-23\"\n",
    "CPI_FIRST_FILE ='20250101'\n",
    "EPS_FIRST_FILE ='20250105'\n",
    "AHT_FIRST_FILE = \"20250101_20250131\"\n",
    "Exception_pattern = r\"\\..{3,4}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80d377a7-5a02-4995-b3f7-f98d76c80d72",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Func Compare row with non pattern file name\n",
    "def Row_Compare_Special(Dataframe,Extract_file):\n",
    "    rowdata = Dataframe[Row_column_name].to_list()\n",
    "    # Standard Deviation Math\n",
    "    mean = statistics.mean(rowdata)  \n",
    "    std_dev = statistics.stdev(rowdata) \n",
    "#Tweak the sensitivity of the comparison, lower = more strict\n",
    "    tolerance = 2.5\n",
    "    catch_list=[]\n",
    "    for row in rowdata:\n",
    "         distance = abs(row -mean)\n",
    "         if distance > tolerance * std_dev:\n",
    "              catch_list.append(row)\n",
    "\n",
    "              \n",
    "    if not(catch_list):\n",
    "         return\n",
    "\n",
    "    # Filter the file has been mark out\n",
    "    Sus_file = Dataframe.filter(pl.col(Row_column_name).is_in(catch_list))\n",
    "    for row in Sus_file.iter_rows(named= True):\n",
    "        check =re.split(Exception_pattern,row[Name_Coumn_name])\n",
    "        if check[0] not in Expection_list_checkrow:\n",
    "            Extract_file.append((row[Name_Coumn_name],row[Folder_column_name],\"Inconsistent row\"))\n",
    "            print(f'{bcolors.WARNING}File {row[Name_Coumn_name]} in {row[Folder_column_name]} has inconsistent number of rows {bcolors.ENDC}')\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "44f5c4b1-8cae-458a-a739-3878eb203b86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Func Compare Row with pattern file name\n",
    "def Row_Compare(Dataframe,Extract_file,Folder):\n",
    "    desired_pattern = r\"(\\d{8})_(\\d{8})\"\n",
    "    FilteredDataframe= Dataframe.sort(Name_Coumn_name,descending=False)\n",
    "    rowdivdate =[]\n",
    "    namefilter=[]\n",
    "    row_avg = []\n",
    "    #calculate average number for row in one day we should expected\n",
    "    for row  in FilteredDataframe.iter_rows(named= True):\n",
    "         \n",
    "        match = re.match(desired_pattern,row[Name_Coumn_name])\n",
    "        start_date_string,end_date_start_date_string = match.groups()\n",
    "        try:\n",
    "            start_date = dt.strptime(start_date_string,\"%Y%m%d\").date()\n",
    "            end_date = dt.strptime(end_date_start_date_string,\"%Y%m%d\").date()\n",
    "            #average number of rows should have per day\n",
    "            namefilter.append(row[Name_Coumn_name])\n",
    "            row_avg.append((row[Row_column_name]/((end_date - start_date).days)))\n",
    "        \n",
    "        #Find out if file has the same start date and end date  \n",
    "        except ZeroDivisionError:\n",
    "            print(f\"{bcolors.OKBLUE}File {row[Name_Coumn_name]} in {Folder} has the same start and end date{bcolors.ENDC}\")\n",
    "            Extract_file.append((row[Name_Coumn_name],Folder,\"Same Start and End date\"))\n",
    "            continue\n",
    "\n",
    "    namefilter_series = pl.Series(\"File_name\", namefilter)\n",
    "    row_avg_series = pl.Series(\"Average_Row\", row_avg)\n",
    "    #If none calculated, return\n",
    "    if len(namefilter)<2:\n",
    "        return\n",
    "\n",
    "     #Create Dataframe\n",
    "\n",
    "    dffinal = pl.DataFrame([namefilter_series,row_avg_series])\n",
    "    rowdata = dffinal['Average_Row'].to_list()\n",
    "    # Standard Deviation Math\n",
    "    mean = statistics.mean(rowdata)  \n",
    "    std_dev = statistics.stdev(rowdata) \n",
    "    #Tweak the sensitivity of the comparison, lower = more strict\n",
    "    tolerance = 2.5\n",
    "    catch_list=[]\n",
    "\n",
    "    for row in rowdata:\n",
    "        distance = abs(row -mean)\n",
    "        if distance > tolerance * std_dev:\n",
    "            catch_list.append(row)\n",
    "\n",
    "    \n",
    "    if not(catch_list):\n",
    "        return\n",
    "     \n",
    "     # Filter the file has been mark out\n",
    "    Sus_file = dffinal.filter(pl.col('Average_Row').is_in(catch_list))\n",
    "    for row in Sus_file.iter_rows(named= True):\n",
    "        check =re.split(Exception_pattern,row['File_name'])\n",
    "        if check[0] not in Expection_list_checkrow:\n",
    "            Extract_file.append((row['File_name'],Folder,\"Inconsistent average row\"))\n",
    "            print(f'{bcolors.FAIL}File {row['File_name']} in {Folder} has inconsistent number of rows {bcolors.ENDC}')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21138fed-212b-4927-9cd7-55606f0ffb85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Func Duplicate date check\n",
    "def Duplicate_Date_Check(list_name,extract_list,folder):\n",
    "    file_ranges = []\n",
    "    Valid_list = []\n",
    "    desired_pattern = r\"(\\d{8})_(\\d{8})\"\n",
    "    \n",
    "    for file_name in list_name:\n",
    "        match = re.match(desired_pattern,file_name)\n",
    "        if match:\n",
    "                start_date_string,end_date_start_date_string = match.groups()\n",
    "                try:\n",
    "                    start_date = dt.strptime(start_date_string,\"%Y%m%d\").date()\n",
    "                    end_date = dt.strptime(end_date_start_date_string,\"%Y%m%d\").date()\n",
    "                    #Put date into a list to compare\n",
    "                    file_ranges.append((start_date,end_date,file_name))\n",
    "                    # Valid file will be use to further check\n",
    "                    Valid_list.append(file_name)\n",
    "                except ValueError:\n",
    "                    print(f\"{bcolors.OKBLUE} {file_name} has invalid name format in {folder}, cannot compare date for further check{bcolors.ENDC}\")\n",
    "\n",
    "    file_ranges.sort()\n",
    "    \n",
    "    for i in range(len(file_ranges)):\n",
    "        start_i, end_i, file_i = file_ranges[i]\n",
    "        overlap_count =0\n",
    "        for j in range(len(file_ranges)):\n",
    "            if i!= j:\n",
    "                start_j, end_j, file_j = file_ranges[j]\n",
    "                if folder == 'AHT' and file_i==file_j:\n",
    "                    extract_list.append((file_i,folder,\"Duplicate file\"))\n",
    "                    print(f'{bcolors.FAIL}Duplicate date file: {file_i}{bcolors.ENDC}')\n",
    "                    break\n",
    "                #Check if current file is totally in another file\n",
    "                if start_j <= start_i <= end_j and start_j <= end_i <= end_j and folder !='AHT':\n",
    "                    extract_list.append((file_i,folder,\"Duplicate file\"))\n",
    "                    print(f'{bcolors.FAIL}Duplicate date file: {file_i}{bcolors.ENDC}')\n",
    "                else:\n",
    "                # Check if currentfile has a part in another file\n",
    "                    if start_i <= end_j and end_i >= start_j:\n",
    "                        overlap_count +=1\n",
    "                if overlap_count >=2:\n",
    "                    extract_list.append((file_i,folder,\"Has overlap days\"))\n",
    "                    print(f'{bcolors.WARNING}File might have issue with overlapping date: {file_i}{bcolors.ENDC}')\n",
    "\n",
    "                    break\n",
    "    \n",
    "    return Valid_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6c62518-41db-4bb3-a589-1b57e0a2c3b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:90: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:140: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:90: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:140: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\tungquan.le\\AppData\\Local\\Temp\\ipykernel_17632\\2289369839.py:90: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  checkyear = re.search('\\d{4}',clean_named[index-lingering])\n",
      "C:\\Users\\tungquan.le\\AppData\\Local\\Temp\\ipykernel_17632\\2289369839.py:140: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  checkyear = re.search('(\\d{8})_(\\d{8})',clean_named[index-lingering])\n"
     ]
    }
   ],
   "source": [
    "#Missing file check\n",
    "def Missing_File_check(list_name,extract_list,folder):\n",
    "    clean_named=[]\n",
    "#clear datetime modified from the file name, remove exception file\n",
    "    if folder == 'EPS':#entire new scenario for EPS\n",
    "        for name in list_name:\n",
    "            match = re.search(r'\\d{8}',name)\n",
    "            cleaned_date = match.group()\n",
    "            if cleaned_date not in Expection_list_checkmissing:\n",
    "                clean_named.append(cleaned_date)\n",
    "        \n",
    "    else: \n",
    "        for name in list_name:\n",
    "            split = re.split(Exception_pattern,name)\n",
    "            if split[0] not in Expection_list_checkmissing:\n",
    "                clean_named.append(split[0])\n",
    "                \n",
    "                \n",
    "    clean_named.sort()\n",
    "\n",
    "\n",
    "#sort and checking missing file\n",
    "    current_date =dt.now() \n",
    "    match folder:\n",
    "        case'WpDetail'|'WpSummary'|'IEX_Hrs':\n",
    "            #edit here if first file is differ follow format YYYY-WW â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
    "            first_file =  WP_FIRST_FILE\n",
    "\n",
    "            #check how many week between the first file and today (week 23 of 2025)\n",
    "            start_end_pattern = r'(\\d{4})-(\\d{2})'\n",
    "            matchformat = re.search(start_end_pattern,first_file)\n",
    "            year_string,weeknum_string = matchformat.groups()\n",
    "            fulldate = f'{year_string}-W{weeknum_string}'\n",
    "            reference_date = dt.strptime(fulldate+'-1',\"%Y-W%W-%w\")\n",
    "            number_of_week = math.floor((current_date-reference_date).days /7)\n",
    "            #lingering to make sure we didnt skip file that actual exist\n",
    "            lingering =0\n",
    "            for index in range(number_of_week+1):\n",
    "                    #if out of index, that's mean we missed alot of file so registered it\n",
    "                    try:\n",
    "                        if clean_named[index-lingering] != first_file:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                        #check the next file after the first file\n",
    "                        matchformat = re.search(Namepattern(folder),first_file)\n",
    "                        year_string,weeknum_string = matchformat.groups()\n",
    "                        weeknum_string = int(weeknum_string)+1\n",
    "                        #if over next year, increase year and reset week num\n",
    "                        if weeknum_string == 53:\n",
    "                            weeknum_string = 1\n",
    "                            year_string = int(year_string)+1\n",
    "                        if weeknum_string <10:\n",
    "                            first_file = f'{year_string}-0{weeknum_string}'\n",
    "\n",
    "                        else:\n",
    "                            first_file = f'{year_string}-{weeknum_string}'\n",
    "                        # senario where list is missing a lot of file and this will help the code continue to run\n",
    "                    except IndexError:\n",
    "                        print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                        extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                        matchformat = re.search(Namepattern(folder),first_file)\n",
    "                        year_string,weeknum_string = matchformat.groups()\n",
    "                        weeknum_string = int(weeknum_string)+1\n",
    "                        if weeknum_string == 53:\n",
    "                            weeknum_string = 1\n",
    "                            year_string = int(year_string)+1\n",
    "                        if weeknum_string <10:\n",
    "                            first_file = f'{year_string}-0{weeknum_string}'\n",
    "                        else:\n",
    "                            first_file = f'{year_string}-{weeknum_string}'\n",
    "                    continue\n",
    "        case 'CSAT_RS'|'OT_RAMCO'|'RAMCO'|'LogoutCount'|'PSAT'|'CPI_PEGA'|'CSAT_TP':\n",
    "            #edit here if first file is differ follow format YYYY-WW â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
    "            first_file = '20250101_20250131'\n",
    "\n",
    "            #check how many month between the first file and today (Jan of 2025)\n",
    "            start_end_pattern = r'(\\d{8})_(\\d{8})'\n",
    "            matchformat = re.search(start_end_pattern,first_file)\n",
    "            start_string,end_string = matchformat.groups()\n",
    "            start_string = dt.strptime(start_string,\"%Y%m%d\")\n",
    "            first_file_month= start_string.month\n",
    "            first_file_year= start_string.year\n",
    "            number_of_month = math.floor((current_date-start_string).days/30)\n",
    "            year_pass =0\n",
    "            lingering =0\n",
    "            for index in range(number_of_month+1):\n",
    "                try:\n",
    "                    #if file is not after first file year, bye bye\n",
    "                    checkyear = re.search('\\d{4}',clean_named[index-lingering])\n",
    "                    if int(checkyear.group(0))< first_file_year:     \n",
    "                        continue\n",
    "                    if clean_named[index-lingering] != first_file:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                    #if year is passing, we increase year pass and reset the month\n",
    "                    if first_file_month == 12:\n",
    "                         first_file_month = 1\n",
    "                         year_pass = year_pass+1\n",
    "                    else:\n",
    "                        first_file_month = first_file_month +1\n",
    "                    #get next file name\n",
    "                    firstday_month = dt(first_file_year+year_pass, first_file_month, 1)\n",
    "                    lastday_month = firstday_month + pd.offsets.MonthEnd(1)\n",
    "                    if first_file_month < 10:\n",
    "                        first_file = f'{firstday_month.year}0{firstday_month.month}01_{lastday_month.year}0{lastday_month.month}{lastday_month.day}'\n",
    "                    else:\n",
    "                        first_file = f'{firstday_month.year}{firstday_month.month}01_{lastday_month.year}{lastday_month.month}{lastday_month.day}'\n",
    "                     \n",
    "                   \n",
    "                except IndexError:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            if first_file_month == 12:\n",
    "                                first_file_month = 1\n",
    "                                year_pass = year_pass+1\n",
    "                            else:\n",
    "                                first_file_month = first_file_month +1\n",
    "                    #get next file name\n",
    "                            firstday_month = dt(first_file_year+year_pass, first_file_month, 1)\n",
    "                            lastday_month = firstday_month + pd.offsets.MonthEnd(1)\n",
    "                            if first_file_month < 10:\n",
    "                                first_file = f'{firstday_month.year}0{firstday_month.month}01_{lastday_month.year}0{lastday_month.month}{lastday_month.day}'\n",
    "                            else:\n",
    "                                first_file = f'{firstday_month.year}{firstday_month.month}01_{lastday_month.year}{lastday_month.month}{lastday_month.day}'\n",
    "                continue\n",
    "\n",
    "        case 'CPI':   \n",
    "            first_file = CPI_FIRST_FILE\n",
    "\n",
    "            #check how many date between the first file and today (01 Jan of 2025)\n",
    "\n",
    "            start_string = dt.strptime(first_file,\"%Y%m%d\")\n",
    "            number_of_dates = (current_date-start_string).days\n",
    "            lingering =0\n",
    "            for index in range(number_of_dates+1):\n",
    "                try:\n",
    "                    #if file is follow patter xxxxxxxx_xxxxxxxx, bye bye\n",
    "                    checkyear = re.search('(\\d{8})_(\\d{8})',clean_named[index-lingering])\n",
    "                    if checkyear:     \n",
    "                        continue\n",
    "                    #check for all file follow the date pattern \n",
    "                    if clean_named[index-lingering] != first_file:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                    #check next date\n",
    "                    checkdate = dt.strptime(first_file,\"%Y%m%d\")\n",
    "                    date_string = checkdate+timedelta(1)\n",
    "                    date_string = dt.strftime(date_string,\"%Y%m%d\")\n",
    "                    first_file = f'{date_string}'\n",
    "                     \n",
    "                   \n",
    "                except IndexError:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            checkdate = dt.strptime(first_file,\"%Y%m%d\")\n",
    "                            date_string = checkdate+timedelta(1)\n",
    "                            date_string = dt.strftime(date_string,\"%Y%m%d\")\n",
    "                            first_file = f'{date_string}'\n",
    "                            \n",
    "                continue\n",
    "        case 'EPS':   \n",
    "            first_file = EPS_FIRST_FILE\n",
    "\n",
    "            #check how many date between the first file and today (01 Jan of 2025)\n",
    "\n",
    "            start_string = dt.strptime(first_file,\"%Y%m%d\")\n",
    "            number_of_week = math.floor((current_date-start_string).days /7)\n",
    "\n",
    "            lingering =0\n",
    "            for index in range(number_of_week+1):\n",
    "                try:\n",
    "                    #check for all file follow the date pattern \n",
    "                    if clean_named[index-lingering] != first_file:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                    #check next date\n",
    "                    checkdate = dt.strptime(first_file,\"%Y%m%d\")\n",
    "                    date_string = checkdate+timedelta(7)\n",
    "                    date_string = dt.strftime(date_string,\"%Y%m%d\")\n",
    "                    first_file = f'{date_string}'\n",
    "                     \n",
    "                   \n",
    "                except IndexError:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            checkdate = dt.strptime(first_file,\"%Y%m%d\")\n",
    "                            date_string = checkdate+timedelta(7)\n",
    "                            date_string = dt.strftime(date_string,\"%Y%m%d\")\n",
    "                            first_file = f'{date_string}'\n",
    "                            \n",
    "                continue\n",
    "                \n",
    "        case 'ROSTER':\n",
    "\n",
    "            first_file = ROSTER_FIRST_FILE\n",
    "            #check how many month between the first file and today (Jan of 2025)\n",
    "            start_end_pattern = r'(\\d{8})_(\\d{8})'\n",
    "            matchformat = re.search(start_end_pattern,first_file)\n",
    "            start_string,end_string = matchformat.groups()\n",
    "            start_string = dt.strptime(start_string,\"%Y%m%d\")\n",
    "            end_string = dt.strptime(end_string,\"%Y%m%d\")\n",
    "            number_of_week = math.floor((current_date-start_string).days/7)\n",
    "            lingering =0\n",
    "            for index in range(number_of_week+1):\n",
    "                try:\n",
    "                    if clean_named[index-lingering] != first_file:\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                    #check next date week\n",
    "                    recheck = re.search(start_end_pattern,first_file)\n",
    "                    start_string,end_string = recheck.groups()\n",
    "                    start_string = dt.strptime(start_string,\"%Y%m%d\")\n",
    "                    end_string = dt.strptime(end_string,\"%Y%m%d\")\n",
    "                    start_string = start_string+timedelta(7)\n",
    "                    end_string = end_string+timedelta(7)\n",
    "                    start_string = dt.strftime(start_string,\"%Y%m%d\")\n",
    "                    end_string = dt.strftime(end_string,\"%Y%m%d\")\n",
    "                    first_file = f'{start_string}_{end_string}'\n",
    "                except IndexError:\n",
    "                    print(f\"{bcolors.FAILVIOLET}Missing {first_file} in folder {folder}{bcolors.ENDC}\")\n",
    "                    extract_list.append((first_file,folder,\"Missing file\"))\n",
    "                    #check next date week\n",
    "                    recheck = re.search(start_end_pattern,first_file)\n",
    "                    start_string,end_string = recheck.groups()\n",
    "                    start_string = dt.strptime(start_string,\"%Y%m%d\")\n",
    "                    end_string = dt.strptime(end_string,\"%Y%m%d\")\n",
    "                    start_string = start_string+timedelta(7)\n",
    "                    end_string = end_string+timedelta(7)\n",
    "                    start_string = dt.strftime(start_string,\"%Y%m%d\")\n",
    "                    end_string = dt.strftime(end_string,\"%Y%m%d\")\n",
    "                    first_file = f'{start_string}_{end_string}'                    \n",
    "                continue\n",
    "        case 'AHT':\n",
    "            first_file = AHT_FIRST_FILE\n",
    "            file_type = [\"_nonphone\",\"_phone\"]\n",
    "            #check how many month between the first file and today (Jan of 2025)\n",
    "            start_end_pattern = r'(\\d{8})_(\\d{8})'\n",
    "            matchformat = re.search(start_end_pattern,first_file)\n",
    "            start_string,end_string = matchformat.groups()\n",
    "            start_string = dt.strptime(start_string,\"%Y%m%d\")\n",
    "            first_file_month= start_string.month\n",
    "            first_file_year= start_string.year\n",
    "            number_of_month = math.floor((current_date-start_string).days/30)\n",
    "            year_pass= 0\n",
    "            lingering =0\n",
    "            for index in range(number_of_month+1):\n",
    "                try:\n",
    "                    if clean_named[index-lingering] != f'{first_file}{file_type[index%2]}':\n",
    "                            print(f\"{bcolors.FAILVIOLET}Missing {first_file}{file_type[index%2]} in folder {folder}{bcolors.ENDC}\")\n",
    "                            extract_list.append((f'{first_file}{file_type[index%2]}',folder,\"Missing file\"))\n",
    "                            lingering = lingering+1\n",
    "                    #check twice then increase\n",
    "                    if index%2 ==1:\n",
    "                    #if year is passing, we increase year pass and reset the month\n",
    "                        if first_file_month == 12:\n",
    "                            first_file_month = 1\n",
    "                            year_pass = year_pass+1\n",
    "                        else:\n",
    "                            first_file_month = first_file_month +1\n",
    "                        #get next file name\n",
    "                        firstday_month = dt(first_file_year+year_pass, first_file_month, 1)\n",
    "                        lastday_month = firstday_month + pd.offsets.MonthEnd(1)\n",
    "                        if first_file_month < 10:\n",
    "                            first_file = f'{firstday_month.year}0{firstday_month.month}01_{lastday_month.year}0{lastday_month.month}{lastday_month.day}'\n",
    "                        else:\n",
    "                            first_file = f'{firstday_month.year}{firstday_month.month}01_{lastday_month.year}{lastday_month.month}{lastday_month.day}'\n",
    "                    \n",
    "                except IndexError:\n",
    "                    print(f\"{bcolors.FAILVIOLET}Missing {first_file}{file_type[index%2]} in folder {folder}{bcolors.ENDC}\")\n",
    "                    extract_list.append((f'{first_file}{file_type[index%2]}',folder,\"Missing file\"))\n",
    "                    #check twice then increase\n",
    "\n",
    "                    if index%2 ==1:\n",
    "                    #if year is passing, we increase year pass and reset the month\n",
    "\n",
    "                        if first_file_month == 12:\n",
    "                            first_file_month = 1\n",
    "                            year_pass = year_pass+1\n",
    "                        else:\n",
    "                            first_file_month = first_file_month +1\n",
    "                        #get next file name\n",
    "                            firstday_month = dt(first_file_year+year_pass, first_file_month, 1)\n",
    "                            lastday_month = firstday_month + pd.offsets.MonthEnd(1)\n",
    "                        if first_file_month < 10:\n",
    "                            first_file = f'{firstday_month.year}0{firstday_month.month}01_{lastday_month.year}0{lastday_month.month}{lastday_month.day}'\n",
    "                        else:\n",
    "                            first_file = f'{firstday_month.year}{firstday_month.month}01_{lastday_month.year}{lastday_month.month}{lastday_month.day}'        \n",
    "                continue\n",
    "        case _:\n",
    "            print(f'{bcolors.OKCYAN}Skip {folder} for missing check {bcolors.ENDC}')\n",
    "            return\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d05ca292-406e-4c4a-ae14-c9efae7b1894",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Func Check update \n",
    "\n",
    "def File_need_update_check(list_name,extract_list,Folder):\n",
    "    #pattern to get the modified date\n",
    "    time_pattern = r\"(\\d{4})\\-(\\d{1,2})\\-(\\d{1,2})\"\n",
    "    current_date = dt.now()\n",
    "    #flag to report\n",
    "    Most_recent_CUIC_file = 1\n",
    "    Most_recent_EPS_file = 5\n",
    "    Most_recent_Quality_file = 5\n",
    "    Most_recent_WpDetail_file = 7\n",
    "    Prepresent_file = \"\"\n",
    "    How_Long_Prepresent_file_have_not_update=60\n",
    "    for name in list_name:\n",
    "        #Check last time file was modified by seaching the pattern, assume that file is up to date\n",
    "        match = re.search(time_pattern,name)\n",
    "        How_Long_have_not_update=0\n",
    "        if match:\n",
    "            year_string,month_string,day_string = match.groups()\n",
    "            last_edit = dt(int(year_string),int(month_string),int(day_string))\n",
    "            How_Long_have_not_update = (current_date-last_edit).days\n",
    "            check =re.split(Exception_pattern,name)\n",
    "            if check[0] not in Expection_list_checkupdate:\n",
    "                #Threshhold for each type of folder\n",
    "                match Folder:\n",
    "                    case 'ExceptionReq':\n",
    "                        if  How_Long_have_not_update >1:\n",
    "                            print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                            extract_list.append((name,Folder,\"May need update\"))           \n",
    "                    #Update CPI\n",
    "                    case 'CPI':\n",
    "                        How_old_is_this_file =4\n",
    "                        # Calculate how old is this file and should it be neccessary to update it\n",
    "                        yyyymmdd_pattern = r'(\\d{8})'\n",
    "                        matchformat = re.search(yyyymmdd_pattern,name)\n",
    "                        if matchformat:\n",
    "                            start_date_string = matchformat.group()\n",
    "                            start_date = dt.strptime(start_date_string,\"%Y%m%d\")\n",
    "                            How_old_is_this_file = (current_date-start_date).days\n",
    "\n",
    "                        if  How_old_is_this_file < 3 and How_Long_have_not_update >=1:\n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "                    #Update CUIC\n",
    "                    case 'CUIC':\n",
    "                        How_old_is_this_file =4\n",
    "                        # Calculate how old is this file and should it be neccessary to update it\n",
    "                    \n",
    "                        yyyy_dd_mm_pattern = r'(\\d{4})_(\\d{2})_(\\d{2})'\n",
    "                        matchformat = re.match(yyyy_dd_mm_pattern,name)\n",
    "                        if matchformat:\n",
    "                            year_s,mon_s,day_s = matchformat.groups()\n",
    "                            start_2 = dt(int(year_s),int(mon_s),int(day_s))\n",
    "                            How_old_is_this_file = (current_date-start_2).days\n",
    "\n",
    "                            #Flag to check for the newest file\n",
    "                            if How_old_is_this_file <=0:\n",
    "                                Most_recent_CUIC_file = 0\n",
    "\n",
    "                        if  How_old_is_this_file < 3 and How_Long_have_not_update >1:\n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #update 1-3 days\n",
    "                    case 'CSAT_RS'|'CSAT_TP'|'LogoutCount'|'PSAT'|'RAMCO'|'ROSTER'|'AHT':\n",
    "\n",
    "                        # Calculate how old is this file and should it be neccessary to update it\n",
    "                        start_end_pattern = r'(\\d{8})_(\\d{8})'\n",
    "                        How_old_is_this_file =8\n",
    "                        matchformat = re.search(start_end_pattern,name)\n",
    "                        \n",
    "                        if matchformat:\n",
    "                            start_date_string,end_date_string = matchformat.groups()\n",
    "                            end_date = dt.strptime(end_date_string,\"%Y%m%d\")\n",
    "                            How_old_is_this_file = (current_date-end_date).days\n",
    "\n",
    "                            if  How_Long_have_not_update > 2 and How_old_is_this_file <4:  \n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #update weekly\n",
    "                    case 'CPI_PEGA'|'OT_RAMCO'|'OTReq'|'RegisteredOT'|'RONA':\n",
    "                        # Calculate how old is this file and should it be neccessary to update it\n",
    "                        start_end_pattern = r'(\\d{8})_(\\d{8})'\n",
    "                        How_old_is_this_file =8\n",
    "                        matchformat = re.search(start_end_pattern,name)\n",
    "                        if matchformat:\n",
    "                            start_date_string,end_date_string = matchformat.groups()\n",
    "                            end_date = dt.strptime(end_date_string,\"%Y%m%d\")\n",
    "                            How_old_is_this_file = (current_date-end_date).days\n",
    "                        \n",
    "                            if  How_Long_have_not_update > 5 and How_old_is_this_file <7:  \n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #update Contract\n",
    "                    case 'Contrack':\n",
    "                        # Calculate how old is this file and should it be neccessary to update it\n",
    "                        wfm_pattern = r'[WFM] Contact Tracker'\n",
    "                        matchformat = re.search(wfm_pattern,name)  \n",
    "                        if How_Long_have_not_update> 2 and matchformat:  \n",
    "                            print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                            extract_list.append((name,Folder,\"May need update\"))\n",
    "            \n",
    "\n",
    "                    #update monthly\n",
    "                    case 'CapHC'|'DailyReq'|'IntervalReq'|'KPI_Target'|'LTTransfers'|'ProjectedHC':\n",
    "                        if  How_Long_have_not_update < How_Long_Prepresent_file_have_not_update:  \n",
    "                            Prepresent_file = name\n",
    "                            How_Long_Prepresent_file_have_not_update=How_Long_have_not_update\n",
    "\n",
    "                    #update yearly\n",
    "                    case 'PremHdays'|'NormHdays':\n",
    "                        if How_Long_have_not_update > 364:\n",
    "                            print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                            extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #update WDD/ProjectedShrink/Staff\n",
    "                    case 'EmpMaster'|'Resignation'|'Termination'|'ProjectedShrink'|'Staff':\n",
    "                        if How_Long_have_not_update > 8 and Folder != 'ProjectedShrink' :\n",
    "                            print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                            extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #Update EPS\n",
    "                    case 'EPS':\n",
    "                        How_old_is_this_file =5\n",
    "                        yyyymmdd_pattern = r'(\\d{8})'\n",
    "                        matchformat = re.search(yyyymmdd_pattern,name)\n",
    "                        if matchformat:\n",
    "                            start_date_string = matchformat.group()\n",
    "                            start_date = dt.strptime(start_date_string,\"%Y%m%d\")\n",
    "                            How_old_is_this_file = (current_date-start_date).days\n",
    "                        # Flag the folder if the file is not newest\n",
    "                            if How_old_is_this_file < Most_recent_EPS_file:\n",
    "                                Most_recent_EPS_file = How_old_is_this_file\n",
    "                        \n",
    "                        if  How_old_is_this_file < 4 and How_Long_have_not_update >=3:\n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #Update Quality\n",
    "                    case 'Quality':\n",
    "                        How_old_is_this_file =5\n",
    "                        yyyymmdd_pattern = r'(\\d{8})'\n",
    "                        matchformat = re.search(yyyymmdd_pattern,name)\n",
    "                        if matchformat:\n",
    "                            start_date_string = matchformat.group()\n",
    "                            start_date = dt.strptime(start_date_string,\"%Y%m%d\")\n",
    "                            How_old_is_this_file = (current_date-start_date).days\n",
    "                        # Flag the folder if the file is not newest\n",
    "                            if How_old_is_this_file < Most_recent_Quality_file:\n",
    "                                Most_recent_Quality_file = How_old_is_this_file\n",
    "\n",
    "                        if  How_old_is_this_file < 4 and How_Long_have_not_update >=3:\n",
    "                                print(f'{bcolors.OKCYAN}File {name} in {Folder} might need to update{bcolors.ENDC}')\n",
    "                                extract_list.append((name,Folder,\"May need update\"))\n",
    "\n",
    "                    #Update WpDetail\n",
    "                    case 'WpDetail':\n",
    "                        start_end_pattern = r'(\\d{4})-(\\d{2})'\n",
    "                        How_old_is_this_file =7\n",
    "                        matchformat = re.search(start_end_pattern,name)\n",
    "                        if matchformat:\n",
    "                            year_string,weeknum_string = matchformat.groups()\n",
    "                            fulldate = f'{year_string}-W{weeknum_string}'\n",
    "                            end_date = dt.strptime(fulldate+'-1',\"%Y-W%W-%w\")\n",
    "                            How_old_is_this_file = (current_date-end_date).days\n",
    "\n",
    "                        # Flag the folder if the file is not newest\n",
    "                        if  How_old_is_this_file < Most_recent_WpDetail_file:\n",
    "                            Most_recent_WpDetail_file= How_old_is_this_file\n",
    "        \n",
    "                    #folder not found\n",
    "                    case _:\n",
    "                        print(f'{bcolors.OKCYAN}{Folder} is not expected for the update check {bcolors.ENDC}')\n",
    "                        return\n",
    "    \n",
    "    # Raise notify base on flag \n",
    "    if Most_recent_CUIC_file!=0 and Folder==\"CUIC\":\n",
    "        print(f'{bcolors.OKCYAN}{Folder} need to be updated to the newest data {bcolors.ENDC}')\n",
    "        extract_list.append((\"Missing Today File\",Folder,\"Need update\"))\n",
    "    if Most_recent_EPS_file>=3 and Folder==\"EPS\":\n",
    "        print(f'{bcolors.OKCYAN}{Folder} need to be updated to the newest data {bcolors.ENDC}')\n",
    "        extract_list.append((\"Missing This Week File\",Folder,\"Need update\"))\n",
    "    if Most_recent_Quality_file>=3 and Folder==\"Quality\":\n",
    "        print(f'{bcolors.OKCYAN}{Folder} need to be updated to the newest data {bcolors.ENDC}')\n",
    "        extract_list.append((\"Missing This Week File\",Folder,\"Need update\"))\n",
    "    if Most_recent_WpDetail_file >7 and Folder==\"WpDetail\":\n",
    "        print(f'{bcolors.OKCYAN}{Folder} need to be updated to the newest data {bcolors.ENDC}')\n",
    "        extract_list.append((\"Missing This Week File\",Folder,\"Need update\"))    \n",
    "    if How_Long_Prepresent_file_have_not_update>30 and Prepresent_file:\n",
    "        print(f'{bcolors.OKCYAN}{Prepresent_file} in {Folder} need to be updated to the newest data {bcolors.ENDC}')\n",
    "        extract_list.append((Prepresent_file,Folder,f'Last update {How_Long_Prepresent_file_have_not_update} days ago'))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9866700b-3f6d-4d1f-80a7-2a0515649259",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Category check cho toÃ n bá»™ Func trÃªn dá»±a trÃªn káº¿t quáº£ code 1\n",
    "def CategoryCheck (your_dataframe,file_error):\n",
    "     #Check each folder \n",
    "     for folder_name in your_dataframe[Folder_column_name].unique():\n",
    "               #Current folder checking\n",
    "               current_check = your_dataframe.filter(pl.col(Folder_column_name) == folder_name)\n",
    "               current_extract_grp=[]\n",
    "               #Check naming rule\n",
    "               for file_name in current_check[Name_Coumn_name]:\n",
    "                    match = re.match(Namepattern(folder_name),file_name)\n",
    "                    if match:\n",
    "                          #Extract valid file name to check further\n",
    "                        current_extract_grp.append(f\"{file_name}\")\n",
    "                    else:\n",
    "                        print(f\"{bcolors.FAILVIOLET}Weird Name Pattern at {file_name} in folder {folder_name}{bcolors.ENDC}\")\n",
    "                        current_extract_grp.append(f\"{file_name}\")\n",
    "                        file_error.append((file_name,folder_name,\"Weird Name\"))\n",
    "               #Check Missing File if current folder only have 1 file, skip this\n",
    "               if current_check.count()[0,1]>1:\n",
    "                    Missing_File_check(current_extract_grp,file_error,folder_name)\n",
    "               #Check update\n",
    "               File_need_update_check(current_extract_grp,file_error,folder_name)\n",
    "               \n",
    "               #Check Duplicate Date, if current folder only have 1 file, skip this\n",
    "               filter_file = []\n",
    "               if current_check.count()[0,1]>1:\n",
    "                    filter_file = Duplicate_Date_Check(current_extract_grp,file_error,folder_name)\n",
    "                    \n",
    "               #Deviation in row check using valid list with format yyyymmdd_yyyymmdd from previous func\n",
    "               if filter_file:\n",
    "                    filtered_DF_standard_pattern = current_check.filter(pl.col(Name_Coumn_name).is_in(filter_file))\n",
    "                    Row_Compare(filtered_DF_standard_pattern,file_error,folder_name)\n",
    "               \n",
    "               #Row check for wild file name\n",
    "               filtered_DF_other_pattern = current_check.filter(pl.col(Name_Coumn_name).is_in(filter_file).not_())\n",
    "               if filtered_DF_other_pattern.count()[0,1]>1 and folder_name != \"CUIC\": \n",
    "                    #Delete the [and folder_name != \"CUIC\"] when feel like it's time (ðŸ‘‰ï¾Ÿãƒ®ï¾Ÿ)ðŸ‘‰Due to CUIC format is under renovation, temporarely remove it from the check so the number of file with new rows pattern will soon be sufficient to not bluffing during this report\n",
    "                    Row_Compare_Special(filtered_DF_other_pattern,file_error)\n",
    "\n",
    "                \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3fba4f1-13b5-4409-af5d-c370b1784089",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Error check CODE 2 and read LOG\n",
    "def Error_Check(Dataframe,extract_file,LINK):\n",
    "    #Check code 2\n",
    "    Only_Important = Dataframe.filter(pl.col(important_column)==\"IMPORTANT\",pl.col(Check_dup_column)>0)\n",
    "    if Only_Important.count()[0,1]>0:\n",
    "        for row in Only_Important.iter_rows(named=True):\n",
    "                print(f\"{bcolors.FAIL}Folder {row[Table_column]} has {row[Check_dup_column]} duplicate row{\"s\"if row[Check_dup_column]>1 else \" \"}{bcolors.ENDC}\")\n",
    "                extract_file.append((\"\",row[Table_column],F\"{row[Check_dup_column]} row(s) of duplicate data\"))\n",
    "    \n",
    "    #Check log\n",
    "    for file in glob.glob(LINK):\n",
    "        #Get file name -> folder name\n",
    "        Current_file = pl.read_excel(file)\n",
    "        filename = os.path.basename(file)\n",
    "        foldername = re.split('_log',filename)\n",
    "        # Looking out for error in error column of log file\n",
    "        try:\n",
    "            if Current_file.filter(pl.col(Error_log_column)!=\"\").count()[0,1]>0:\n",
    "                for row in Current_file.filter(pl.col(Error_log_column)!=\"\").iter_rows(named=True):\n",
    "                    print(f\"{bcolors.FAIL}Folder {row[Log_name_column]} in {foldername[0]} a has fatal error{bcolors.ENDC}\")\n",
    "                    extract_file.append((row[Log_name_column],foldername[0],\"Fatal Error\"))        \n",
    "        except Exception:\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ded2948-b601-4729-a84e-ee8c85f37f5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mSkip CUIC for missing check \u001b[0m\n",
      "\u001b[96mCUIC need to be updated to the newest data \u001b[0m\n",
      "\u001b[96mSkip CapHC for missing check \u001b[0m\n",
      "\u001b[96mSkip RONA for missing check \u001b[0m\n",
      "\u001b[96mSkip Quality for missing check \u001b[0m\n",
      "\u001b[96mQuality need to be updated to the newest data \u001b[0m\n",
      "\u001b[93mFile 20250831.xlsx - 2025-09-10 07:58:04 in Quality has inconsistent number of rows \u001b[0m\n",
      "\u001b[96mSkip IntervalReq for missing check \u001b[0m\n",
      "\u001b[96mFile 20251001_20251031.csv - 2025-10-14 17:50:07 in RAMCO might need to update\u001b[0m\n",
      "\u001b[96mSkip RegisteredOT for missing check \u001b[0m\n",
      "\u001b[96mFile 20251006_20251012.xlsx - 2025-10-10 15:23:17 in RegisteredOT might need to update\u001b[0m\n",
      "\u001b[96mSkip DailyReq for missing check \u001b[0m\n",
      "\u001b[93mFile 202303_202502.xlsx - 2025-02-27 20:34:37 in DailyReq has inconsistent number of rows \u001b[0m\n",
      "\u001b[96mWpSummary is not expected for the update check \u001b[0m\n",
      "\u001b[35mMissing 20250601_20250630 in folder CSAT_TP\u001b[0m\n",
      "\u001b[35mMissing 20250701_20250731 in folder CSAT_TP\u001b[0m\n",
      "\u001b[35mMissing 20250801_20250831 in folder CSAT_TP\u001b[0m\n",
      "\u001b[35mMissing 20251014 in folder CPI\u001b[0m\n",
      "\u001b[35mMissing 20251015 in folder CPI\u001b[0m\n",
      "\u001b[96mSkip ProjectedHC for missing check \u001b[0m\n",
      "\u001b[96mSkip Contrack for missing check \u001b[0m\n",
      "\u001b[96mIEX_Hrs is not expected for the update check \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#MAIN RUN\n",
    "file_error= []\n",
    "CategoryCheck(Code1_Result,file_error)\n",
    "Error_Check(Code2_Result,file_error,LOG_LINK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f8714ba-b4c6-4da5-ba2b-cde69e18f72a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tungquan.le\\AppData\\Local\\Temp\\ipykernel_17632\\2347980961.py:3: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  error_report = pl.DataFrame(file_error, schema=[\"File Name\",\"Folder\",\"Reason\"],)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xlsxwriter.workbook.Workbook at 0x230d5df73b0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Final Report\n",
    "#Táº¡o dataframe trá»‘ng vá»›i 3 cá»™t\n",
    "error_report = pl.DataFrame(file_error, schema=[\"File Name\",\"Folder\",\"Reason\"],)\n",
    "#ÄÆ°á»ng dáº«n \n",
    "Output_path = os.path.join(user_credential,\n",
    "                                r'DataBase//DataRaw//BKN')\n",
    "#TÃªn file xuáº¥t\n",
    "Output_file = os.path.join(Output_path,\n",
    "                            r'Mod_Log.xlsx')\n",
    "#Lá»‡nh xuáº¥t\n",
    "error_report.write_excel(Output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f11a83fb-3808-4ddb-adf1-40bbd4b9efab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Allow leaves\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import ColorScaleRule\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "\n",
    "personal_path = os.environ['USERPROFILE']\n",
    "middle_path = r'Concentrix Corporation\\CNXVN - WFM Team - Documents\\DataBase'\n",
    "user_credential = os.path.join(os.environ['USERPROFILE'], middle_path)\n",
    "\n",
    "# LinkðŸ“ƒ\n",
    "requirement_path = os.path.join(user_credential, r'DataRaw\\BKN\\REQUIREMENT_HOURS')\n",
    "mr_path = os.path.join(user_credential, r'DataRaw\\BKN\\AGENTS')\n",
    "schedule_path = os.path.join(user_credential, r'DataRaw\\BKN\\ROSTER')\n",
    "ot_path = os.path.join(user_credential, r'DataRaw\\BKN\\OVERTIME')\n",
    "wp_path = os.path.join(user_credential, r'DataRaw\\BKN\\WP_SUMMARY')\n",
    "\n",
    "\n",
    "dtype_error_map = [['float64', 'int64'], ['datetime64[ns]', 'object'], ['object', 'float64'], ['int64', 'object']]\n",
    "\n",
    "def import_xlsx(path, **kwargs):\n",
    "    list_dir = sorted([x for x in os.listdir(path) if x.endswith('.xlsx')])\n",
    "    raw = []\n",
    "    standard_cols = pd.read_excel(os.path.join(path, list_dir[0]), engine=\"openpyxl\", sheet_name = list(kwargs.values())[0]).columns.to_list()\n",
    "    standard_dtype = pd.read_excel(os.path.join(path, list_dir[0]), engine=\"openpyxl\", sheet_name = list(kwargs.values())[0]).dtypes.to_dict()\n",
    "    change_log = []\n",
    "    global go\n",
    "    for file in list_dir:\n",
    "        file_path = os.path.join(path, file)\n",
    "        try:\n",
    "            next = True\n",
    "            sheetname_position = 0\n",
    "            while next == True and sheetname_position<= len(kwargs.values()):\n",
    "                try: \n",
    "                    file_data = pd.read_excel(file_path, engine=\"openpyxl\", sheet_name = list(kwargs.values())[sheetname_position])\n",
    "                    next = False\n",
    "                except:\n",
    "\n",
    "                    sheetname_position += 1\n",
    "                \n",
    "            file_data_dtype =  file_data.dtypes.to_dict()\n",
    "            for col in file_data.columns.to_list(): #check unexpected columns\n",
    "                if col not in standard_cols:\n",
    "                    print(f'{file} contains unexpected column {col}')\n",
    "                    change_log.append([dt.now().strftime(\"%Y-%m-%d %H:%M:%S\"), personal_path, file, \"unexpected column\", col])\n",
    "            for col in standard_cols: #check missing columns\n",
    "                if col not in file_data.columns.to_list():\n",
    "                    print(f'{file} has a missing column {col}')\n",
    "                    change_log.append([dt.now().strftime(\"%Y-%m-%d %H:%M:%S\"), personal_path, file, \"missing column\", col])\n",
    "            for key in standard_dtype:\n",
    "                if key in file_data.columns.to_list() and standard_dtype[key] != file_data_dtype[key]:\n",
    "                    if [standard_dtype[key], file_data_dtype[key]] in dtype_error_map or [file_data_dtype[key], standard_dtype[key]] in dtype_error_map:\n",
    "                        pass\n",
    "                    else:\n",
    "                        print(f'{file} {key}:{standard_dtype[key]} -> {file_data_dtype[key]}')\n",
    "                        change_log.append([dt.now().strftime(\"%Y-%m-%d %H:%M:%S\"), personal_path, file, \"wrong dtype\", key])\n",
    "            file_data[\"filename\"] = file\n",
    "            raw.append(file_data)\n",
    "        except:\n",
    "            print(f'Cannot input {file} into dataframe')\n",
    "\n",
    "    final_raw = pd.concat(raw, ignore_index=True)\n",
    "    return final_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "006b38a7-e0cf-4f4f-afe8-8baa9de63a1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mr = import_xlsx(mr_path, sheet_name=\"Sheet1\")\n",
    "schedule = import_xlsx(schedule_path, sheet_name=\"Sheet1\")\n",
    "schedule = schedule[schedule['Attribute'].dt.year >= 2025]\n",
    "ot = import_xlsx(ot_path, sheet_name=\"Sheet1\")\n",
    "ot = ot[ot['Date'].dt.year >= 2025]\n",
    "wp = import_xlsx(wp_path, sheet_name=\"Sheet1\")\n",
    "wp = wp[wp['Date'].dt.year >= 2025]\n",
    "req = import_xlsx(requirement_path, sheet_name=\"Sheet1\")\n",
    "req = req[req['Date'].dt.year >= 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75882470-18e2-42cc-8bde-f6cadcb353e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# mr['Employee_ID'] = mr['Employee_ID'].astype('int64')\n",
    "schedule = schedule.rename(columns={'Attribute':'Date','Value':'Shift'})\n",
    "schedule['Emp ID'] = schedule['Emp ID'].astype('int64')\n",
    "# Get TL Tedname\n",
    "schedule = pd.merge(schedule, mr[['Employee_ID', 'TED Name']], left_on='team_leader', right_on='Employee_ID', how='left')\n",
    "schedule = schedule.rename(columns={'TED Name':'TL'})\n",
    "schedule = schedule.drop(columns=['team_leader','Employee_ID'])\n",
    "ot = pd.merge(ot, schedule[['Emp ID','Date','LOB']], on=['Emp ID','Date'], how='left')\n",
    "ot = ot.drop(columns=['LOB_y'])\n",
    "ot = ot.rename(columns={'LOB_x':'LOB'})\n",
    "# sum ot per day, lob\n",
    "ot_date_lob = ot.groupby(['Date','LOB'], as_index=False)['OT'].sum()\n",
    "projected_AR = pd.DataFrame({'LOB':['EN','IT','FR','NO','CS','DE','NL','RU','RO','VICSG','VICSP','Senior VICSP'],\n",
    "                'Projected AR':['0.07','0.07','0.07','0.1','0.1','0.07','0.07','0.1','0.1','0.1','0.1','0.1']})\n",
    "projected_AR['Projected AR'] = projected_AR['Projected AR'].astype('float')\n",
    "wp = wp[wp['Scheduled Activity'].isin([\"Team Meeting\", \"Coaching 1:1\", \"Training Offline\",\"Training N\",\"Training U\",\"Training A\",\"Coaching 1:1 Offline\",\"Training Q\"])]\n",
    "wp = wp.groupby(['Date','LOB'], as_index=False)['Length'].sum()\n",
    "wp['Length'] = wp['Length']*24\n",
    "wp = wp.rename(columns={'Length':'Downtime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bed3b4a2-921b-4f2c-bd2c-274bd08befcb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "schedule = schedule[(schedule.Shift != 'OFF') & (schedule.Shift != 'Training')]\n",
    "schedule['Leaves'] = schedule.apply(lambda x: 1 if x['Shift'] in ['UPL','AL','CO'] else 0, axis=1)\n",
    "# total leaves per catogory\n",
    "leaves_date_lob = schedule.groupby(['Date','LOB'], as_index=False)['Leaves'].sum()\n",
    "leaves_date_lob = leaves_date_lob.rename(columns={'Leaves':'Leaves per LOB'})\n",
    "leaves_tl_date_lob = schedule.groupby(['Date','LOB','TL'], as_index=False)['Leaves'].sum()\n",
    "leaves_tl_date_lob = leaves_tl_date_lob.rename(columns={'Leaves':'Leaves per TL'})\n",
    "# total hc per catogory\n",
    "hc_by_date_lob = schedule.groupby(['Date','LOB'], as_index=False)['Emp ID'].count()\n",
    "hc_by_date_lob = hc_by_date_lob.rename(columns={'Emp ID':'HC per LOB'})\n",
    "hc_by_date_lob = pd.merge(hc_by_date_lob, leaves_date_lob, on = ['Date','LOB'], how='left')\n",
    "hc_by_tl_date_lob = schedule.groupby(['Date','LOB','TL'], as_index=False)['Emp ID'].count()\n",
    "hc_by_tl_date_lob = hc_by_tl_date_lob.rename(columns={'Emp ID':'HC per TL'})\n",
    "hc_by_tl_date_lob = pd.merge(hc_by_tl_date_lob, leaves_tl_date_lob, on = ['Date','LOB','TL'], how='left')\n",
    "# mapping hc vs leaves VS OT\n",
    "mapping_hc = pd.merge(hc_by_date_lob, hc_by_tl_date_lob, on = ['Date','LOB'], how='left')\n",
    "mapping_hc = pd.merge(mapping_hc, req, on = ['Date','LOB'], how='left')\n",
    "mapping_hc = pd.merge(mapping_hc, ot_date_lob, on = ['Date','LOB'], how='left')\n",
    "mapping_hc['Week'] = mapping_hc['Date'].dt.strftime('%Y%W').astype('int64')\n",
    "mapping_hc = pd.merge(mapping_hc, projected_AR, on='LOB', how='left')\n",
    "mapping_hc = pd.merge(mapping_hc, wp, on = ['Date','LOB'], how='left')\n",
    "mapping_hc['Downtime'] = mapping_hc['Downtime'].fillna(0)\n",
    "mapping_hc['Projected prod hrs'] = mapping_hc['HC per LOB']*7.5*(1-mapping_hc['Projected AR'])- mapping_hc['Downtime']\n",
    "mapping_hc['O/U'] = mapping_hc['Projected prod hrs'] - mapping_hc['Prod Requirement']\n",
    "mapping_hc['Allowed leaves_HC_tl'] = ((mapping_hc['HC per TL']/mapping_hc['HC per LOB'])*mapping_hc['O/U'])/7.5\n",
    "mapping_hc['Allowed leaves_HC_tl'] = mapping_hc.apply(lambda x: x['Allowed leaves_HC_tl'] if x['Allowed leaves_HC_tl'] >= 0 else 0, axis=1)\n",
    "mapping_hc['Deficit'] = (mapping_hc['Allowed leaves_HC_tl'] - mapping_hc['Leaves per TL']).round(2)\n",
    "mapping_hc['Negative deficit'] = mapping_hc.apply(lambda x: 'Yes' if x['Deficit'] < 0 else '', axis=1)\n",
    "mapping_hc = mapping_hc[mapping_hc['Date'].dt.year >= 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bb6ebfea-ec46-4d81-a80b-1f2e9f45d4e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_path = os.path.join(user_credential, r'DataRaw\\BKN\\Change LOB')\n",
    "allow_leave = mapping_hc[['Week','Date','LOB','TL','Deficit']]\n",
    "# pivot_table = pivot_table[pivot_table['Deficit'] < 0]\n",
    "allow_leave['Week'] = allow_leave['Date'].dt.strftime('%Y%W')\n",
    "allow_leave['Date'] = allow_leave['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "current_week = datetime.now().strftime('%Y%W')\n",
    "allow_leave = allow_leave.loc[(allow_leave['Week'] == current_week)]\n",
    "pivot_table = allow_leave[['Date','LOB','TL','Deficit']]\n",
    "pivot_table=pl.from_pandas(pivot_table)\n",
    "pivot_table = pivot_table.pivot(\n",
    "    index=[\"Date\",\"TL\",],\n",
    "    on=\"LOB\",\n",
    "    aggregate_function=\"sum\" # WE can use 'first' náº¿u chá»‰ cÃ³ 1 giÃ¡ trá»‹ duy nháº¥t cho má»—i tá»• há»£p index/columns\n",
    ")\n",
    "\n",
    "pivot_table=pivot_table.to_pandas()\n",
    "\n",
    "# Export to xlsx\n",
    "os.chdir(output_path)\n",
    "writer = pd.ExcelWriter(\"Allowed leaves pivot.xlsx\", engine=\"xlsxwriter\")\n",
    "pivot_table.to_excel(writer, sheet_name=\"Sheet1\", startrow=1,header=False ,index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "(max_row, max_col) = pivot_table.shape\n",
    "column_settings = [{\"header\": column} for column in pivot_table.columns]\n",
    "worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "worksheet.set_column(0, 1, 19)\n",
    "worksheet.set_column(2, max_col - 1, 5)\n",
    "worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#F8696B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#63BE7B'})\n",
    "writer.close()\n",
    "\n",
    "pivot_total = allow_leave[['LOB','TL','Deficit']]\n",
    "pivot_total=pl.from_pandas(pivot_total)\n",
    "pivot_total = pivot_total.pivot(\n",
    "    index=[\"TL\",],\n",
    "    on=\"LOB\",\n",
    "    aggregate_function=\"sum\" # WE can use 'first' náº¿u chá»‰ cÃ³ 1 giÃ¡ trá»‹ duy nháº¥t cho má»—i tá»• há»£p index/columns\n",
    ")\n",
    "\n",
    "pivot_total=pivot_total.to_pandas()\n",
    "\n",
    "# Export to xlsx\n",
    "os.chdir(output_path)\n",
    "writer = pd.ExcelWriter(\"Allowed leaves total.xlsx\", engine=\"xlsxwriter\")\n",
    "pivot_total.to_excel(writer, sheet_name=\"Sheet1\", startrow=1,header=False ,index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "(max_row, max_col) = pivot_total.shape\n",
    "column_settings = [{\"header\": column} for column in pivot_total.columns]\n",
    "worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "worksheet.set_column(0, 0, 19)\n",
    "worksheet.set_column(1, max_col - 1, 5)\n",
    "worksheet.conditional_format(1, 1, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#F8696B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#63BE7B'})\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ec9a2b4-7b78-4d0d-bbf2-c3bd406eab00",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#OT_DETAIL (Aimee ask for report OT > 40H)\n",
    "sql_query=\"\"\"\n",
    "with ot_raw as (\n",
    "select [OM_Name],[TL_Name],[Emp_Name] as [Agent_Name],[Week_num],[OT_Registered(s)],DATENAME(month,[Date]) as [MONTH],month([Date]) as [#MONTH],[Date]\n",
    "from BCOM.EEAAO\n",
    "where [Date]>=DATEADD(DAY, -100,CAST(GETDATE() As Date)) \n",
    "and [OT_Registered(s)]>0 and MONTH([Date])>=month(CAST(GETDATE() As Date))-2),\n",
    "ot as (\n",
    "select [OM_Name],[TL_Name],[Agent_Name],[MONTH], [#MONTH],sum(cast([OT_Registered(s)] as float)/3600) as [OT]\n",
    "from ot_raw\n",
    "group by  [OM_Name],[TL_Name],[Agent_Name],[MONTH], [#MONTH])\n",
    "select * from ot where [OT]>40\n",
    "\"\"\"\n",
    "ot = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "# Export to CSV\n",
    "os.chdir(ot_report)\n",
    "ot_CSV = ot.write_excel(workbook=\"BKN_OT.xlsx\",worksheet=\"Sheet1\",table_name='Frame0', autofit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9fbb679a-50ba-41d4-bc8c-391c5191baba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#OT_MONTH (Aimee ask for report OT > 40H) group by month\n",
    "sql_query=\"\"\"\n",
    "with ot_raw as (\n",
    "select [OM_Name],[TL_Name],[Emp_Name] as [Agent_Name],[Week_num],[OT_Registered(s)],DATENAME(month,[Date]) as [MONTH],month([Date]) as [#MONTH],[Date]\n",
    "from BCOM.EEAAO\n",
    "where [Date]>=DATEADD(DAY, -100,CAST(GETDATE() As Date)) \n",
    "and [OT_Registered(s)]>0 and MONTH([Date])>=month(CAST(GETDATE() As Date))-2),\n",
    "ot as (\n",
    "select [OM_Name],[TL_Name],[Agent_Name],[MONTH], [#MONTH],sum(cast([OT_Registered(s)] as float)/3600) as [OT],\n",
    "case when sum(cast([OT_Registered(s)] as float)/3600)>40 then 1 else 0 end as [Cases]\n",
    "from ot_raw\n",
    "group by  [OM_Name],[TL_Name],[Agent_Name],[MONTH], [#MONTH]),\n",
    "ot_month as (\n",
    "select [OM_Name],[TL_Name],[MONTH], [#MONTH],sum([Cases]) as [Cases]\n",
    "from ot\n",
    "group by [OM_Name],[TL_Name],[MONTH], [#MONTH])\n",
    "select * from ot_month where [Cases]>0\n",
    "\"\"\"\n",
    "ot_month = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "ot_month=ot_month.to_pandas()\n",
    "ot_month['#MONTH']=ot_month['#MONTH'].astype(\"int64\")\n",
    "ot_month=ot_month.sort_values(by='#MONTH',ascending=True)\n",
    "ot_month=ot_month[['OM_Name','TL_Name','MONTH','Cases']]\n",
    "ot_month= pl.from_pandas(ot_month)\n",
    "pivot_ot_month = ot_month.pivot(\n",
    "            values=[\"Cases\",],\n",
    "            index=[\"OM_Name\",\"TL_Name\",],\n",
    "            on=\"MONTH\",\n",
    "            aggregate_function=\"sum\" # WE can use 'first' náº¿u chá»‰ cÃ³ 1 giÃ¡ trá»‹ duy nháº¥t cho má»—i tá»• há»£p index/columns\n",
    "        )\n",
    " \n",
    "pivot_ot_month = pivot_ot_month.to_pandas()\n",
    "pivot_ot_month=pivot_ot_month.sort_values(by=[\"OM_Name\",\"TL_Name\"],ascending=True)\n",
    "# Export to xlsx\n",
    "os.chdir(ot_report)\n",
    "writer = pd.ExcelWriter(\"BKN_OT_MONTH.xlsx\", engine=\"xlsxwriter\")\n",
    "pivot_ot_month.to_excel(writer, sheet_name=\"Sheet1\", startrow=1,header=False ,index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "(max_row, max_col) = pivot_ot_month.shape\n",
    "column_settings = [{\"header\": column} for column in pivot_ot_month.columns]\n",
    "worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "worksheet.set_column(0, 1, 19)\n",
    "worksheet.set_column(2, max_col - 1, 7)\n",
    "worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d7c674fa-38f9-48a7-8570-16960efd3ec2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#OT_WEEK (Aimee ask for report OT > 40H) group by weeks\n",
    "sql_query=\"\"\"\n",
    "with ot_raw as (\n",
    "select [OM_Name],[TL_Name],[Emp_Name] as [Agent_Name],[Week_num],[OT_Registered(s)],\n",
    "CASE WHEN FORMAT(DATEPART(ISO_WEEK, [Date]),'00') < 3 AND MONTH([Date]) > 10\n",
    "\tTHEN CONCAT(YEAR([Date])+1, FORMAT(DATEPART(ISO_WEEK,[Date]),'00'))\n",
    "\tELSE CONCAT(YEAR([Date]), FORMAT(DATEPART(ISO_WEEK,[Date] ),'00'))\n",
    "\tEND AS [Week],\n",
    "[Date]\n",
    "from BCOM.EEAAO\n",
    "where [Date]>=DATEADD(DAY, -100,CAST(GETDATE() As Date)) \n",
    "and [OT_Registered(s)]>0 \n",
    "and CASE WHEN FORMAT(DATEPART(ISO_WEEK, [Date]),'00') < 3 AND MONTH([Date]) > 10\n",
    "\tTHEN CONCAT(YEAR([Date])+1, FORMAT(DATEPART(ISO_WEEK,[Date]),'00'))\n",
    "\tELSE CONCAT(YEAR([Date]), FORMAT(DATEPART(ISO_WEEK,[Date] ),'00'))\n",
    "\tEND >=CASE WHEN FORMAT(DATEPART(ISO_WEEK, CAST(GETDATE() As Date)),'00') < 3 AND MONTH(CAST(GETDATE() As Date)) > 10\n",
    "\tTHEN CONCAT(YEAR(CAST(GETDATE() As Date))+1, FORMAT(DATEPART(ISO_WEEK,CAST(GETDATE() As Date)),'00'))\n",
    "\tELSE CONCAT(YEAR(CAST(GETDATE() As Date)), FORMAT(DATEPART(ISO_WEEK,CAST(GETDATE() As Date) ),'00'))\n",
    "\tEND-5),\n",
    "ot as (\n",
    "select [OM_Name],[TL_Name],[Agent_Name],[Week],sum(cast([OT_Registered(s)] as float)/3600) as [OT],\n",
    "case when sum(cast([OT_Registered(s)] as float)/3600)>20 then 1 else 0 end as [Cases]\n",
    "from ot_raw\n",
    "group by  [OM_Name],[TL_Name],[Agent_Name],[Week]),\n",
    "ot_month as (\n",
    "select [OM_Name],[TL_Name],[Week],sum([Cases]) as [Cases]\n",
    "from ot\n",
    "group by [OM_Name],[TL_Name],[Week])\n",
    "select * from ot_month where [Cases]>0\n",
    "\"\"\"\n",
    "ot_week = pl.read_database(query=sql_query, connection=engine)\n",
    "engine.dispose()\n",
    "ot_week=ot_week.to_pandas()\n",
    "ot_week['Week']=ot_week['Week'].astype(\"int64\")\n",
    "ot_week=ot_week.sort_values(by='Week',ascending=True)\n",
    "ot_week=ot_week[['OM_Name','TL_Name','Week','Cases']]\n",
    "ot_week= pl.from_pandas(ot_week)\n",
    "pivot_ot_week = ot_week.pivot(\n",
    "            values=[\"Cases\",],\n",
    "            index=[\"OM_Name\",\"TL_Name\",],\n",
    "            on=\"Week\",\n",
    "            aggregate_function=\"sum\" # WE can use 'first' náº¿u chá»‰ cÃ³ 1 giÃ¡ trá»‹ duy nháº¥t cho má»—i tá»• há»£p index/columns\n",
    "        )\n",
    " \n",
    "pivot_ot_week = pivot_ot_week.to_pandas()\n",
    "pivot_ot_week=pivot_ot_week.sort_values(by=[\"OM_Name\",\"TL_Name\"],ascending=True)\n",
    "# Export to xlsx\n",
    "os.chdir(ot_report)\n",
    "writer = pd.ExcelWriter(\"BKN_OT_WEEK.xlsx\", engine=\"xlsxwriter\")\n",
    "pivot_ot_week.to_excel(writer, sheet_name=\"Sheet1\", startrow=1,header=False ,index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "(max_row, max_col) = pivot_ot_week.shape\n",
    "column_settings = [{\"header\": column} for column in pivot_ot_week.columns]\n",
    "worksheet.add_table(0, 0, max_row, max_col - 1, {\"columns\": column_settings\n",
    "                                                        ,\"style\": \"Table Style Light 9\"})\n",
    "worksheet.set_column(0, 1, 19)\n",
    "worksheet.set_column(2, max_col - 1, 7)\n",
    "worksheet.conditional_format(1, 2, max_row, max_col, {\"type\": \"3_color_scale\",\n",
    "                                                          'min_color':'#63BE7B',\n",
    "                                                          'mid_color':'#FFEB84',\n",
    "                                                          'max_color':'#F8696B'})\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
