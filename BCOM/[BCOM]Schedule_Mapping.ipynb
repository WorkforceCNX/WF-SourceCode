{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41785d20-75ea-42e7-8b47-386570be6d81",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# LibraryðŸ“ƒ\n",
    "\n",
    "import glob, warnings, polars as pl, datetime, sqlite3, time, os, zipfile, xml.dom.minidom\n",
    "from datetime import datetime as dt, time as t, timedelta, date\n",
    "import pandas as pd, numpy as np, sqlalchemy as sa, xlsxwriter\n",
    "from sqlalchemy import create_engine\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "# LinkðŸ“ƒ\n",
    "Link_DB = os.path.join(os.environ['USERPROFILE'], r'Desktop//Bcom_DB.db')\n",
    "conn = create_engine(f\"sqlite:///{Link_DB}\")\n",
    "pattern_raw_path=os.path.join(os.environ['USERPROFILE'], r'Concentrix Corporation\\CNXVN - WFM Team - Documents\\DataBase\\DataRaw\\BKN\\SCHEDULE_MAPPING\\PatternID')\n",
    "special_request_path=os.path.join(os.environ['USERPROFILE'], r'Concentrix Corporation\\CNXVN - WFM Team - Documents\\DataBase\\DataRaw\\BKN\\SCHEDULE_MAPPING\\Special Request')\n",
    "schedule_path=os.path.join(os.environ['USERPROFILE'], r'Concentrix Corporation\\CNXVN - WFM Team - Documents\\DataBase\\DataFrame\\BKN\\SCHEDULE')\n",
    "team_shift_path=os.path.join(os.environ['USERPROFILE'], r'Concentrix Corporation\\CNXVN - WFM Team - Documents\\DataBase\\DataRaw\\BKN\\SCHEDULE_MAPPING\\Team shift')\n",
    "ews_path=os.path.join(os.environ['USERPROFILE'], r'Concentrix Corporation\\CNXVN - WFM Team - Documents\\DataBase\\DataRaw\\BKN\\WFMForm')\n",
    "roster_path=os.path.join(os.environ['USERPROFILE'], r'Concentrix Corporation\\CNXVN - WFM Team - Documents\\DataBase\\DataRaw\\BKN\\ROSTER\\Schedule Query\\*.xlsx')\n",
    "agents_path=os.path.join(os.environ['USERPROFILE'], r'Concentrix Corporation\\CNXVN - WFM Team - Documents\\DataBase\\DataRaw\\BKN\\AGENTS')\n",
    "\n",
    "# Weekoff RuleðŸ“ƒ\n",
    "weekoff_mapping = {\n",
    "    'MonTue': ('MonTue','TueWed', 'MonSun'),\n",
    "    'TueWed': ('MonTue','TueWed', 'WedThu','MonSun'),\n",
    "    'WedThu': ('MonTue','TueWed', 'WedThu','ThuFri','MonSun'),\n",
    "    'ThuFri': ('MonTue','TueWed', 'WedThu','ThuFri', 'FriSat','MonSun'),\n",
    "    'FriSat': ('MonTue','TueWed', 'WedThu','ThuFri', 'FriSat','SatSun','MonSun'),\n",
    "    'SatSun': ('MonTue','TueWed', 'WedThu','ThuFri', 'FriSat','SatSun','MonSun'),\n",
    "    'MonSun': ('MonTue','TueWed', 'WedThu','ThuFri', 'FriSat','SatSun','MonSun')\n",
    "}\n",
    "weekoff_mapping_pre = {\n",
    "    'MonTue': ('MonTue','TueWed', 'WedThu','ThuFri', 'FriSat','SatSun','MonSun'),\n",
    "    'TueWed': ('MonTue','TueWed', 'WedThu','ThuFri', 'FriSat','SatSun','MonSun'),\n",
    "    'WedThu': ('TueWed', 'WedThu','ThuFri', 'FriSat','SatSun','MonSun'),\n",
    "    'ThuFri': ('WedThu','ThuFri', 'FriSat','SatSun','MonSun'),\n",
    "    'FriSat': ('ThuFri', 'FriSat','SatSun','MonSun'),\n",
    "    'SatSun': ('FriSat','SatSun','MonSun'),\n",
    "    'MonSun': ('MonTue','TueWed', 'WedThu','ThuFri', 'FriSat','SatSun','MonSun')    \n",
    "}\n",
    "# Nextweek first dayðŸ“ƒ\n",
    "today = datetime.date.today()\n",
    "next_week = pd.to_datetime(today) + pd.offsets.Week(weekday=0)\n",
    "next_week = next_week.date()\n",
    "print(next_week)\n",
    "current_week = pd.to_datetime(today) + pd.offsets.Week(weekday=0) - pd.Timedelta(days=1)\n",
    "current_week = current_week.date()\n",
    "print(current_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec5dc7e-36d7-4827-8668-dacb80567be4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Roster & Pattern ðŸ§©\n",
    "\n",
    "current_week = pd.to_datetime(today) + pd.offsets.Week(weekday=0) - pd.Timedelta(days=1)\n",
    "current_week = current_week.date()\n",
    "Data_Schedule = []\n",
    "for file in glob.glob(roster_path):\n",
    "    filename = os.path.basename(file)\n",
    "    Read = pl.read_excel(file, infer_schema_length=None, engine=\"calamine\", sheet_name=\"Sheet1\")\n",
    "    Schedule = Read.select(pl.all(), pl.lit(filename).alias(\"Filename\"))\n",
    "    Data_Schedule.append(Schedule)\n",
    "roster_df = pl.concat(Data_Schedule, how=\"diagonal\")\n",
    "roster_df =roster_df.to_pandas()\n",
    "roster_df['Attribute']=pd.to_datetime(roster_df['Attribute'],format='mixed').dt.date\n",
    "roster_df =roster_df.loc[((roster_df['Attribute']==current_week) & (roster_df['week_shift'] !='Training') & (roster_df['week_shift'] !=''))]\n",
    "roster_df[\"ShiftStart\"] = pd.to_datetime(roster_df['Attribute'].astype(str) + \" \" + roster_df[\"week_shift\"].str[:2] + \":00:00\", format='%Y-%m-%d %H:%M:%S')\n",
    "roster_df[\"ShiftEnd\"] = roster_df[\"ShiftStart\"] + pd.Timedelta(hours=9)\n",
    "roster_df =roster_df[['Emp ID','week_off','LOB','team_leader',\"ShiftStart\",\"ShiftEnd\",'week_shift']]\n",
    "roster_df=roster_df.rename(columns={'Emp ID':'EID','week_off':'WeekOff'})\n",
    "\n",
    "# Merge with team shift to get shift typeðŸ’¡\n",
    "team_shift = pd.read_excel(f\"{team_shift_path}/Team shift.xlsx\", sheet_name=\"Sheet1\")\n",
    "roster_df = pd.merge(roster_df, team_shift, left_on='team_leader', right_on='EID', how='left')\n",
    "roster_df['Prioritized shift'] = roster_df['SHIFT'].apply(lambda x: 'NS' if x == 'NS' else 'DS')\n",
    "roster_df = roster_df.drop(columns=['EID_y', 'TL']).rename(columns={'EID_x': 'EID'})\n",
    "# Merge ews to remove attritionðŸ’¡\n",
    "ews = pd.read_excel(f\"{ews_path}/WFMForm.xlsx\", sheet_name=\"EWSView\", dtype={\"EID\": str})\n",
    "roster_df[\"EID\"] = roster_df[\"EID\"].astype(str)\n",
    "roster_df = pd.merge(roster_df, ews[[\"EID\", \"LWD_OnFloor\"]], on=\"EID\", how=\"left\")\n",
    "roster_df[\"LWD_OnFloor\"] = roster_df[\"LWD_OnFloor\"].fillna(\"2030-01-01\")\n",
    "roster_df[\"LWD_OnFloor\"] = pd.to_datetime(roster_df[\"LWD_OnFloor\"], format=\"mixed\").dt.date\n",
    "roster_df[\"LWD_OnFloor\"] = (roster_df[\"LWD_OnFloor\"] > next_week).astype(int)  \n",
    "roster_df = roster_df[roster_df[\"LWD_OnFloor\"] == 1]  \n",
    "roster_df[[\"ShiftStart\", \"ShiftEnd\"]] = roster_df[[\"ShiftStart\", \"ShiftEnd\"]].apply(pd.to_datetime, format=\"mixed\")  \n",
    "roster_df[\"Gap\"] = roster_df[\"ShiftEnd\"] + pd.Timedelta(hours=12)\n",
    "roster_df[\"Order\"] = roster_df[\"WeekOff\"].isin((\"MonSun\", \"SatSun\")).astype(int) \n",
    "roster_df.sort_values(by=['Gap', 'team_leader'], ascending=True, inplace=True)\n",
    "roster_df.sort_values(by=['Order'], ascending=False, inplace=True)\n",
    "roster_df.sort_values(by=['Prioritized shift'], ascending=False, inplace=True)\n",
    "roster_df.drop(columns=[ \"Order\", \"SHIFT\", \"LWD_OnFloor\"], inplace=True)\n",
    "\n",
    "# Create Pattern\n",
    "next_week = next_week.strftime(\"%Y%m%d\")\n",
    "path=\".xlsx\"\n",
    "filename= next_week+path\n",
    "pattern_df = pd.read_excel(f\"{pattern_raw_path}/{filename}\", sheet_name=\"Sheet1\")\n",
    "ds_shifts = ('0000-0900', '0100-1000', '0200-1100', '0300-1200', '0400-1300', '0500-1400', '0600-1500', '0700-1600', \n",
    "             '0800-1700', '0900-1800', '1000-1900', '1100-2000', '1200-2100', '1300-2200', '1400-2300', '1500-0000')\n",
    "ns_shifts = ('1600-0100', '1700-0200', '1800-0300', '1900-0400', '2000-0500', '2100-0600', '2200-0700', '2300-0800')\n",
    "pattern_df['ShiftType'] = pattern_df['Shift'].apply(lambda x: 'NS' if x in ns_shifts else 'DS')\n",
    "pattern_df[\"ShiftStart\"] = pd.to_datetime(pattern_df['Date'].astype(str) + \" \" + pattern_df[\"Shift\"].str[:2] + \":00:00\", format='%Y-%m-%d %H:%M:%S')\n",
    "pattern_df[\"ShiftEnd\"] = pattern_df[\"ShiftStart\"] + pd.Timedelta(hours=9)\n",
    "pattern_df[\"Date\"] = pd.to_datetime(pattern_df[\"Date\"]).dt.date\n",
    "pattern_df['Check'] = pattern_df.apply(lambda x: 0 if x['RD'] in ('MonSun', 'MonTue') else 1, axis=1)\n",
    "pattern_df = pattern_df.sort_values(by=['ShiftType', 'Check', 'ShiftStart'], ascending=False)\n",
    "pattern_df['EID'] = pattern_df['EID'].fillna('NA')\n",
    "pattern_df['ID Pattern'] = pattern_df['ID Pattern'].astype(str)\n",
    "pattern_df['Check'] = pattern_df['LOB'] + pattern_df['ID Pattern']\n",
    "pattern_df = pattern_df[['Date', 'LOB', 'ID Pattern', 'ShiftType', 'RD', 'Shift', 'ShiftStart', 'ShiftEnd', 'EID', 'Check']]\n",
    "\n",
    "print(roster_df)\n",
    "print(pattern_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67707123-4f3d-4ef0-ab29-b02b192dc5c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Request âœ¨\n",
    "next_week = pd.to_datetime(today) + pd.offsets.Week(weekday=0)\n",
    "next_week = next_week.date()\n",
    "\n",
    "special_request_df = pd.read_excel(special_request_path+\"/\"+filename,sheet_name=\"Sheet1\")\n",
    "special_request_df=special_request_df.fillna(0)\n",
    "special_request_df[\"ShiftStart\"] = special_request_df.apply(lambda x: x[\"Shift\"][0:2] if x['Shift']!=0 else x['Shift'], axis=1)\n",
    "special_request_df[\"ShiftStart\"]=special_request_df[\"ShiftStart\"].astype(\"int64\")\n",
    "special_request_df[\"ShiftStart\"]=pd.to_datetime(special_request_df[\"ShiftStart\"],format='%H').dt.time\n",
    "special_request_df[\"ShiftStart\"]=pd.to_datetime(special_request_df['Date'].astype(str) + special_request_df[\"ShiftStart\"].astype(str), format = '%Y-%m-%d%H:%M:%S')\n",
    "special_request_df[\"ShiftEnd\"]=pd.to_datetime(special_request_df[\"ShiftStart\"],format='mixed') + pd.Timedelta(hours=9)\n",
    "special_request_df[\"Date\"]=pd.to_datetime(special_request_df[\"Date\"],format='mixed').dt.date\n",
    "special_request_df[\"EID\"]=special_request_df[\"EID\"].astype(\"str\")\n",
    "special_request_df=pd.merge(special_request_df,roster_df[['LOB','EID','WeekOff','Gap']], left_on='EID', right_on='EID', how='left')\n",
    "special_request_df['LOB']=special_request_df.apply(lambda x: x['LOB_y'] if x['LOB_y'] in ('VICSG','VICSP','Senior VICSP') else x['LOB_x'], axis=1)\n",
    "special_request_df['WeekOff']=special_request_df.apply(lambda x: x['WeekOff_y'] if x['WeekOff_x'] ==0 else x['WeekOff_x'], axis=1)\n",
    "special_request_df = pd.merge(special_request_df, ews[[\"EID\", \"LWD_OnFloor\"]], on=\"EID\", how=\"left\")\n",
    "special_request_df[\"LWD_OnFloor\"] = special_request_df[\"LWD_OnFloor\"].fillna(\"2030-01-01\")\n",
    "special_request_df[\"LWD_OnFloor\"] = pd.to_datetime(special_request_df[\"LWD_OnFloor\"], format=\"mixed\").dt.date\n",
    "special_request_df[\"LWD_OnFloor\"] = (special_request_df[\"LWD_OnFloor\"] > next_week).astype(int) \n",
    "special_request_df = special_request_df[special_request_df[\"LWD_OnFloor\"] == 1] \n",
    "special_request_df=special_request_df.drop(columns=['LOB_x', 'LOB_y','WeekOff_x','WeekOff_y',\"LWD_OnFloor\"])\n",
    "\n",
    "# Special request mapping\n",
    "schedule_sr=special_request_df\n",
    "def tim_emp_phu_hop(EID, rd,shifttype, shift, lob, gap,pattern_df):\n",
    "    # Define the condition for the filter\n",
    "    lob_condition = ((pattern_df['LOB'].isin(['VICSG', 'VICSP', 'Senior VICSP'])) & (lob == pattern_df['LOB'])) | \\\n",
    "                    ((lob not in ['VICSG', 'VICSP', 'Senior VICSP']) & (~pattern_df['LOB'].isin(['VICSG', 'VICSP', 'Senior VICSP'])))\n",
    "    gap_hour = gap.hour\n",
    "    # Filter rows based on the parameters passed\n",
    "    filtered_roster = pattern_df[\n",
    "        pattern_df['RD'].isin(weekoff_mapping_pre) &\n",
    "        pattern_df['RD'].apply(lambda x: rd in weekoff_mapping.get(x, [])) &\n",
    "        ((pattern_df['ShiftStart'].dt.hour > gap_hour) | \n",
    "        (pattern_df['RD'].isin(['MonTue','MonSun'])) | (rd in ('SatSun', 'MonSun'))) &\n",
    "        ((rd == 0) | (pattern_df['RD'] == rd)) & \n",
    "        ((lob == 0) | (pattern_df['LOB'] == lob)) & \n",
    "        ((shift == 0) | (pattern_df['Shift'] == shift)) & ((shifttype == 0) | (pattern_df['ShiftType'] == shifttype)) &\n",
    "        lob_condition]\n",
    "    # Return the filtered 'Check' column as a list\n",
    "    return filtered_roster['Check'].tolist() if not filtered_roster.empty else []\n",
    "schedule_sr['emp_list'] = schedule_sr.apply(lambda row: tim_emp_phu_hop(row['EID'], row['WeekOff'], row['ShiftType'], row['Shift'], row['LOB'],row['Gap'], pattern_df), axis=1)\n",
    "processed_employees = []\n",
    "schedule_sr['ID Pattern'] = None\n",
    "for i, row in schedule_sr.iterrows():\n",
    "   for emp_list in row['emp_list']:\n",
    "           if emp_list not in processed_employees:                   \n",
    "                schedule_sr.loc[i, 'ID Pattern'] = emp_list\n",
    "                processed_employees.append(emp_list)\n",
    "                break\n",
    "schedule_sr['ID Pattern']=schedule_sr['ID Pattern'].fillna(0)\n",
    "\n",
    "# Loai cac ID pattern da xep cho Special request ra khoi pattern_df\n",
    "pattern_df=pd.merge(pattern_df,schedule_sr[['EID','ID Pattern']], left_on='Check', right_on='ID Pattern', how='left')\n",
    "pattern_df['EID_y']=pattern_df['EID_y'].fillna(0)\n",
    "pattern_df['EID']=pattern_df.apply(lambda x: x['EID_y'] if x['EID_y']!=0 else x['EID_x'], axis=1)\n",
    "pattern_df=pattern_df.drop(columns=['EID_x', 'EID_y', 'ID Pattern_y','Check'])\n",
    "pattern_df=pattern_df.rename(columns={'ID Pattern_x':'ID Pattern'})\n",
    "pattern_df['EID']=pattern_df['EID'].astype(\"str\")\n",
    "\n",
    "print(pattern_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af3108-556c-4d76-bf2a-ff3091f956ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Mapping ðŸ“¥\n",
    "\n",
    "roster=pd.merge(roster_df,pattern_df[['EID','RD']], left_on='EID', right_on='EID', how='left')\n",
    "roster=roster.loc[(roster['RD'].isnull()==True)]\n",
    "roster=roster.drop(columns=['RD'])\n",
    "schedule=pattern_df\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "def tim_emp_phu_hop(EID, rd, shiftype, shiftstart, lob, roster):\n",
    "    if EID == 'NA':\n",
    "        shiftstart_hour = shiftstart.hour\n",
    "        shiftstart_minute = shiftstart.minute\n",
    "        # Filter\n",
    "        filtered_roster = roster[\n",
    "            roster['WeekOff'].isin(weekoff_mapping) &\n",
    "            roster['WeekOff'].apply(lambda x: rd in weekoff_mapping.get(x, [])) &\n",
    "            ((roster['Gap'].dt.hour < shiftstart_hour) | \n",
    "             ((roster['Gap'].dt.hour == shiftstart_hour) & (roster['Gap'].dt.minute <= shiftstart_minute)) |\n",
    "             (roster['WeekOff'].isin(['SatSun', 'MonSun'])) | (rd in ('MonTue','MonSun'))) &\n",
    "            (lob == roster['LOB']) & (roster['Prioritized shift']==shiftype)\n",
    "            ]\n",
    "        return filtered_roster['EID'].tolist()\n",
    "    else:\n",
    "        return [] \n",
    "schedule['emp_list'] = schedule.apply(lambda row: tim_emp_phu_hop(row['EID'], row['RD'], row['ShiftType'], row['ShiftStart'], row['LOB'], roster), axis=1)\n",
    "processed_employees = []\n",
    "schedule['EID_2'] = None\n",
    "# Loop 1\n",
    "for i, row in schedule.iterrows():\n",
    "   for emp_list in row['emp_list']:\n",
    "           if emp_list not in processed_employees:                   \n",
    "                schedule.loc[i, 'EID_2'] = emp_list\n",
    "                processed_employees.append(emp_list)\n",
    "                break\n",
    "schedule['EID_2'] = schedule['EID_2'].fillna(0)\n",
    "schedule['EID']=schedule.apply(lambda x: x['EID_2'] if x['EID_2'] !=0 else x['EID'], axis=1)\n",
    "#Loop 2\n",
    "for _ in range(4): \n",
    "    schedule['EID_2'] = None\n",
    "    for i, row in schedule.iterrows():\n",
    "       for emp_list in row['emp_list']:\n",
    "               if emp_list not in processed_employees:\n",
    "                   if schedule.loc[i,'EID']=='NA':\n",
    "                        schedule.loc[i, 'EID_2'] = emp_list\n",
    "                        processed_employees.append(emp_list)\n",
    "                        break\n",
    "    schedule['EID_2'] = schedule['EID_2'].fillna(0)\n",
    "    schedule['EID']=schedule.apply(lambda x: x['EID_2'] if x['EID_2'] !=0 else x['EID'], axis=1)\n",
    "# Map with diff LOB\n",
    "def tim_emp_phu_hop(EID, rd,shiftype, shiftstart, lob, roster):\n",
    "    if EID == 'NA':\n",
    "        shiftstart_hour = shiftstart.hour\n",
    "        shiftstart_minute = shiftstart.minute\n",
    "        # Filter\n",
    "        filtered_roster = roster[\n",
    "            roster['WeekOff'].isin(weekoff_mapping) &\n",
    "            roster['WeekOff'].apply(lambda x: rd in weekoff_mapping.get(x, [])) &\n",
    "            ((roster['Gap'].dt.hour < shiftstart_hour) | \n",
    "             ((roster['Gap'].dt.hour == shiftstart_hour) & (roster['Gap'].dt.minute <= shiftstart_minute)) |\n",
    "             (roster['WeekOff'].isin(['SatSun', 'MonSun'])) | (rd in ('MonTue','MonSun'))) &\n",
    "            (((roster['LOB'].isin(['VICSG', 'VICSP', 'Senior VICSP'])) & (lob == roster['LOB'])) |\n",
    "             ((lob not in (['VICSG', 'VICSP', 'Senior VICSP'])) & (~roster['LOB'].isin (['VICSG', 'VICSP', 'Senior VICSP']))))\n",
    "            & (roster['Prioritized shift']==shiftype)\n",
    "            ]\n",
    "        return filtered_roster['EID'].tolist()\n",
    "    else:\n",
    "        return [] \n",
    "schedule['emp_list'] = schedule.apply(lambda row: tim_emp_phu_hop(row['EID'], row['RD'],row['ShiftType'], row['ShiftStart'], row['LOB'], roster), axis=1)\n",
    "# Loop 1 with diff LOB\n",
    "for i, row in schedule.iterrows():\n",
    "   for emp_list in row['emp_list']:\n",
    "           if emp_list not in processed_employees:                   \n",
    "                schedule.loc[i, 'EID_2'] = emp_list\n",
    "                processed_employees.append(emp_list)\n",
    "                break\n",
    "schedule['EID_2'] = schedule['EID_2'].fillna(0)\n",
    "schedule['EID']=schedule.apply(lambda x: x['EID_2'] if x['EID_2'] !=0 else x['EID'], axis=1)\n",
    "#Loop 2 with diff LOB\n",
    "for _ in range(4): \n",
    "    schedule['EID_2'] = None\n",
    "    for i, row in schedule.iterrows():\n",
    "       for emp_list in row['emp_list']:\n",
    "               if emp_list not in processed_employees:\n",
    "                   if schedule.loc[i,'EID']=='NA':\n",
    "                        schedule.loc[i, 'EID_2'] = emp_list\n",
    "                        processed_employees.append(emp_list)\n",
    "                        break\n",
    "    schedule['EID_2'] = schedule['EID_2'].fillna(0)\n",
    "    schedule['EID']=schedule.apply(lambda x: x['EID_2'] if x['EID_2'] !=0 else x['EID'], axis=1)\n",
    "\n",
    "print(schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f2f78-a45f-4007-aa8b-6ebafb1ecb3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Out put ðŸ’¡\n",
    "\n",
    "# unused pattern\n",
    "pattern = schedule[['Date', 'LOB', 'ID Pattern', 'ShiftType', 'RD', 'Shift', 'ShiftStart', 'ShiftEnd', 'EID']]\n",
    "unused_pattern = pattern[pattern['EID'] == 'NA']\n",
    "# unscheduled agent\n",
    "unschedule_agent = pd.merge(roster_df, schedule[['ID Pattern', 'EID']], on='EID', how='left')\n",
    "unschedule_agent = unschedule_agent[unschedule_agent['ID Pattern'].isna()]\n",
    "# Function to write DataFrames to Excel\n",
    "def write_to_excel(filename, data_dict):\n",
    "    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
    "        for sheet, data in data_dict.items():\n",
    "            data.to_excel(writer, sheet_name=sheet, index=False)\n",
    "# Prepare data and write to Excel\n",
    "schedule_data = {'PATTERN': pattern, 'UNUSED_PATTERN': unused_pattern, 'UNSCHEDULE_AGENT': unschedule_agent,'ROSTER': roster_df}\n",
    "write_to_excel(f\"{schedule_path}/Schedule_{filename}\", schedule_data)\n",
    "\n",
    "# Print the data\n",
    "print(pattern)\n",
    "print(unused_pattern)\n",
    "print(unschedule_agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
